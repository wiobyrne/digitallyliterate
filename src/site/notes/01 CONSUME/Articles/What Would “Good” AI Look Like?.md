---
{"dg-publish":true,"permalink":"/01-consume/articles/what-would-good-ai-look-like/","title":"What Would “Good” AI Look Like?","tags":["ai","good-AI","hype-cycle"]}
---


# What Would “Good” AI Look Like?

## Key Points:
We're a few years into the tech industry's [[AI\|AI]] hype cycle, and it's all been characterized by far more heat than light. The assertions by the people making the AI platforms are as absurd as we've come to expect from shameless Silicon Valley shills. ([[AGI: a strategy of raising funding based on the promise of being able to replace any worker with a Python script.\|AGI: a strategy of raising funding based on the promise of being able to replace any worker with a Python script.]])

Interestingly enough, while there are tons of valid critiques of today's AI offerings, we don't often see an affirmative example of what we *would* want to see. So, I'd like to share an example that's been banging around in my head for a while of what a *good* AI platform might look like. Some of this is just a thought exercise, trying to imagine an alternate future. But this is also an intentional, practical strategy and an attempt at a more effective form of critique — because if we are going to have better AI in the future, we are going to have get lots of people to understand that such a thing is possible.

## The Good AI?

This isn't a comprehensive list, but it's possible to imagine some traits of an AI system that could credibly offer an alternative to the offerings that are currently dominating the conversation. (This is deliberately light on technical specifics and is intended for a more general audience, but is grounded in familiarity with the current state of progress on consumer-grade AI technologies.) Here are some highlights:

- **Content consent:** A model trained on a data set gathered with *consent*, from creators or content owners who have agreed to allow their work or intellectual property to be indexed, and with revenues (if any) shared back to those creators if those are the agreed terms.
- **Hallucination-free:** Alternative approaches, possibly other than a large language model entirely, which avoid the confabulation issues generally described as "hallucination" in current systems, or which clearly label content likely to be spurious.
- **Green:** Clarity on sustainability and energy consumption for both training and usage of new offerings, reflecting the vast improvements in efficiency that have been achieved by recent models, and encouraging and rewarding the use of lower-impact, more conventional approaches (like traditional search!) where appropriate.
- **Actually open source:** The Open Source Initiative has offered us a [clear definition of open source AI](https://opensource.org/ai), which doesn't settle for the mere "open weights" that industry titans are trying to pass off as "open", and offers real transparency for developers and institutions, which would unlock a new era of innovation and accountability. Developers are ready to get their hands on these kinds of tools.
- **Community-led:** Alternative creation, ownership and governance models for AI tools that address the corporate chaos of today's big names are well past due. Whether it takes the form of a workers' cooperative, an open source collective, stewardship by an academic or NGO, or some other simple format for sharing the work and the tech, both users and the industry are ready for other players to change the power dynamic around AI tech. There's even the potential for a platform that is creator-led or owned and controlled by those who contributed to its creation, aligning the motivations of the platform with those who make its existence possible.
- **Accessible:** These are tools that should be available to all. Whether that means across devices, across continents, across abilities, across platforms, or even simply across a longer span of time and attention than "until the VC money runs out", there's a huge opportunity in making tools that serve everyone.

As mentioned, these are highlights. We can imagine a lot more details, and there are probably additional ambitions that we might want to capture. But this kind of reframing of the AI space would be akin to what has happened in other fundamental enabling technologies ranging from operating systems to web servers to countless systems at the protocol or infrastructure level. Tech at those layers gets more open, more collaborative, and more empowering for more organizations while reducing the amount of institutional control. We even see those patterns repeat in cultural phenomena like " [wherever you get your podcasts](https://www.anildash.com/2024/02/06/wherever-you-get-podcasts/) ".

We simply need to start thinking through the implications of a fundamentally better approach to AI, and to understand that all of these things are extremely possible. Consumer-grade AI tools that are actually good do not have to be a hallucination.

## Summary:
A blog about making culture. Since 1999.

---

*Source: [What Would “Good” AI Look Like?](https://www.anildash.com/2025/05/01/what-would-good-ai-look-like/)*
