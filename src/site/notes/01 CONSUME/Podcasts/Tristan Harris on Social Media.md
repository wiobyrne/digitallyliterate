---
{"dg-publish":true,"permalink":"/01-consume/podcasts/tristan-harris-on-social-media/","title":"Tristan Harris on Social Media"}
---

# Tristan Harris on Social Media

![rw-book-cover](https://wsrv.nl/?url=https%3A%2F%2Fssl-static.libsyn.com%2Fp%2Fassets%2F0%2F9%2F7%2Fe%2F097e1e1107a7009a%2FMAKING_SENSE_MASTER.png&w=300&h=300)

[[Tristan Harris\|Tristan Harris]], a former [[Google\|Google]] designer and [[advocate\|advocate]] for [[ethical technology\|ethical technology]], discusses the detrimental effects of [[social media\|social media]] on individual and societal [[well-being\|well-being]]. He shares insights from his documentary, [[The Social Dilemma\|The Social Dilemma]], focusing on how [[algorithms\|algorithms]] promote division. The conversation includes perspectives on content moderation and corporate transparency from [[Jack Dorsey\|Jack Dorsey]], while [[Jonathan Haidt\|Jonathan Haidt]] reveals alarming [[mental health\|mental health]] impacts, particularly on [[adolescent\|adolescent]] [[girls\|girls]]. The episode concludes with a look at the political ramifications of social media, emphasizing the urgent need for solutions.


## Highlights
- Social Media: [[Technology Overwhelms Human Weaknesses\|Technology Overwhelms Human Weaknesses]]
  Key takeaways:
  • Social media has a problem of incentives that are doing harm.
  • The exact harms of these incentives are hard to find.
  • Technology is undermining human weaknesses, not just overwhelming human strengths.
  • The film and presentation at SF Jazz Center framed the issue in this way.
  Transcript:
  Speaker 4
  Let's take it from the top here. What's wrong with social media at this point? If you could boil it down to the elevator pitch answer, what is the problem that we're going to unspool?
  Speaker 3
  Well, it's funny because the film actually opens with that prompt to the blank stares of many technology insiders, including myself, because I think it's so hard to find exactly what This problem is. There's clearly a problem of incentives, but beneath that, there's a problem of what those incentives are doing and where the exact harms show up. And the way that we frame it in the film and in a big presentation we gave at the SF Jazz Center back in April 2019 to a bunch of the top technologists and people in the industry was to say that While we've all been looking out for the moment when AI would overwhelm human strengths and when we get the singularity, when would AI take our jobs, when would it be smarter than humans? We missed this much, much earlier point when technology didn't overwhelm human strengths, but it undermined human weaknesses. And you can actually frame the cacophony of grievances and scandals and problems that we've seen in the tech industry, from distraction to addiction to polarization to bullying to Harassment to the breakdown of truth, all in terms of progressively hacking more and more of human vulnerabilities and weaknesses. So if we take it from the top, our brain's short-term memory system have 7 plus or minus two things that we can hold. When technology starts to overwhelm our short-term and working memory, we feel that as a problem called distraction. Oh my gosh, I can't remember what I was doing. I came here to open an email. I came here to go to Facebook to look something up, but now I got sucked down into something else. That's a problem of overwhelming the human limit and weakness of just our working memory. When it overwhelms our dopamine systems and our reward systems, that we feel that as a problem called addiction. When it taps into and exploits our reliance on stopping cues, that at some point I will stop talking and that's a cue for you to keep going. When technology doesn't stop talking and it just gives you the independent bottomless bowl, we feel that as a problem called addiction or addictive use. When technology exploits our social approval and giving us more and more social approval, we feel that as a problem called teen depression because suddenly children are dosed with Social approval every few minutes and are hungry for more likes and comparing themselves in terms of the currency of likes. And when technology hacks the limits of our heuristics for determining what is true. For example, that Twitter profile who just commented on your tweet five seconds ago, that photo looked pretty real. They've got a bio that seems pretty real. They've got 10,000 followers. We only have a few cues that we can use to discern what is real and bots and deepfakes. And I'm sure we'll get into GPT three actually overwhelmed that human weakness so we don't even know what's true. So I think that the main thing that we really want people to get is through a series of misaligned incentives, which we'll further get into technology has overwhelmed and undermined Human weaknesses. And many of the problems that we're seeing as separate are actually the same. And just one more thing on this analogy, it's kind of like collectively, this digital fallout of addiction, teen depression, suicides, polarization, breakdown of truth, we think Of this as a collective digital fallout or a kind of climate change of culture, that much like the oil extractive economy that we have been living in an extractive race for attention, There's only so much when it starts running out. We have to start fracking your attention by splitting your attention into multiple streams. I want you watching an iPad and a phone and the television at the same time because that lets me triple the size of the attention economy. But that extractive race for attention creates this global climate change of culture. And much like climate change, it happens slowly, it happens gradually, it happens chronically, it's not this sudden immediate threat, it's this slow erosion of the social fabric. And that collectively, we call it in that presentation, human downgrading, but you can call it whatever you want. The point is that, you know, if you think back to the climate change movement, before there was climate change as a cohesive understanding of emissions and linking to climate change, We had some people working on polar bears, some people working on the coral reefs, we had some people working on species loss in the Amazon, and it wasn't until we had an encompassing View of how all these problems get worse that we start to get changed. And so we're really hoping that this film can act as a kind of catalyst for a global response to this really destructive thing that's happened to society. [Time 0:08:03](https://readwise.io/open/543804560)
{ #rw543804560}


- The Impact of Smartphones on the Attention Economy
  Key takeaways:
  • The attention economy is not a new concept and has existed with various mediums competing for attention throughout history.
  • Smartphones have become an integral part of people's daily lives and are the primary mediator for attention.
  • Smartphones have also taken over as the primary vehicle for many day-to-day activities such as communication.
  Transcript:
  Speaker 3
  Gosh, there's so much good stuff to unpack here. So on the attention economy, obviously, we've always had it. We've had television competing for attention, radio, and we've had evolutions of the attention economy before, competition between books, competition between newspapers, competition Between television to more engaging television to more channels of television. So in many ways, this isn't new. But I think what we really need to look at is what was mediating where that attention went to. Mediating's a big word. Smartphones, we check out, we check our smartphones, you know, a hundred times or something like that per day. They are intimately woven into the fabric of our daily lives. And ever more so because of, if we pre-establish addiction or just this addictive checking that we have, then any moment of anxiety, we turn to our phone to look at it. So it's intimately woven into where the attention starting place will come from. It's also taken over our fundamental infrastructure for our basic verbs. Like if I want to talk to you or talk to someone else, my phone has become the primary vehicle for just about for many, many verbs in my life, whether it's ordering food or speaking to someone Or, you know, figuring out where to go on a map, we are increasingly reliant on the central node of our smartphone to be a router for where all of our attention goes. [Time 0:15:50](https://readwise.io/open/543804561)
{ #rw543804561}


- The Intimately Woven Nature of Technology and its Asymmetry in Influence
  Key takeaways:
  • Intimately woven nature and social infrastructure make technology unavoidable.
  • Technology is inhumane due to reliance on unsafe or contaminated infrastructure.
  • Asymmetry between traditional media and technology is significant.
  • Supercomputing infrastructure behind technology influences user behavior.
  Transcript:
  Speaker 3
  So that's the first part of this intimately woven nature. And the fact that it's our social, it's part of the social infrastructure by which we rely on. We can't avoid it. And part of what makes technology today inhumane is that we're reliant on infrastructure that's not safe or contaminated for many reasons that we'll get into later. A second reason that's different is the degree of asymmetry between, let's say, that newspaper editor or journalist who is writing that enticing article that gets you to turn to the Next page, versus the level of asymmetry of when you watch a YouTube video and you think, yeah, this time, I'm just going to watch one video and then I've got to go back to work and you wake Up from a trance, you know, two hours later, and you say, man, what happened to me, I should have had more self-control. What that misses is there's literally the Google's billions of dollars of supercomputing infrastructure on the other side of that slab of glass in your hand pointed at your brain, Doing predictive analytics on what would be the perfect next video to keep you here. And the same is true on Facebook. You think, okay, I've sort of been scrolling through this thing for a while, but I'm just going to swipe up one more time. And then I'm done. Each time you swipe up with your finger, you know, you're activating a Twitter or a Facebook or a TikTok supercomputer that's doing predictive analytics, which has billions of data Points on exactly the thing that'll keep you here. [Time 0:17:01](https://readwise.io/open/543804562)
{ #rw543804562}


- Social Media: The Battle Between Our Brain and Supercomputers
  Key takeaways:
  • There is a greater degree of asymmetry between traditional media and social media in regards to user attention.
  • The supercomputing infrastructure of platforms like Google, Facebook, Twitter, and TikTok are used to keep users engaged.
  • Predictive analytics are used to determine perfect next videos or posts to keep users on the platform.
  Transcript:
  Speaker 3
  A second reason that's different is the degree of asymmetry between, let's say, that newspaper editor or journalist who is writing that enticing article that gets you to turn to the Next page, versus the level of asymmetry of when you watch a YouTube video and you think, yeah, this time, I'm just going to watch one video and then I've got to go back to work and you wake Up from a trance, you know, two hours later, and you say, man, what happened to me, I should have had more self-control. What that misses is there's literally the Google's billions of dollars of supercomputing infrastructure on the other side of that slab of glass in your hand pointed at your brain, Doing predictive analytics on what would be the perfect next video to keep you here. And the same is true on Facebook. You think, okay, I've sort of been scrolling through this thing for a while, but I'm just going to swipe up one more time. And then I'm done. Each time you swipe up with your finger, you know, you're activating a Twitter or a Facebook or a TikTok supercomputer that's doing predictive analytics, which has billions of data Points on exactly the thing that'll keep you here. And I think it's important to expand this metaphor in a way that you've talked about on, I think in your show before about just the power, increasing power and computational power of AI. When you think about a supercomputer pointed at your brain trying to figure out what's the perfect next thing to show you, that's on one side of the screen. On the other side of the screen is my prefrontal cortex, which has evolved millions of years ago and doing the best job it can to do goal articulation, goal retention and memory and sort Of staying on tasks, self-discipline, et cetera. So who's going to win in that battle? Well, a good metaphor for this is let's say you or I were to play Gary Kasparov at chess. Like, why would you or I lose? It's because, you know, there I am on the chessboard and I'm thinking, okay, if I do this, he'll do this. But if I do this, he'll do this. And I'm playing out a few new moves ahead in the chessboard. But when Gary looks at that same chessboard, he's playing out a million more moves ahead than I can, right? And that's why Gary is going to win and beat you and I every single time. But when Gary, the human, is playing chess against the best supercomputer in the world, no matter how many million moves ahead that Gary can see, the supercomputer can see billions Of moves ahead. And when he beats Gary, who is the best human chess player of all time, he's beaten like the human brain at chess because that was kind of the best one that we had. And so when you look at the degree of asymmetry that we now have, when you're sitting there and noctivously saying, okay, I'm just going to watch one video and then I'm out, we have to recognize That we have an exponential degree of asymmetry and they know us and our weaknesses better than we know ourselves. [Time 0:17:18](https://readwise.io/open/543804563)
{ #rw543804563}


- The Battle of AI and Human Brain: A Chess Metaphor
  Key takeaways:
  • The power and computational power of AI can be compared to a supercomputer pointed at the brain.
  • The prefrontal cortex is responsible for goal articulation, goal retention, memory, staying on tasks, and self-discipline.
  • A metaphor for the battle between AI and the prefrontal cortex is playing chess against Gary Kasparov.
  • Gary Kasparov is able to play out many more moves ahead than an average person.
  Transcript:
  Speaker 3
  And I think it's important to expand this metaphor in a way that you've talked about on, I think in your show before about just the power, increasing power and computational power of AI. When you think about a supercomputer pointed at your brain trying to figure out what's the perfect next thing to show you, that's on one side of the screen. On the other side of the screen is my prefrontal cortex, which has evolved millions of years ago and doing the best job it can to do goal articulation, goal retention and memory and sort Of staying on tasks, self-discipline, et cetera. So who's going to win in that battle? Well, a good metaphor for this is let's say you or I were to play Gary Kasparov at chess. Like, why would you or I lose? It's because, you know, there I am on the chessboard and I'm thinking, okay, if I do this, he'll do this. But if I do this, he'll do this. And I'm playing out a few new moves ahead in the chessboard. But when Gary looks at that same chessboard, he's playing out a million more moves ahead than I can, right? And that's why Gary is going to win and beat you and I every single time. But when Gary, the human, is playing chess against the best supercomputer in the world, no matter how many million moves ahead that Gary can see, the supercomputer can see billions Of moves ahead. And when he beats Gary, who is the best human chess player of all time, he's beaten like the human brain at chess because that was kind of the best one that we had. And so when you look at the degree of asymmetry that we now have, when you're sitting there and noctivously saying, okay, I'm just going to watch one video and then I'm out, we have to recognize That we have an exponential degree of asymmetry and they know us and our weaknesses better than we know ourselves. [Time 0:18:15](https://readwise.io/open/543804564)
{ #rw543804564}


- The Consequences of the Idea That Information Should be Free
  Key takeaways:
  • The idea that information should be free was a deeply held belief starting in the 80s and still holds for many people.
  • Defying this belief was difficult and resulted in losing friends.
  • The belief that information is weightless and free in infinite supply is a serious mistake that threatens the survival of our species.
  • Information only exists to the degree that people can perceive, process, and understand it.
  Transcript:
  Speaker 1
  Well, this idea that information should be free was held in the most profound and intense way. It was something that was believed so intensely during a period starting in the 80s. And in some ways, it still holds for a lot of people. And to defy that was very, very difficult. It was painful for my friends who couldn't believe that I was defying it. It was painful for me. I did lose friends over it. And on its face, it sounds very generous and fair and proper and freeing. But there are problems with it that are so deep as to, I think, threaten the survival of our species. It's actually a very, very, very serious mistake. So the mistakes happen on a couple of levels here. I would say the first one has to do with this idea that information is totally weightless and intrinsically something that's free in an infinite supply. And that's not true because information only exists to the degree that people can perceive it and process it and understand it. [Time 0:23:29](https://readwise.io/open/543804565)
{ #rw543804565}


- The Idea That Information Should Be Free: A Serious Mistake Threatening The Survival of Our Species
  Key takeaways:
  • The idea of information being free was deeply held during the 80s and still holds true for many.
  • Defying this idea was difficult and caused pain and loss of friendships.
  • The belief that information is weightless and intrinsically free is a serious mistake that threatens the survival of the species.
  • Information only has meaning when it is perceived, processed, and understood by humans, and it only exists as human experience.
  Transcript:
  Speaker 1
  Well, this idea that information should be free was held in the most profound and intense way. It was something that was believed so intensely during a period starting in the 80s. And in some ways, it still holds for a lot of people. And to defy that was very, very difficult. It was painful for my friends who couldn't believe that I was defying it. It was painful for me. I did lose friends over it. And on its face, it sounds very generous and fair and proper and freeing. But there are problems with it that are so deep as to, I think, threaten the survival of our species. It's actually a very, very, very serious mistake. So the mistakes happen on a couple of levels here. I would say the first one has to do with this idea that information is totally weightless and intrinsically something that's free in an infinite supply. And that's not true because information only exists to the degree that people can perceive it and process it and understand it. It ultimately only has a meaning when it grounds out as human experience. The slogan I used to have back in the 80s when we were first debating these things is that information is alienated experience, meaning information is similar to stored energy that Can be released. You put energy into a battery, then you can release it or you lift up a weight and then you look over the weight and it goes back down and you've released the energy that was stored. And in the same way, information ultimately only has meaning as experience at some point in the future. [Time 0:23:29](https://readwise.io/open/543804566)
{ #rw543804566}


- The Fallacy of Information Being Weightless and Infinite
  Key takeaways:
  • Information is not totally weightless and is not intrinsically free.
  • Information only has meaning as experience at some point in the future.
  • Assuming that information is free makes oneself vulnerable to having more information than can be experienced.
  Transcript:
  Speaker 1
  Has to do with this idea that information is totally weightless and intrinsically something that's free in an infinite supply. And that's not true because information only exists to the degree that people can perceive it and process it and understand it. It ultimately only has a meaning when it grounds out as human experience. The slogan I used to have back in the 80s when we were first debating these things is that information is alienated experience, meaning information is similar to stored energy that Can be released. You put energy into a battery, then you can release it or you lift up a weight and then you look over the weight and it goes back down and you've released the energy that was stored. And in the same way, information ultimately only has meaning as experience at some point in the future. And the problem with experience or maybe the benefit of experience is that it's only a finite potential. You can't experience everything. And so therefore, if you make the mistake of assuming that information is free, you'll have more information than you can experience. And what you do is you make yourself vulnerable to what we could call a denial of service attack and other context. So a denial of service attack means that malicious people send some in your request to a website that it's effectively knocked out off the web. [Time 0:24:24](https://readwise.io/open/543804567)
{ #rw543804567}


- The Illusion of Free Information and Opposing Views on Technology
  Key takeaways:
  • Seriousness is necessary for reality, quality, truth, and decency, and cannot be obtained for free.
  • Technology is often portrayed as opposed to humanity.
  • Talk of job loss due to AI and robots could lead to a society where only the elite are needed and everyone else becomes a burden on the state.
  Transcript:
  Speaker 1
  There's no such thing as a free lunch. There's no such thing as free information. There's no such thing as infinite attention. There has to be some way that seriousness comes into play if you want to have any sense of reality or quality or truth or decency. And unfortunately, we haven't created a world in which that's so. But then there's a flip side to it, which is equally important, which is we've created this world in which we're talking about technology often as something that's if not opposed to Humanity opposed to most of humanity. So there's a lot of talk and a lot of this comes from really good technologies. So it's not from like malicious outsiders who are trying to screw us up. It's our own fault where we'll say, well, a lot of the jobs will go away because of our artificial intelligence and our robots. And that might either be some extreme case where a super intelligent AI takes over the world and disposes of humanity. Or it might just be that only the most elite, smart, techy people are still needed and everybody else becomes this burden on the state. And they have to go on some kind of basic income. And it's just a depressing. It's like, it's like everybody's going to become this useless burden. And so even if that means, Oh, well, I'll get basic income, we won't have to work for a living. There's also something fundamentally undignified, like you won't be needed. And any situation like that, it's just bound to be a political disaster or an economic disaster on many levels we can go into if it isn't obvious. But the thing to see is that this economic hole that we seem to be driving ourselves into is one in the same as the information wants to be free. Because the thing is ultimately all these ais and robots and all this stuff, they run on information that at the end of the day has to come from people. And each instance is a little different. But for a lot of them, there's input from a lot of people. And I can give you some examples. So if we say that information is free, then we're saying, we're in the information age, everybody's worthless, because what they can contribute is information. The example I like to use as just an entry point to this idea is the people who translate between languages. So they've seen their careers be decimated. They're 10th of what they were in the same way that recording musicians and oh, you know, investigative journalists and many other classes of people who have an information product That they've all been kind of reduced under this weird regime we've created. But the thing is, in order to run the so-called AI translators that places like Bing and Google offer, we have to scrape tens of millions of examples from real life people translating Things every single day in order to keep up with slang and public events. Language is alive, the world is alive. You can't just stuff a language translator once. You have to keep on refilling it. And so we're totally reliant on the very people that we're putting out of work. So it's fundamentally like a form of theft through dishonesty. [Time 0:26:24](https://readwise.io/open/543804568)
{ #rw543804568}


- The Potential Downside of Artificial Intelligence and Robots on Jobs and Society
  Key takeaways:
  • The talk about jobs going away due to artificial intelligence and robots is not from malicious outsiders but our own fault.
  • The extreme scenario of a super intelligent AI taking over the world is one potential outcome of this.
  • There is a risk that only a few elite tech-savvy individuals will be needed in the job market leading to a burden on the state and basic income for others.
  • This scenario is undignified and bound to create political and economic disasters.
  Transcript:
  Speaker 1
  So there's a lot of talk and a lot of this comes from really good technologies. So it's not from like malicious outsiders who are trying to screw us up. It's our own fault where we'll say, well, a lot of the jobs will go away because of our artificial intelligence and our robots. And that might either be some extreme case where a super intelligent AI takes over the world and disposes of humanity. Or it might just be that only the most elite, smart, techy people are still needed and everybody else becomes this burden on the state. And they have to go on some kind of basic income. And it's just a depressing. It's like, it's like everybody's going to become this useless burden. And so even if that means, Oh, well, I'll get basic income, we won't have to work for a living. There's also something fundamentally undignified, like you won't be needed. And any situation like that, it's just bound to be a political disaster or an economic disaster on many levels we can go into if it isn't obvious. But the thing to see is that this economic hole that we seem to be driving ourselves into is one in the same as the information wants to be free. Because the thing is ultimately all these ais and robots and all this stuff, they run on information that at the end of the day has to come from people. And each instance is a little different. But for a lot of them, there's input from a lot of people. [Time 0:27:02](https://readwise.io/open/543804569)
{ #rw543804569}


- The Authenticity of Podcasting and Advertising
  Key takeaways:
  • Podcasting is still considered an authentic medium because it is crafted by the podcaster and not manipulated by algorithms or advertisers.
  • As long as every listener can understand the same ad, it is acceptable to include them in a podcast.
  • There is no meta podcast or algorithm changing the content of a podcast to meet advertiser needs.
  Transcript:
  Speaker 1
  You're going to want this t-shirt. And that works for people who... I know I've heard some really... Listening to some of the podcasters have to read their ads when it's clearly bizarre. It's actually kind of entertaining. But the thing is, as long as every listener hears the same ad and everybody can understand what's going on, that's okay. I mean, the reason podcasting is still, in my view, an unmolested, authentic medium is that there are algorithms calculating what somebody hears on a podcast. It's still... It's crafted by you. And if it includes ads, people can tell it includes ads. There isn't some meta podcast that's taking snippets and creating a feed for people. There isn't some algorithm that's in at least so far that is like changing what you say with, you know, audio signal processing technology to see the needs of somebody who's paying from The side, some advertiser. There's not a calculation of a feed designed by behaviorists, theorists, to change people. [Time 0:33:01](https://readwise.io/open/543804570)
{ #rw543804570}


- The Negative Impact of Manipulative Social Media and the Need to Reboot the Internet
  Key takeaways:
  • Social media companies can undermine human dignity and self-determination with manipulative and creepy algorithms.
  • Gradually bringing money back into the world of information could be a solution.
  • People should be able to earn a living when adding valuable information to the network.
  Transcript:
  Speaker 1
  There's not a calculation of a feed designed by behaviorists, theorists, to change people. And as long as it's just a crafted thing, even if it includes commercial communication, I don't think it destroys society. I think it does start to destroy society when everything becomes really manipulative and creepy in a way that people can't possibly follow or understand, then it starts to undermine Human dignity and self-determination. And that's exactly what's going on with social media companies and the way searches run and the way YouTube videos are selected for you and fed to you and many other examples. And that's where we really have the most serious problem.
  Speaker 4
  So what is the solution now? If you could reboot the internet, how would you do it?
  Speaker 1
  I would do a few things. The first thing I would do is encourage everybody involved to gradually bring money back into the world of information instead of expunging it. And I think people should be able to earn a living when what they add to the network is valuable. I mean, right now we're creating the most valuable companies in history based on the information that people add to them. And meanwhile, we're creating more and more economic separation, more and more inequality. And obviously that can't go on forever. [Time 0:34:03](https://readwise.io/open/543804571)
{ #rw543804571}


- Creating Intermediate Structures to Avoid Demanding Authoritarianism
  Summary:
  We're demanding authoritarianism. And the way around that is to create middle sized organizations where you can volunteer and get paid decently instead of having a giant race to the bottom. They can become brands and themselves that enforce quality and become trustworthy, he says.
  Transcript:
  Speaker 1
  And it's just not tenable. We're demanding authoritarianism. And the way around that is to create middle sized organizations that are analogous to things like scientific journals or universities or trade unions or many other examples where You can volunteer, you can voluntarily join these things and they collectively bargain for you so you can get paid decently instead of having a giant race to the bottom. And they can become brands and themselves that enforce quality and become trustworthy. And so we have to create this, this, this sense of intermediate structures. And remember in the past before the internet, the place where excellence and compassion and trustworthiness came from was not the central government declaring it, but rather things Like universities and scientific journals and high quality news outlets developing a reputation and being selective. And but that was all voluntary, voluntary. So it wasn't authoritarian. And so if you have in between sized organizations, you can have all these effects that would be authoritarian if they were global and directed from the center. And all of those institutions are exactly the ones that were weakened and destroyed when Facebook said we're going to move fast and break things. The stuff that was broken were all those in between organizations. And so we have to rebuild them in a new way in order to have this more humane and sustainable internet. [Time 0:37:12](https://readwise.io/open/543804572)
{ #rw543804572}


