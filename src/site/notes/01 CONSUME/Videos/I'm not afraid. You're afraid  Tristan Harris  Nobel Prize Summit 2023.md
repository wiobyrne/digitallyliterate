---
{"dg-publish":true,"permalink":"/01-consume/videos/i-m-not-afraid-you-re-afraid-tristan-harris-nobel-prize-summit-2023/","title":"I'm not afraid. You're afraid | Tristan Harris | Nobel Prize Summit 2023"}
---

# I'm not afraid. You're afraid  Tristan Harris  Nobel Prize Summit 2023

![I'm not afraid. You're afraid | Tristan Harris | Nobel Prize Summit 2023](https://www.youtube.com/watch?v=6lVBp2XjWsg?list=WL)

## Description

Note: There may be missing presentation graphics in this video. See a version that includes the graphics: https://www.youtube.com/live/k06hShz_nV0?feature=share&t=20867
A thought-provoking talk by technology ethicist Tristan Harris, on the race between technology creators and our regulation on AI and our ever-increasing addiction to social media. Harris proposes that when we are creating this technology, we need to look further than blaming big tech on providing platforms for disinformation but balance the power of creation of technologies with our responsibility to govern and understand it.

Watch a playlist of Nobel Prize Summit 2023: https://www.youtube.com/playlist?list=PLJE9rmV1-0uDQH8AhUCHSyuWzCVcHFBJp

About Nobel Prize Summit 2023:

How can we build trust in truth, facts and scientific evidence so that we can create a hopeful future for all?

Misinformation is eroding our trust in science and runs the risk of becoming one of the greatest threats to our society today.

This yearâ€™s Nobel Prize Summit which brought together laureates, leading experts and the public in a conversation on how we can combat misinformation, restore trust in science and create a hopeful future. 

Learn more at https://www.nobelprize.org/events/nobel-prize-summit/2023 

Nobel Prize Summit in partnership with National Academy of Sciences. Lead partner Knight Foundation. Contributing partner Luminate. Supporting organisations Annenberg Public Policy Center University of Pennsylvania, Rita Allen Foundation. Nobel International Partners 3M, ABB, Capgemini, EQT, H2green steel, Scania. 

Special thanks to:
Alliance4Europe, American Association for the Advancement of Science, Deliberative Democracy Lab at the Stanford Center on Democracy; Development and the Rule of Law, Digital Public Goods Alliance, Embassy of Sweden to the U.S., Gordon and Betty Moore Foundation, International Panel on the Information Environment, Media Literacy Now, National Science Foundation, PeaceTech Lab, SkillsVR, S&R Evermay, Smithsonian Science Education Center, Stockholm Resilience Center/Beijer Institute, The Inter-American Institute for Global Change Research, The Mercury Project, Transatlantic Consumer Dialogue, United Nations Development Programme, W.K. Kellogg Foundation, Wikimedia DC.

#NobelPrizeSummit

## Notes

## Transcript

## Intro

0:00

\[Applause\]

0:03

um it's great to be here uh with all of

0:06

you and so great to see the broad range

0:09

of of topics that have been covered

0:11

because it's really more it's so much

0:13

more than just misinformation we often

0:16

think about social media as kind of

0:17

creating the climate change of culture

0:19

and what I hope to do is sort of broaden

0:21

and maybe zoom out a bit on what are the

0:23

collective effects of uh technology and

0:27

Humanity we often start our

0:28

presentations with this quote by eio

0:30

Wilson the Harvard sociobiologist who

0:32

said the real problem of humanity is

0:36

that we have Paleolithic emotions or

0:39

brains medieval

0:42

institutions and Godlike

0:45

technology and it's it's so clear we

## Alignment problem in AI

0:47

repeat it in every presentation because

0:49

I just feel like it it so quickly

0:52

summarizes the feeling that we have that

0:55

our brains are not matched with the way

0:57

that our technology is influencing our

0:59

minds which is what you've been hearing

1:00

about all day today and so often times

1:04

we talk about um the alignment problem

1:06

in in AI right how do we align AI with

1:08

Humanity well how do we align our brains

1:12

with our institutions having a steering

1:14

wheel over something that's Godlike

1:16

that's moving a million times faster

1:17

especially as we have large language

1:19

models as AIS that are going to be

1:21

moving way faster who here is sort of

1:23

feeling the explosive rate of AI moving

1:25

in the world right that's going to

1:27

supercharge so many of the things you've

1:29

been hearing about and what I'll kind of

1:30

talk about today now um many of you here

1:33

have probably seen the social dilemma

1:34

how many people here have actually seen

1:35

the social dilemma okay good maybe a

1:37

good third of you the social dilemma was

1:39

a Netflix documentary I was a part of

1:42

that was actually seen by more than 125

1:44

million people in 190 countries and 30

1:46

languages about the effects that social

1:49

media had on Humanity it was rewiring

1:51

the flows of attention uh and

1:53

information in our society and what we

1:56

actually talk about is that people might

1:58

have missed that was actually first

1:59

Conta

2:00

between humanity and AI people say how

2:02

is AI going to affect Humanity well we

2:04

actually already had an AI that rewired

2:07

and was misaligned with Humanity because

2:08

when you swipe your finger on Tik Tok or

2:10

swipe your finger on Twitter or swipe

2:12

your finger on YouTube You activated a

2:14

supercomputer pointed at your brain to

2:16

calculate based on what three billion

2:18

other Human Social primates have watched

2:20

seen or looked at what is the perfect

2:22

next thing to show you when you swipe

2:25

right that was first

2:27

Contact how did it go

2:31

so in first contact with social media I

2:34

hope you can see these slides here we

2:35

have information overload Doom scrolling

2:37

loneliness crisis the influencer culture

2:39

sexualization of young kids which angle

2:41

makes me look the best uh polarization

2:44

Bots and deep fakes and basically the

2:45

breakdown of our shared reality

2:48

collectively these effects are something

2:50

like the climate change of culture it's

2:51

so much if we just had good information

2:54

in our information environment we would

2:55

still have Doom scrolling um if you just

2:58

had good information or information

2:59

environment You' still have a loneliness

3:01

crisis CU people would be by themselves

3:02

on a screen scrolling by themselves and

3:04

that would affect the belonging dynamics

3:06

that uh har just spoke to and so this is

3:10

really important because as we're about

3:11

to go into second contact with AI with

3:14

large language models we haven't really

3:16

fixed this first misalignment we lost

3:19

how did we lose to this AI how did we

3:23

lose in this first Contact well what

3:25

were the stories we were telling

3:26

ourselves it seems really aligned right

3:28

uh social media is going to connect

3:29

people with their friends we're going to

3:31

give people what they want we're going

3:32

to show people the most personalized ads

3:34

that are relevant to them only the

3:35

things that they would want to buy these

3:37

stories that we were telling ourselves

3:40

are true but that somehow hid what was

3:43

underneath all that which as other

3:45

speakers have talked about today the

3:46

race to maximize engagement because how

3:48

much have you paid for your Tik Tok

3:50

account in the last year how much have

3:52

you paid for your YouTube account in the

3:53

last year how much have you paid for

3:55

your um uh Facebook account in the last

3:57

year zero how are they worth a trillion

3:59

dollars in market cap people say it's

4:02

your data but they're actually selling

4:03

also your attention so how do I get your

4:06

attention you know we add slot machine

4:08

mechanics pull to refresh how many likes

4:10

did I get did I get more this time than

4:11

last time I just checked my email 5

4:13

seconds ago but I'll check it again it's

4:15

not enough just to get your attention if

4:17

I'm a social media company my goal is

4:20

actually to get you addicted to getting

4:22

attention from other people because a

4:24

person who's validation seeking and

4:25

wants attention from other people is

4:27

more profitable than someone who does

4:30

not care about attention from other

4:31

people so how do we do that we add

4:33

beautification filters to uh to it right

4:37

and what we call the raise to the bottom

## Instagram vs TikTok

4:39

of the brain stem if Snapchat adds

4:40

beautification filters Instagram will

4:42

lose if they don't also add

4:43

beautification filters Tik Tok was found

4:46

uh to actually automatically add a

4:48

beautification of like between 1 and 5%

4:51

without even asking people because we're

4:53

all users mirror mirror on the wall

4:55

which makes me look best of all and we

4:57

use that app right now these design

5:00

decisions that again other speakers have

5:02

been talking about all day also led to

5:04

the creation of this because a button

5:07

that instantly retweets reshares um uh

5:10

this content quickly is good at creating

5:13

attention addicts right because now I if

5:17

I Tik Tok is literally competing with

5:19

Instagram if you post this video on

5:20

Instagram and Instagram offers you a

5:23

hundred views on average but if you post

5:24

it on um on Tik Tok you get a thousand

5:27

views on average if you're a teenager

5:29

are you going to post your next video

5:31

Tik Tok Tik Tok the one that gives you

5:33

the more reach so it's a it's a race to

5:35

who can inflate your ego and give you

5:37

the most instant sharing as fast as

5:39

possible and we've all seen the effects

## The Fun House Mirror

5:41

of that fake news spreads six times

5:43

faster than True News and as other

5:44

people have seen this is the study from

5:45

more in common this has led to a massive

5:48

over representation a funhouse mirror of

5:50

the extreme voices to the moderate

5:52

voices with this instant sharing because

5:54

what's the difference between a moderate

5:55

voice on the internet versus an extreme

5:57

voice do extreme voices post more they

6:00

I'll just say they post more often right

6:02

and moderate voices post

6:04

infrequently that's the first layer of

6:06

the double whammy the second is that

6:08

when someone says something extreme it

6:10

goes more viral than when something when

6:12

someone says something more moderate so

6:14

even though there's a very small number

6:15

of very extreme voices out there social

6:18

media takes that like 5% of the

6:20

population and then just spreads it out

6:22

and stretches it out over the whole

6:23

canvas and movie screen of humanity and

6:25

you run Society through that fun house

6:27

mirror for about 10 years and you Qui

6:29

end up in a very distorted uh

6:32

world uh I don't know if you can read

6:33

this um this is a thing that says social

6:36

media summarized elegantly in two tweets

6:38

the top tweet says and I'll just zoom in

6:39

really quickly the much vaunted Pandora

6:41

papers revealed that the Patriotic

6:43

zalinsky was storing payments from his

6:45

top funer Israel eigor Koski in offshore

6:48

accounts and this person was also a

6:49

funer of a Neo-Nazi Battalion and notice

6:52

that that first tweet got 8,000 retweets

6:54

the top the top one now underneath it

6:57

says I was the editor and co-p of that

6:58

story you can look up you've completely

7:00

Twisted it there's no link between this

7:01

money and anything to do with it and

7:03

that got 58

7:05

tweets I really we could all just go

7:08

home because that kind of

7:10

summarizes what the entire information

7:12

environment looks like and if that's the

7:15

asymmetry of power that we have granted

7:17

to every actor in the information

7:19

ecosystem right we have been living in

7:22

this uh funhouse

7:23

mirror and so we got to a world that

7:26

looks like this the climate change of

7:28

culture um and we have another talk out

7:30

there that I highly recommend folks you

7:32

know I have a short amount of time today

7:33

but you should check out this talk we we

7:34

recently gave called the AI dilemma that

7:37

talks about this second contact which

7:38

unfortunately I won't have time to talk

7:40

about

7:40

today so what's the solution to this

7:45

problem well is it content moderation is

7:48

it factchecking is it is information

7:50

true versus false well what about all

7:53

the sort of salaciousness that has

7:54

partial truth that are spun what about

7:56

if we vilify the

7:58

CEOs right

## Complexity vs Institutions

8:00

one of the things that I think we really

8:01

need to get good at is recognizing that

8:03

the complexity of our problems actually

8:05

has exceeded the institutions the

8:07

complexity of our world is going up

8:09

right pandemics what's the right way to

8:11

respond to pandemic what's going on with

8:12

covid nuclear escalation how do we deal

8:14

with energy crises debt crisis fin uh

8:17

GDP to um debt to GDP ratio

8:20

misinformation the complexity of all

8:22

these issues also combinatorically right

8:25

and then Sim simultaneously our ability

8:27

to respond to that complexity but both

8:29

as our brains and our institutions right

8:33

so our paleo brains and our in our

8:34

institutions collectively is represents

8:36

Humanity's ability to respond to the

8:39

complexity of our

8:41

problems but what is Runaway technology

8:43

adding to this well runaway technology

8:45

AI steepens the curve of the complexity

8:47

because if synthetic biology was a

8:49

threat before AI supercharges the threat

8:51

of Sy synthetic biology if

8:52

misinformation was a threat before then

8:54

generative media supercharges the threat

8:57

of gener of of misinformation because

8:59

people people can publish uh just

9:00

yesterday two days ago um the Pentagon

9:02

right was there's a fake image of

9:04

Pentagon being bombed if I wanted to

9:06

cause a bank run in the United States I

9:08

could if I'm Russia or China I could

9:09

easily just create photos of people

9:11

standing in front of L lines of people

9:13

standing in front of Wells Fargo Chase

9:15

Bank Etc I can devalue the US dollar

9:17

like that there's no Department of

9:19

Homeland Security or you know Patriot

9:21

missile defense system that's going to

9:22

stop someone from doing something like

9:24

that and there's a million more examples

9:26

like that by the way and so what the

9:28

reason I'm going here is that I think we

9:29

are often thinking too narrowly about

9:32

how to solve these problems we're

9:33

thinking about content moderation and

9:34

factchecking when really it's about how

9:37

do we have wisdom how do we have the

9:39

bottom line our brains and our

9:41

institutions and our social trust and

9:43

our social fabric actually match the

9:46

speed and complexity of the of the

9:48

evolutionary curve of technology and our

9:50

issues think of it this way if your

9:52

immune system has a slower evolutionary

9:54

Pace than a virus has a fast

9:56

evolutionary pace which is going to win

9:57

your immune system or the virus virus

9:59

virus our immune system are our

10:01

institutions our governance our

10:03

regulation and that's why we have to

10:05

upgrade those

10:07

institutions what this means is that the

10:09

sense making and choic making of

10:10

humanity in terms of both individually

10:13

uh and in terms of our regulation in

10:14

terms of how our institutions act has to

10:16

match the complexity of the world and I

10:19

I wanted to reframe what we're here to

10:21

do which is to also say in addition to

10:22

dealing with the information ecosystem

10:24

we need an information ecosystem that is

10:26

I think collapsing these lines together

10:28

with the quality of our sense Mak and

10:29

choice making matches the complexity of

10:31

choices that we face and one way maybe

## Embrace our Paleolithic brains

10:34

of saying that to go back to EO Wilson

10:37

is that we need to embrace our

10:40

Paleolithic brains upgrade our medieval

10:43

institutions and bind the race dynamics

10:46

of the Godlike technology and just to

10:49

give some subtle examples of this what

10:52

do we mean by embrace our paleo brains

10:54

you've been hearing from people today

10:55

talking about confirmation bias giz M's

10:58

talk about um uh the social rewards that

11:01

we get belonging that is embracing what

11:03

it means to be human you know our name

11:05

the center for Humane technology is

11:07

named as such because my co-founder

11:09

aaras and his father was the inventor of

11:11

the Macintosh project at Apple he wrote

11:13

a book called The Humane interface and

11:15

the word Humane means having an honest

11:17

reflected view in the mirror of how does

11:19

our brains really work that's how he

11:21

came up with and was conceiving of the

11:23

Macintosh because the Macintosh

11:24

different than the personal computer

11:25

with a blinking green cursor and a

11:27

command line interface was a very non

11:29

ergonomic way to match our brains but

11:31

the Macintosh with The Mouse and the

11:33

menu bar and drag and drop and icons was

11:35

a much more Humane interface because it

11:38

embraced how we really work on the

11:39

inside but now what we need to do is

11:42

apply those kinds of insights to um our

11:45

brains have confirmation bias we need to

11:47

feel belonging rather than loneliness so

11:50

how would technology Embrace these

11:52

aspects of what it means to be human and

11:54

design in a richer way if we were to get

11:56

rid of the engagement based business

11:58

models that sell are advertising when

12:00

you open up Facebook Facebook could be

12:02

ranked instead of which content should I

12:03

show you it could be ranked in terms of

12:05

what are things that I can do with

12:06

different communities around me in in my

12:08

physical environment they could be

12:10

supercharging the reinstantiate and the

12:13

reflowering of the social fabric instead

12:15

of showcasing virtual Facebook groups

12:17

they could be showcasing actual physical

12:19

communities that people could spend time

12:21

with each other because as many people

## Upgrading our medieval institutions

12:22

have found out when you spend physical

12:23

time with people face to face it

12:25

automatically has healing properties

12:26

right ter building trust building

12:28

connection upgrading our medieval

12:30

institutions one of the limits of our

12:32

institutions right now is they deal with

12:34

acute harms discreet harms right this

12:37

product hurt this person but it doesn't

12:40

deal with diffuse chronic um and

12:43

long-term cumulative harms think climate

12:46

change think forever chemicals in our

12:48

atmosphere think climate change of

12:50

culture Slow Rolling increases in mental

12:52

health issues uh addiction loneliness

12:54

Etc in society we need institutions that

12:57

deal with those long-term cumulative

12:58

diffus issues rather than just the acute

13:01

issues liability for example is

13:02

something that we need for AI companies

13:04

that's coming down the pipe but

13:05

liability only deals with an acute issue

13:07

like someone died while using a car or

13:09

you know using a product and in terms of

13:11

binding our god-like technology we need

13:14

to actually recognize when there's a

13:15

race if I don't do it I lose to the guy

13:17

that will right if I don't uh use social

13:20

media for my nonprofit to try to boost

13:22

up my influence I'll just lose to the

13:24

other nonprofits that boost up their

13:26

influence with social media so it

13:27

becomes a race to create this virtual

13:29

ual amount of influence on online um if

13:32

I don't deploy open AI to as many people

13:34

as possible and deploy AI into Snapchat

13:37

because now every kid on Snapchat has a

13:39

my AI bot at the top a friend who will

13:41

always always answer your questions um

13:43

and will always be there when their

13:44

other friends go to bed at 10 p.m.

13:46

Snapchat is going to win if they do that

13:48

versus the other companies that don't so

13:50

as we are deploying this god-like

13:52

technology we need to actually recognize

13:54

not be upset at bad guys bad CEOs but

13:57

get upset at bad games bad races and

14:00

that would be another form of upgrading

14:01

our institutions and just to sort of

14:04

close a quote that we reference all the

14:06

time is that you cannot have the power

14:09

of gods without the wisdom love and

14:11

Prudence of gods if you have more power

14:14

than you have wisdom or

14:16

responsibility that by definition means

14:18

you are going to be creating effects in

14:21

society that you can't see because you

14:22

have more power then you have awareness

14:24

of what those effects are think of it as

14:26

you know people are now in um aware of

14:28

things like a a bios safety level four

14:31

laboratory uh from the Wu Wuhan

14:33

Institute of orology if you have bios

14:35

safety level four capabilities where

14:37

you're developing pathogens you need

14:38

bios safety level four safety practices

14:41

as we're developing AI we are now

14:42

inventing bios safety level 10 level

14:45

capabilities but we haven't even

14:47

invented what biosafety level 10

14:50

practices would need to be and one of

14:52

the hardest things I think humanity is

14:53

going to have to do in looking in the

14:54

mirror is thinking about how do we bind

14:57

and limit the power that we're handing

14:58

out out to the appropriate level of

15:00

wisdom and responsibility the biggest

15:02

mistake we made with social media is

15:04

handing out Godlike powers of instant

15:05

re-sharing to everyone which can be very

15:08

helpful in certain cases but it's

15:10

helpful specifically because it's bound

15:12

to wisdom when it's when it's going well

15:14

and when it's not going well it's

15:15

because that power is not bound to

15:17

wisdom so those are some thoughts I

15:18

wanted to uh leave you with today thank

15:19

you very much