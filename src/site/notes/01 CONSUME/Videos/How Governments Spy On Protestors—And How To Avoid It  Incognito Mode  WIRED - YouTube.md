---
{"dg-publish":true,"permalink":"/01-consume/videos/how-governments-spy-on-protestors-and-how-to-avoid-it-incognito-mode-wired-you-tube/","title":"How Governments Spy On Protestors—And How To Avoid It | Incognito Mode | WIRED - YouTube"}
---

# How Governments Spy On Protestors—And How To Avoid It  Incognito Mode  WIRED - YouTube

![How Governments Spy On Protestors—And How To Avoid It | Incognito Mode | WIRED - YouTube](https://www.youtube.com/watch?v=lL34WpoETds?list=WL)

## Description

Law enforcement’s ability to track and profile political protestors has become increasingly multifaceted and technology driven. In this edition of Incognito Mode WIRED Senior Editor, Security & Investigations Andrew Couts and WIRED Senior Writer Lily Hay Newman discuss the technologies used by law enforcement that put citizens' privacy at risk—and how to avoid them.

Shop for products discussed in this episode of Incognito Mode:
Silent Pocket SLNT Faraday Waterproof Backpack: https://amzn.to/42ePTOg
Visit the SLNT Storefront: https://amzn.to/4cA8ub9

_When you buy something through our affiliate links, we earn a commission_

0:00 How Governments Spy On Protestors
0:44 facial recognition
5:31 social media
9:24 IMSI catchers
12:17 geofencing
13:40 data brokers
16:46 license plate readers
18:33 drones
20:10 emerging tech
23:23 how to protect yourself

Director: Efrat Kashai
Director of Photography: Brad Wickham
Editor: Matthew Colby
Host: Andrew Couts
Guest: Lily Newman
Line Producer: Joseph Buscemi
Associate Producer: Paul Gulyas
Production Manager: Peter Brunette
Production Coordinator: Rhyan Lark
Camera Operator: Mar Alfonso
Gaffer: Niklas Moller
Sound Mixer: Sean Paulsen
Production Assistant: Malaia Simms
Post Production Supervisor: Christian Olguin
Supervising Editor: Erica DeLeo
Assistant Editor: Justin Symonds

Still haven’t subscribed to WIRED on YouTube? ►► http://wrd.cm/15fP7B7 
Listen to the Get WIRED podcast  ►► https://link.chtbl.com/wired-ytc-desc
Want more WIRED? Get the magazine ►► https://subscribe.wired.com/subscribe/splits/wired/WIR_YouTube?source=EDT_WIR_YouTube_0_Video_Description_ZZ

Follow WIRED:
Instagram ►►https://instagram.com/wired
Twitter ►►http://www.twitter.com/wired
Facebook ►►https://www.facebook.com/wired
Tik Tok  ►►https://www.tiktok.com/@wired

Get more incredible stories on science and tech with our daily newsletter: https://wrd.cm/DailyYT

Also, check out the free WIRED channel on Roku, Apple TV, Amazon Fire TV, and Android TV. 

ABOUT WIRED
WIRED is where tomorrow is realized. Through thought-provoking stories and videos, WIRED explores the future of business, innovation, and culture.

## Notes

## Transcript

## How Governments Spy On Protestors

0:00

\- Protests, almost by definition, are points of contention

0:02

between citizens and their governments.

0:04

\[subdued music\]

0:06

Police tracking of protestors is multifaceted

0:08

and includes a variety of tactics

0:09

and gear that generate different data.

0:11

Some surveillance is done at the protests,

0:13

while other methods are used outside of it.

0:15

\- It's just like all different ways

0:17

to get at this core thing of who was there,

0:21

what are they up to, what do they think about things?

0:24

I think that's sort of how I break it down

0:26

because so many of these technologies

0:28

are unseen or not intuitive.

0:31

\- In this episode,

0:32

we'll discuss the technologies used by law enforcement

0:34

that put citizens' privacy at risk.

0:36

This is "Incognito Mode."

0:38

\[moody music\]

## facial recognition

0:44

\- The movies were way ahead on this, right?

0:46

Like they were depicting, it's like the yellow box

0:49

that goes around the face type of thing.

0:52

Now, that is very real.

0:54

This technology is more and more available

0:57

to law enforcement.

0:58

\- Although law enforcement have had access

1:00

to facial recognition tools for about 20 years,

1:02

they previously were only able

1:04

to search government images such as mugshots.

1:06

This changed in 2018 when many police departments

1:09

started using Clearview AI, a facial recognition app

1:12

that allows them to match photos from around the web.

1:14

Once a photo is uploaded,

1:15

the app pulls up matches found online

1:17

along with links to the source of those photos.

1:19

\- \[Newsreader\[ Clearview says more

1:20

than 600 law enforcement agencies across the country

1:24

use this software.

1:26

\- Based on the person's facial geometry,

1:28

the images are converted by the system

1:29

into a formula measuring things like eye distance.

1:32

This means that law enforcement can use any image

1:34

to search for a person

1:35

who doesn't currently have a police record

1:37

and isn't known to authorities,

1:38

and potentially identify them in seconds.

1:41

\- I wanted to ask you, since you've covered this a lot,

1:44

how do you view the risk of these platforms

1:47

as they proliferate?

1:49

\- To be quite frank, it freaks me the hell out.

1:51

Image recognition is just really, really good now

1:54

and cheaper to deploy

1:56

and so you know, I think it's more just kind of accepting

1:59

that this is just part of life.

2:01

Like just commuting every day,

2:02

you're probably being subjected

2:03

to some of these systems in one form or another.

2:06

It's not just the systems where you have face rec built in.

2:08

It can be deployed after the fact

2:10

if you're in people's pictures

2:11

that are posted on social media,

2:13

it can get uploaded to these systems

2:14

and then you can get picked out of a crowd in that way.

2:16

\- \[Rioters\] USA! USA!

2:18

\- We saw that with, you know,

2:19

the January 6th Insurrection videos

2:22

that were posted to Parler and other social media platforms.

2:25

\- \[Newsreader\] News tonight, an Auburn man

2:27

has been found guilty of federal charges

2:28

for his actions during the January 6th insurrection.

2:31

\- You know, the FBI took those,

2:32

they saw people in the videos,

2:34

they went back and and kind of looked to see

2:35

like, "Okay, here's proof you were there."

2:37

Governments in 78 countries

2:39

use public facial recognition systems

2:41

with varying degrees of support from their citizens.

2:44

Many countries use the technology

2:45

without transparent regulations.

2:47

In Russia, facial recognition tools have been used

2:49

not only to detain people protesting the war in Ukraine,

2:52

but also to identify and arrest opponents of the government

2:55

before they joined any demonstrations.

2:57

Reuters reported that the facial recognition systems

3:00

used in Moscow are powered by Western companies

3:03

including NVIDIA and Intel.

3:05

Other companies such as Amazon have also launched software

3:08

that allows users to build a facial recognition database

3:11

using their own photos.

3:12

These systems, they're everywhere

3:14

and things that you might think

3:15

could kind of thwart these systems,

3:17

even like wearing a mask and these kinds of things,

3:19

some of the technologies can get around that.

3:21

I don't know what to do with that information to be honest.

3:24

\- There are a lot of police here. Are you not frightened?

3:28

\- We are, but you know, we are together.

3:30

That gives a real power.

3:33

\- I am frightened. Of course I'm frightened.

3:35

That's why I'm just covering up all my face

3:37

just so that they cannot even, you know, find my ID,

3:40

but me being afraid doesn't mean

3:43

that I'm not going to be here today and fight for my future.

3:46

\- I agree 100% with what you were saying

3:48

about how masks and other deterrent measures

3:53

aren't always effective

3:54

at defeating these identification technologies.

3:57

But clearly they are at least somewhat effective sometimes

4:03

because you know, in a lot of crackdowns

4:06

we've seen in the last few years by multiple governments,

4:08

like one thing they'll do

4:10

is try to ban mask wearing in certain settings.

4:13

Yeah, are there any other things,

4:15

please tell me that you have more.

4:17

\- Yeah, I mean I think there are ways to minimize the data

4:22

and thus minimize the risks.

4:24

Just simple things like not shooting pictures

4:27

and videos while you're at a protest

4:29

so you're not capturing yourself

4:30

and anybody else who's around you

4:32

is one way to keep it out of some types of systems.

4:35

Avoiding some systems is better than avoiding no systems.

4:38

You are going to be subjected to this technology

4:41

in one way or the other

4:42

and you just kind of have to proceed as best you can

4:46

and minimize your contributions to those systems

4:49

as much as as possible.

4:51

\- CCTVs or security cameras

4:54

have been ubiquitous for a few decades now.

4:58

One could have thought 20 or 30 years ago,

5:01

like, "Well now everything is going

5:02

to be captured on film all the time."

5:05

But there are limitations still

5:08

to just how much data is stored, for how long.

5:12

You know, there've been a lot of high-profile events

5:15

around the world in recent years

5:17

where there wasn't adequate security footage

5:20

to really know what had happened.

5:22

It's not like every step you take,

5:24

someone is paying to run the system

5:27

and store the data to identify you.

5:30

\[subdued music\]

## social media

5:32

\- In 2010, "Wired" reported on federal agents

5:35

friending crime suspects on sites like MySpace

5:37

in order to see their photos, communications,

5:39

and personal relationships.

5:41

More recently, police have used companies like Dataminr

5:44

to more easily sift through massive amounts of data

5:46

in order to glean information

5:47

about how protests are organized,

5:49

to identify activists,

5:51

and to piece together people's connections to each other.

5:53

\- So social media accounts, right?

5:56

It's a lot of data on everyone who's using these platforms.

6:00

But I kind of think of these surveillance technologies

6:04

in two buckets.

6:06

One would be if authorities want

6:09

to find out more about a specific person, right?

6:14

What has Andrew been posting about or saying

6:18

and are there photos you know, of Andrew online?

6:22

Things like that.

6:23

But then the other one would be coming at it the flipped

6:27

where it's like they're looking

6:28

for anyone who has been talking about X thing,

6:33

or you know, anyone marking their location

6:36

in a certain place on a certain day.

6:38

Authorities can go directly to the sites

6:41

or they might wanna use a service

6:44

that kind of pulls a ton of data

6:46

from social platforms together, you know,

6:49

aggregates all of it and getting kind of lists of names.

6:52

It gives the ability to like have this vibe check.

6:56

Like those platforms themselves

6:58

aren't inherently a surveillance tool, right?

7:01

Sometimes we use them for journalism.

7:03

\- I've used some of these services like Dataminr before

7:05

and once you see just the fire hose of information

7:08

that you can get access to when you use it,

7:10

it's becomes clear just how easy it is

7:13

to kind of figure out what is going on.

7:14

Even if it's not obvious to you

7:16

in your own like curated timeline.

7:19

Just the use of them has become more widespread.

7:21

You wouldn't know without doing some investigating,

7:24

"Definitely my local police department

7:25

is using this or not."

7:26

That creates an environment

7:28

where you have to assume that that's what's happening.

7:29

\- Steps like making your account private

7:33

or setting something to expire quickly.

7:36

Maybe they can help.

7:37

But I wouldn't assume those types of settings

7:41

can really truly protect data on big mainstream platforms.

7:47

\- An example of how social media surveillance was used

7:49

can be found through the MPD surveillance

7:51

of the George Floyd protests in 2020.

7:53

It was found that the MPD collected data

7:55

about protest events including dates, locations, organizers,

7:59

and estimated crowd sizes.

8:00

The MPD shared this information with the Secret Service,

8:03

National Park Service, and the Department of Defense.

8:06

\- So I think the other huge advice

8:09

is about data minimization

8:11

and not posting about things

8:15

that you worry about getting into other people's hands.

8:20

There's a tension here with chilling speech, right?

8:23

The nature of the internet is to share information, right?

8:25

That's like the whole purpose of the platform.

8:27

When you put stuff out there, it's hard to say like,

8:31

"Okay, it's out there

8:32

but only for certain people," and control it.

8:35

\- Our perspective on it is probably a little bit different

8:37

because we're journalists,

8:38

we're kind of in the public eye

8:39

in a way that some other people aren't,

8:41

but I think anybody,

8:42

no matter if you have one follower or a million,

8:45

you should be really careful

8:47

about what you post online and when you post it online.

8:50

You know, if you're gonna post vacation pictures,

8:52

I never post them while I'm actually on vacation.

8:55

Because then that signal to somebody like,

8:56

"Hey, my house is empty."

8:57

You can apply that to all different types of risks

9:00

and I think generally posting less is the way to go.

9:03

\- But also some people really wanna post

9:06

or that's their like job,

9:08

or you know, that's how they make money.

9:10

It's just helpful to understand

9:12

that the greater volume you're posting,

9:15

the more there could be things you didn't think of

9:18

that's exposing information

9:20

that you didn't realize is now out there.

9:23

\[subdued music\]

## IMSI catchers

9:25

\- IMSI catchers, also known as cell site simulators

9:27

and formerly referred to as StingRays,

9:29

are devices that impersonate cell towers

9:31

causing cell phones within a certain radius

9:33

to connect to them.

9:34

Initially designed for military

9:35

and national security purposes,

9:37

this technology has emerged in routine police use.

9:40

Until recently, the use of IMSI catchers

9:42

was withheld from the public.

9:43

The FBI has even forced state and local police agencies

9:46

to sign NDAs in order to use their devices.

9:48

I mean, I find IMSI catchers fascinating

9:51

just in that their use is really secretive,

9:54

like there was a long time

9:55

that police weren't allowed to say that they had them

9:57

or that they were using them,

9:58

so there's just- - And no one had seen one.

10:01

\- Right. Yeah, exactly.

10:02

Can you tell us just a little bit about how that works?

10:05

\- These are devices that, at its core,

10:08

just identify that your phone

10:11

was physically in a certain location,

10:13

like that's the baseline thing it's trying to achieve.

10:16

Sometimes called an IMSI catcher

10:17

because of this IMSI number that it's trying to pick up.

10:22

They can work in different ways,

10:23

they can work passively to just sort of sweep around

10:26

and say what devices are in the area

10:28

and let me try to, you know, decrypt their signal

10:31

and catch that you know, an ID number.

10:33

More often, they work actively as like a fake cell tower,

10:39

taking advantage of the way the system works,

10:42

that your phone is going to connect to the cell tower

10:45

that's emitting the strongest signal in the area

10:48

to give you the best service and then grab that ID number.

10:52

Sometimes they can also

10:56

potentially grab other stuff

10:58

like unencrypted communications, like SMS text messages.

11:02

It's important to know that one of the things

11:05

that can happen when you bring a phone

11:07

to an event like a protest

11:09

is that the fact that you were there

11:11

and potentially some other information

11:14

could be sort of pulled out of the air

11:16

by one of these devices.

11:17

\- Records show that IMSI catchers are used

11:19

by 23 states and the District of Columbia,

11:21

the DEA, ICE, FBI, NSA, and DHS,

11:25

along with many additional agencies.

11:27

In terms of how people gauge the risk of these,

11:30

I mean for one thing, like you said,

11:32

a lot of times they're looking

11:34

to target one person or maybe a couple of people

11:37

and it does end up looping in a lot of people

11:40

just by the nature of how it works.

11:41

But it's also one that I think

11:43

is expensive and complicated to deploy

11:45

and so it's probably not gonna be the top concern.

11:48

If I were going to a protest,

11:49

I don't think it's the thing I would be so concerned about,

11:52

just as an average person.

11:54

\- Another thing in that vein,

11:56

you know, if this technology that we're talking about

11:59

is rogue cell towers,

12:00

it means that actual cell towers

12:03

also have all this information, right?

12:04

Like your wireless provider knows where you go.

12:08

So that data exists anyway

12:10

and there are potentially other ways

12:12

that, you know, authorities can get that information.

12:15

\[brooding music\]

## geofencing

12:18

\- Geofence warrants, or reverse location warrants,

12:21

allow law enforcement to request location data from apps

12:24

or tech companies like Google or Apple

12:26

for all devices in a specific area during a set time.

12:29

Authorities can then track locations,

12:31

identify users and collect additional data

12:33

like social media accounts.

12:34

\- This is yet another layer in this multiple approaches

12:40

to getting the same information:

12:42

who was at a certain place at a certain time

12:45

and what can we find out about what they were up to?

12:48

\- A lot of it's advertising data

12:50

or what's being shared all the time from your device

12:52

that you probably aren't paying much attention to

12:54

and is used in a much more innocuous way typically.

12:57

\- And it's sort of slurping up all the data from this area,

13:01

which is constrained in a way

13:03

but doesn't account for passersby,

13:07

people, you know, getting coffee at the deli next door,

13:10

people just sort of coming up to a location

13:14

to see what's going on.

13:15

Like this is just bulk indiscriminate data.

13:19

I am worried about it, but maybe not specifically.

13:21

Like it's in the category to me of all the reasons

13:25

that I might consider leaving a device at home

13:28

or putting it in a Faraday bag.

13:30

It's sort of just on that list of reasons

13:33

that you might wanna minimize the data

13:36

that your device is emitting.

13:38

\[subdued music\]

## data brokers

13:41

\- Data brokers collect and sell personal data

13:43

from public sources, websites,

13:45

and apps people use every day.

13:47

They aggregate all this info

13:48

to build detailed profiles of people

13:50

and to group them into simplified categories

13:51

such as high income, new moms, pet owners,

13:54

impulse buyers, and more.

13:55

While advertisers are usually their primary clients,

13:58

police can also purchase this data.

14:00

Some of the largest data broker companies

14:01

include Experian, Acxiom, and Equifax.

14:04

The amount of data Equifax collected came to light

14:07

in 2017 when a data breach

14:08

exposed 147 million people's personal data.

14:11

\- I think it just fuels this ability

14:15

to identify someone

14:17

and track kind of their behavior across the web

14:21

and potentially their speech.

14:23

Similar to the way law enforcement can track people

14:26

and surveil people through social media platforms,

14:29

information from data brokers

14:31

can aid investigations in two ways.

14:34

They can be coming at it from a person of interest

14:37

who they're trying to find out more about

14:39

or authorities can be coming at it from,

14:42

"I want information on anyone

14:45

who has had an IP address in this area

14:48

or anyone who has keyword searched, you know,

14:53

and been shown these types of ads."

14:55

\- So how do data brokers collect information?

14:57

The most common ways include web browsing history,

15:00

everything from your Google searches,

15:01

sites or apps you visit, cookies, social media activity,

15:04

or even a quiz you just filled out for fun.

15:06

All of that can be scraped and tracked.

15:08

This data creates each person's online history map,

15:10

which in turn allows brokers

15:11

to build a profile on each user.

15:13

The data that companies collect often include:

15:15

name, address, phone number and email address,

15:17

date of birth, gender, marital and family status,

15:20

social security number, education, profession,

15:23

income level, cars and real estate you own.

15:25

It also comes from public sources.

15:26

This can be anything in the public domain

15:28

such as: birth certificates, drivers or marriage licenses,

15:31

court or bankruptcy records,

15:33

DMV records and voter registration information.

15:35

It can also include commercial sources

15:37

such as: your purchase history, loyalty cards,

15:40

coupon use, and so forth.

15:41

And finally, some websites or programs will ask

15:44

for your consent to share your data.

15:45

Sometimes it's anonymized in certain ways,

15:48

especially when it comes to advertising data,

15:50

but it's pretty trivial for law enforcement

15:53

or other investigators to tie certain advertising behavior

15:57

to a specific device,

15:58

especially if it's collecting precise location data

16:01

and there's also data brokers

16:03

that are building network profiles

16:04

so you can not just get information about yourself,

16:07

but everybody you've interacted with,

16:09

whether it's on social media or actually in real life.

16:11

In the United States at least,

16:13

we just lack laws that kind of regulate

16:15

what these companies are able to collect.

16:18

And if you have to participate in modern society,

16:21

as nearly everyone does,

16:24

it's almost impossible to avoid.

16:25

I think in the context of protests,

16:27

it's not an acute concern I would say,

16:30

but it is generally speaking really freaky

16:33

when the sky's the limit on what they could potentially use

16:36

because there's just so much data.

16:38

\- I agree with what you said,

16:39

sort of low on the acute scale,

16:41

but high on the existential scale.

16:43

\[subdued music\]

## license plate readers

16:46

\- One of the big surveillance technologies

16:48

that probably everyone who's driven on a highway knows about

16:51

is license plate readers.

16:52

Really just capturing what your license plate is

16:55

and showing that your vehicle was

16:57

at a certain place at a certain time.

16:59

\- Similar to like your phone,

17:00

your car, it's a proxy for you.

17:03

Maybe you were in the car, maybe you weren't,

17:06

but that's where your car went.

17:07

\- There are three types of ALPR systems:

17:10

stationary or fixed ALPR cameras,

17:12

which are installed in a fixed location

17:14

like a traffic light, telephone pole or a freeway exit ramp.

17:17

The second type are mobile ALPR cameras,

17:20

which are attached to police patrol cars,

17:22

garbage trucks, and other vehicles,

17:24

and allow them to capture data from license plates

17:26

as they drive around the city.

17:27

They can also assist law enforcement in gridding,

17:29

which is when police officers

17:31

drive up and down a neighborhood

17:32

collecting license plates of all parked cars.

17:34

There are also private vendors like Vigilant Solutions,

17:37

which collect license plate data

17:39

and sell that back to police.

17:40

The third type are ALPR trailers,

17:42

which are trailers police can tow to a particular area

17:45

and leave for extended periods of time.

17:47

It's been reported that the DE has disguised ALPR trailers

17:50

as speed enforcement vehicles

17:52

and placed them along the US-Mexico border.

17:54

The things I'm concerned about aren't necessarily even

17:57

it being used for license plates.

17:59

Our colleague, Dhruv Mehrotra has done some reporting

18:01

showing that license plates readers

18:03

can also capture any words that are visible,

18:06

so that can be what's on your t-shirt,

18:07

that could be political signs in your yard.

18:10

This technology may be able to be used

18:12

in ways that we're not even familiar with or would imagine.

18:15

You know, a lot of times when we're talking about

18:17

any surveillance technologies,

18:19

it's really about creating data that then is there

18:23

and could potentially be used

18:24

in any number of ways at any point in the future

18:27

depending on who gets access to it

18:29

and what they want to do with it.

18:30

\[moody music\]

## drones

18:33

\- The key thing here is that these drones,

18:36

even small quadcopters,

18:38

like what we think of as consumer drones,

18:39

they can carry a fair amount of cargo, meaning like cameras.

18:45

\- There are a number of different drones

18:46

used by law enforcement varying in size and ability.

18:49

For example, some drones have thermal imaging capabilities

18:52

for night operations

18:53

while others specialize in long periods of surveillance.

18:56

Protestors have in the past reported drones flying overhead,

18:58

for example in Minneapolis during the George Floyd protests.

19:01

Police and government drones usually fly

19:03

in the range of 11,200 feet above the ground.

19:06

However, it's been reported that the drone used

19:08

to surveil protests in Minneapolis in 2020

19:10

flew at 20,000 feet,

19:12

nearly invisible to protestors on the ground.

19:14

This was a Customs and Border Protection drone,

19:16

which are often equipped with advanced cameras, radar,

19:19

and potential cell phone geolocation tools.

19:22

In terms of how freaked out are you about drones,

19:24

how do you think about that?

19:25

\- Yeah, I would say fairly freaked out.

19:28

But again, like you were saying

19:29

about the layering of these technologies,

19:31

I think it's not the drones themselves,

19:35

it's everything they can do and how cheap they are

19:39

and how easy it would be to deploy even more of this tech.

19:44

When we talk about sort of evolution

19:46

of different technologies,

19:47

this capability is sort of similar to police helicopters

19:52

and now it's just cheaper, lighter, easier.

19:56

Even these sort of benign-seeming quadcopters

19:59

that we see around all the time

20:01

could be carrying equipment on them

20:03

to do like very granular, detailed surveillance

20:06

of something like a protest.

20:08

\[subdued music\]

## emerging tech

20:10

\- There are some technologies that are really just emerging

20:13

and we don't even know if they've been used at protests

20:15

or even used by authorities in the United States.

20:18

\- Right, and your face isn't the only thing

20:20

sort of outside your body that can potentially identify you.

20:25

For example, analyzing your gait, like how you walk.

20:28

\- Gait recognition technology can identify individuals

20:31

by analyzing their unique walking patterns

20:33

using machine learning.

20:34

It captures movements

20:35

through cameras, motion sensors, or even radar.

20:38

It then processes this information,

20:40

breaking it down into contours, silhouettes,

20:42

and other distinguishing features.

20:44

It offers high accuracy,

20:46

but its effectiveness can be influenced

20:47

by things like injuries

20:48

or the types of terrain the subject is traversing.

20:51

This tech is especially useful for authorities

20:53

when people's faces are obscured.

20:55

While there haven't been any reports

20:56

of widespread use of this tech

20:57

by law enforcement agencies in the US,

21:00

Chinese authorities have been utilizing it

21:01

on the streets of Shanghai and Beijing since at least 2018.

21:05

In recent years, there have also been a number of companies

21:07

working on creating emotional detection technology

21:10

where AI uses biometric data

21:12

to determine a person's emotional state

21:13

and the likelihood they will become violent

21:15

or cause a disturbance.

21:17

"Wired" reporting found that Amazon-powered cameras

21:19

have been scanning passengers faces

21:21

in eight train stations in the UK

21:23

to trial this new technology.

21:24

The trials were testing the system

21:26

for age and gender recognition

21:27

as well as the emotional state of the person on camera.

21:30

While there's no current documentation

21:31

of this tech being used at protests,

21:33

the BBC reported that emotional-detection tech

21:36

has been used on Uyghurs in China.

21:37

\- Some of these could be really invasive

21:39

because you know, reading your emotions,

21:42

there start to be maybe inferences

21:45

that someone could make

21:46

about how you were feeling in a certain moment

21:48

that may or may not be accurate, right?

21:50

Because it's sort of being taken out of context.

21:53

So it's difficult to have an algorithm

21:55

just sort of come to one conclusion.

21:58

Like sometimes I think you're doing your angry walk

22:02

coming over when I haven't filed my story,

22:05

but really then you're really nice about it

22:07

and you're like, "It's okay Lily, you can do it."

22:09

And you know, I took it totally the wrong way.

22:12

But potentially there are more sort of

22:16

in terms of just identifying someone in a certain place.

22:19

It is scary that there's something characteristic

22:22

about your walk.

22:23

They're not saying, "Oh, it's Andrew's angry walk,"

22:26

but they're saying, "Oh, that's Andrew."

22:27

\- Certainly creating more systems that are replicating

22:32

what other things like facial recognition do

22:35

and applying it in to other biometrics of a person.

22:38

That definitely is gonna create all the same concerns

22:41

as we've seen with these other technologies

22:43

that were emerging, you know, years or decades ago.

22:46

But now it's your entire body, how you walk,

22:48

and like you mentioned,

22:49

like if we're having computers analyze

22:51

like how I'm feeling in a certain moment,

22:54

effectively establishing intent

22:56

of whatever my actions are in that moment,

22:59

that gets really scary

23:00

because it might be completely inaccurate.

23:02

Every time there's one of these new AI technologies,

23:04

there's always some bias built in.

23:06

There are gonna be people

23:06

who suffer consequences unnecessarily

23:09

because these systems are deployed

23:10

without being fully debugged.

23:12

Experts in the AI field have previously noted

23:14

that emotional-detection tech is unreliable, immature,

23:18

and some even call for the technology

23:19

to be banned altogether.

23:21

\[subdued music\]

## how to protect yourself

23:23

Here are a few simple and effective ways

23:25

to protect yourself and your personal information

23:27

at a protest.

23:28

First, if you can, leave your phone at home,

23:30

I know this might sound drastic,

23:31

but the most effective way

23:32

to ensure that your personal data isn't compromised

23:35

and that your phone won't fall

23:36

in the hands of law enforcement

23:37

is by not having it with you.

23:39

If that's not an option,

23:40

you can put your phone in a Faraday bag

23:41

so data can't be accessed.

23:43

You should also turn off biometrics on your

23:45

like facial recognition or fingerprint scanner,

23:47

meaning you'll need a code to access it.

23:49

That way your face or fingerprints

23:50

can't be forcefully used

23:51

to access your personal information.

23:53

You can always say, "You just don't remember the code.

23:55

Don't unlock it."

23:56

Another thing to keep in mind is posting on social media.

23:58

Jay Stanley, a senior policy analyst at the ACLU says,

24:01

"if you post something online,

24:02

you should do so under the assumption

24:04

that it might be viewed by law enforcement."

24:05

You should always check your sharing settings

24:07

and make sure you know what posts are public.

24:09

Try to minimize the amount of other people's faces

24:11

you capture in your photos or videos,

24:13

use end-to-end encrypted messaging services

24:15

like Signal when possible,

24:17

wear a mask in case photos or videos are taken,

24:19

and finally, know your personal risks.

24:21

Is your immigration status exposing you

24:23

to additional dangers?

24:24

Are you part of a minority group

24:25

that is more likely to be targeted by law enforcement?

24:28

Keeping these things in mind

24:29

for yourself and your loved ones

24:31

when deciding if you should go out to a protest.

24:33

For more information about surveillance at protests,

24:35

check out wired.com.

24:37

This was "Incognito Mode." Until next time.

24:39

\[otherwordly music\]