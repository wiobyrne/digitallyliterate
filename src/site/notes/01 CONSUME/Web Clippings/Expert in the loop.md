---
{"dg-publish":true,"permalink":"/01-consume/web-clippings/expert-in-the-loop/","title":"Expert in the loop","tags":["ai","human-in-the-loop","cognition","expertise"]}
---

# Expert in the loop
## Highlights
The importance of having an expert in the loop when using Generative AI
- The idea of AI as a thinking partner, complementing human cognition
- The potential benefits of having AI and humans generate ideas together
- The distinction between 'human in the loop' and 'expert in the loop'
- The need for human oversight to prevent errors introduced by AI

---
A couple of recent occurrences have prodded me to think. (Dangerous, I know!). In this case, generative AI continues to generate;) hype and concern in close to equal measure. Which means it dominates conversations, including one I had recently with Markus Bernhardt. Then, there was a [post](https://simonterry.com/2025/05/23/human-in-the-loop/) by Simon Terry that said something related that doesn’t completely align. So, some thoughts arguing to have an expert in the loop.

First, as a neighbor as well as an AI strategist of [renown](https://www.endeavorintel.com/), I’m grateful Markus and I can regularly converse. (And usually about AI!) His depth and practical experience in guiding organizations complements my long-standing [fascination](https://blog.learnlets.com/2023/11/an-ai-overview/) with AI. One item in particular was of note. We were discussing how you need a person to vet what comes out of Generative AI. And it became clear that it can’t just be *anybody*. It takes someone with expertise in the area to be able to determine if what’s said is true.

That would suggest that the AI is redundant. However, there are [limitations](https://blog.learnlets.com/2015/10/supporting-our-brains/) to our cognition. As I’ve [recounted](https://blog.learnlets.com/2015/04/cyborg-thinking-cognition-context-and-complementation/) numerous times, technology does well what we don’t, and vice-versa. So, we use tools. One of the things we do is unconsciously forget aspects of solutions that we could benefit from. Hence, for instance, checklists. In this case, Generative AI can be a thinking partner in that it can spin up a lot of ideas. (Ignoring, for the moment, issues like intellectual property and environmental costs, of course.) They may not be all good, or even accurate, but…they may be things we hadn’t recalled or even thought of. Which would be a nice complement to our thinking. It requires our expertise, but it’s a plausible role.

Now, Simon was talking about how ‘human in the loop’ perpetuates a view of humans as cogs in a machine. And I get it. I, too, worry about having people riding herd on AI. That is, for instance, AI doing the creative work, and humans taking responsibility. That’s broken. But, having AI as a thinking partner, with a human generating ideas *with* AI, and taking responsibility for the accuracy as well as the creativity, doesn’t seem to be problematic. (And I may be wrong, these are preliminary thoughts!)

Still, I think that just a ‘human in the loop’ could be wrong. Having an expert in the loop, as Markus suggested, may be a more appropriate situation. He pointed out a couple of ways Generative AIs can introduce errors, and it’s a known problem. We have to have a person in the loop, but who? As I recounted [recently](https://blog.learnlets.com/2025/05/locus-of-intelligence/), are we just training the AI? Still, I can see a case being made that this is the right way to use AI. Not as an agent (acting on its own, \*shudder\*), but as a partner. Thoughts?

This site uses Akismet to reduce spam. [Learn how your comment data is processed.](https://akismet.com/privacy/)

![](https://blog.learnlets.com/wp-content/uploads/2018/02/mLearning_backgroundLearnlets.png)





**Suggested tags:**
- Generative AI
- Expertise
- Human-AI collaboration
- Cognitive technology
- Error prevention