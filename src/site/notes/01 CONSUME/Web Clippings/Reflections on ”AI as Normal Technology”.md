---
{"dg-publish":true,"permalink":"/01-consume/web-clippings/reflections-on-ai-as-normal-technology/","title":"Reflections on ”AI as Normal Technology”"}
---

# Reflections on ”AI as Normal Technology”
## Highlights


### List best points from this page
- Key arguments presented in the article
- Notable statistics or data used
- Critical examples or case studies mentioned
- Author's conclusions and recommendations

---
![](https://falkai.org/wp-content/uploads/2025/04/abstrakt-7.webp?w=1024)

*I’m experimenting with a new format in this post. I asked Claude to summarize my notes, being transparent with who is actually writing. I’ve edited the text from Claude slightly, but it is mainly AI-written.*

This post summarizes Johan Falk’s reading notes on the essay [”AI as Normal Technology”](https://knightcolumbia.org/content/ai-as-normal-technology) published by the Knight First Amendment Institute.

For an interview with one of the authors, check out [this episode of Hard Fork](https://play.pocketcasts.com/podcasts/467b49a0-c657-0138-e72e-0acc26574db2/3b2b19f6-2e9c-440b-8907-89794adce194) (some 29 minutes into the episode).

Concerning diffusion of AI technology: This [interview with Michael Webb](https://80000hours.org/podcast/episodes/michael-webb-ai-jobs-labour-market/) from August 2023 is one of my favorite podcast episodes, and still well worth listening to.

## General Thoughts

The essay makes a valuable contribution to the AI risk discussion by providing a well-articulated alternative to the superintelligence narrative. Their conclusions make sense if we assume AI will advance slowly.

Falk questions whether the contrast between ”normal technology” and ”superintelligence” is the right framing. He suggests it’s more about how quickly progress happens and how far it goes. Even if AI levels off at roughly human capabilities, sufficiently rapid societal changes could still make AI a non-normal technology.

What happens if startups and small organizations skilled at using AI outpace larger, established institutions? This could create a ”technological sonic boom” when the gap between cutting-edge and widely-used AI capabilities grows too large. If schools adopt AI too slowly, will kids turn to DuoLingo for language learning? If democratic institutions lag behind, will social media partially replace them?

## On Technology Adoption

While the original essay argues that AI adoption will be slow, particularly in safety-critical areas, Falk worries that competitive pressures might force faster adoption even in high-risk domains. The Trump administration’s anti-regulatory stance on AI could enable less cautious deployment.

Another factor pointing toward faster AI adoption is that new AI models can seamlessly replace old ones. Given the rapid advancements in LLM capabilities, this is significant.

Falk notes that AI can bypass many factors that typically slow down technology diffusion:

- Upfront costs are paid by AI labs
- Infrastructure for using AI is already in place
- Starting to use the technology is very easy

However, the explosive adoption rates seen after ChatGPT’s release were focused on one product. Other AI tools haven’t seen nearly the same adoption rates.

## On AI Capabilities

Falk disagrees with the essay’s assessment of AI progress. While the authors suggest a measured pace, Falk believes we’re in a rapidly evolving phase of AI advancement, particularly with reasoning models. He finds it likely that the exponential trend in AI progress will continue for several more years.

Falk appreciates how the authors question terms like ”intelligence” and ”superintelligence,” and their useful distinction between capabilities and power. However, he notes this distinction breaks down when malicious or careless users access unrestrained AI models.

## On Human vs. AI Performance

Contrary to the essay’s position that superhuman speed is only useful in a few tasks, Falk argues there are many situations where AI’s ability to process vast information would be valuable. If an AI can review all relevant literature or analyze all stakeholder preferences, it would help in many scenarios.

Falk believes humans make many avoidable mistakes, challenging the essay’s view that human performance is near the limit of what’s possible due to inherent randomness. He particularly disagrees that AI won’t substantially outperform humans in forecasting geopolitical events or persuasion, noting we may already see evidence of the latter in limited contexts.

## On Control and Policy

Falk has less faith in market forces to ensure AI safety than the essay’s authors, noting that companies often externalize costs related to accidents and poor safety.

He endorses the authors’ call for reducing uncertainty about AI risks but suggests complementing this with evidence-gathering for potential catastrophic risks. Falk acknowledges the authors’ case against non-proliferation strategies while recognizing the inherent tensions in various policy approaches.

## Conclusion

While finding many valuable insights in the essay, Falk appears more concerned about the speed of AI progress and adoption. He questions whether market forces and existing regulations will ensure responsible AI development, particularly in the current political environment. Falk values the essay’s pragmatic approach to AI governance while maintaining a more cautious perspective on AI’s trajectory and potential impacts.

---

*This summary was prepared by Claude 3.7 Sonnet based on Johan Falk’s reading notes.*

---



Overall, Johan Falk's reflections on "AI as Normal Technology" offer a critical analysis of the original essay's arguments. Falk questions the pace of AI advancement, potential societal impacts, and the adequacy of current regulations in ensuring responsible AI development. He emphasizes the need for caution and evidence-gathering regarding AI risks, especially in light of rapid progress and adoption rates. Despite finding value in the essay's insights, Falk remains more skeptical about the trajectory and impact of AI technology.