---
{"dg-publish":true,"permalink":"/01-consume/web-clippings/are-human-beings-necessary-in-the-life-cycle-of-knowledge/","title":"Are human beings necessary in the life cycle of knowledge?","tags":["ai","education"]}
---

# Are human beings necessary in the life cycle of knowledge
## Highlights

1. The potential crisis in the implementation of AI in schools, termed as the "classroom AI doom loop."
2. The worst-case scenario of automation in education, where AI takes over the entire knowledge transmission cycle.
3. The unintended consequences of AI functionality in education, leading to issues like cheating and lack of human involvement.
4. A call for a serious policy discussion about the purpose of education and the importance of human involvement in teaching important skills.
5. Emphasizing the role of humans in modeling, coaching, teaching, and developing skills like communication, critical thinking, collaboration, and creativity.

---
Idea

A teacher warns of a looming AI crisis in education: without clear guidance, learning risks falling into an uncontrollable doom loop.

23 April 2025

Last update:25 April 2025

![David Ross](https://www.unesco.org/sites/default/files/styles/paragraph_medium_desktop/article/2025-04/donald-tran_unsplash.jpg.webp?itok=074i_1Vh)

**By David Ross, writer and AI consultant, Ross Consulting**

A few nights ago, I spent 90 minutes online with the staff of an elite public school in Shenzhen, China. I gave an hour-long talk about generative AI and its uses in education then engaged my audience in a 30-minute Q&A.

Near the end of our chat, one of the teachers made a passing comment that has made me think about a potential crisis in our implementation of AI in schools. I call this foreseeable crisis, with very little hyperbole, *the classroom AI doom loop*.

The teacher in question strode to the front of the room to grab the microphone and then explained the tremendous pressure he and his colleagues face. Students, parents, administrators, government officials, industry leaders, and the public were demanding that they increase students' AI literacy while training learners to use the tools in ethical and effective ways.

This implementation was, somehow, to occur in a learning environment bereft of guidelines, policy, laws, regulations, research, models, or proven strategies. He and his teaching colleagues were left on their own to face the most invasive disruption to education since, well, paper.

Students in his high school history class were turning in 25-page reports, perfectly written, clearly reasoned, and adorned with pages of citations. Did he really want to tell influential parents that their cherished offspring had cheated by using AI? Even if he did, could he prove it? He had no clue how to assess the work.

The teacher glared at me – the expert – and asked a two-part question: “ Where do you see this going? Best-case scenario and worst-case scenario?”

## Worst-case scenario: a screenplay

I, and all the other experts in this field, have answered the best-case scenario question countless times, but I had never really pondered the idea of a worst-case scenario. Three days later, I have one. I’ll call it *Johnny and Mr. Bennett Enter the Classroom AI Doom Loop*, with apologies to the team who wrote the introduction for the classic American television program Twilight Zone...

> *You're traveling through another dimension -- a dimension not only of sight and sound but of mind, both human and artificial. A journey into a wondrous land whose boundaries are that of imagination. There ’ s a signpost up ahead: You are now entering the Classroom AI Doom Loop…*

Mr. Bennett, who teaches 10th-grade history and is the father of a newborn, asks ChatGPT to create five standards-based writing prompts for the topic of a compare-and-contrast essay on the root causes of the French and American Revolutions. ChatGPT pops out five prompts a moment later. Mr. Bennett skims the options and quickly chooses prompt No. 2:

“ Examine how economic hardship—especially unfair taxation and national debt—fueled the American and French Revolutions. How did the similarities and differences in each country ’ s financial pressures affect the direction of revolt?”

Mr. Bennett pastes the prompt into a new assignment in Google Classroom and schedules it for release the following morning. He goes back to caring for his new baby.

Johnny sees the assignment in the morning, copies it, pastes it into Claude.ai and asks Claude to write a response in the style of a 10th-grade student. Claude generates a passable essay, which Johnny scoops off the screen and pastes into a blank email in an attempt to remove any digital watermarks. He then copies the scrubbed text and pastes it into the AI Humanizer [Twixify](https://www.twixify.com/). The Humanizer makes it read even more like a 10th-grader by eliminating the mechanical tropes of AI-generated text.

I, and all the other experts in this field, have answered the best-case scenario question countless times, but I had never really pondered the idea of a worst-case scenario.

Johnny, who is thinking only about his overloaded daily schedule, doesn ’ t even read the output from the humanizer before downloading it as a Word doc and sending it via email attachment to [Essay Grader AI](https://www.essaygrader.ai/) for automatic grading.

Essay Grader AI assesses the essay using a system-generated rubric, giving Mr. Bennett advice for improving the assignment and Johnny for improving his writing. The AI outputs the score back into the Google Classroom grade book, which ports that grade into the district grade book on [PowerSchool](https://www.powerschool.com/).

Mr. Bennett, consumed by his fatherly duties, should really look at the feedback from Essay Grader AI, but he doesn ’ t have time. He supplements his salary by coaching the girls ’ basketball team after school. For understandable reasons, he trusts the AI to relieve him of the onerous task of grading 125 essays every week.

> *"We know that a scenario can be real, but who ever thought that reality could be a scenario? We exist, of course, but how, in what way? As we believe, as flesh-and-blood human beings, or are we simply parts of an AI ’ s automated workflow? Think about it, and then ask yourself, do you live here, in this classroom, in this school, or do you live, instead, in the Classroom AI Doom Loop?"*

We exist, of course, but how, in what way? As we believe, as flesh-and-blood human beings, or are we simply parts of an AI’s automated workflow?

## The mechanics of the doom loop

![Slides](https://www.unesco.org/sites/default/files/styles/paragraph_medium_desktop/article/2025-04/Ross.Blog_.WorflowGraphic.04.2025.png.jpg.webp?itok=cGTxs_zz "The Mechanics of the Doom Loop")

©David Ross

Let ’ s follow the workflow:

- Teacher prompts AI, which generates assignment
- Teacher posts assignment in Learning Management System
- Student copies text of assignment and prompts AI to create response
- AI generates a response, which student pastes into a AI Humanizer
- AI Humanizer outputs revised response, which student uploads to automated AI grader
- AI grader evaluates response then posts grade/feedback to LMS
- LMS outputs grade into Student Information System

No humans were harmed in this process because humans were only ancillaries to the process. And this is today ’ s technology. By the beginning of the next school year, agentic AIs such as [Manus](https://www.technologyreview.com/2025/03/11/1113133/manus-ai-review/), [Convergence](https://convergence.ai/) or [Responses API](https://link.mail.beehiiv.com/ss/c/u001.1FxDUWkbNuPKPw5uRCpR2uGSpKdR5Oxsq71SiE3ETtcp8RBbbSDEuEdHvGXDFo3Btie1SSSHXdG5PGLHZZfoJGIx8ESzXmePz-FvO6Fa0vJbyjP4fWP_nXPURnvfL15tA-YWh__WQ7OxZEceIO9BsLAjZOHUYWu1srrhKwgtwbQCnyFh84Gq0bdIlFY5JiWQvidfp1LX2xkUqqD87PKoOQYdZAwbsjx8UshT4LIx-PeioSUz21_YSeXPG8RvS3ExtIJAYWFeLl0FM7-fypg90SB19tbui0IuNMf1W9o5Xnw/4eq/pipIdGB-TjSh3RwRgEH6WA/h15/h001.nFNDOy1LBnZAuNqYoJ6-RMW2SaK5AlT6Clp1382_Dc4) will be able to eliminate humans from any involvement in the knowledge transmission cycle. If the last 100 years of technological innovation have taught us anything, it ’ s that if something can be automated, it will be automated.

Is this scenario really that far-fetched? Students and parents are busy and stressed. They hate homework because they have to give up their evenings and weekends to do it or monitor it. Teachers are busy and stressed. They hate homework because they have to give up their evenings and weekends creating it and then grading it. There is no conspiracy here, but humans will all choose to use AI for similar reasons.

Wouldn ’ t it be ironic if the solution to the industrial model of knowledge transmission is in fact automation?

## Do not blame the tech sector

The tech sector did not create AI so that students could cheat on history homework or teachers could relieve themselves of the drudgery of grading assignments. These are unintended consequences of AI’s functionality. However, the training data and processes used to build these tools play a significant role in how a student or teacher uses them. One also can’t ignore the reality of the market: Companies must create products that generate revenue as well as text and images. Form and function are close to an ideal match. Generative AI tools are large-language models. Teaching and learning is an even larger language model. They fit together naturally.

By the beginning of the next school year, agentic AIs...will be able to eliminate humans from any involvement in the knowledge transmission cycle. If the last 100 years of technological innovation have taught us anything, it’s that if something can be automated, it will be automated.

In 1951, the philosopher Bertrand Russell wrote an [essay](https://www.taylorfrancis.com/chapters/mono/10.4324/9781003104735-31/human-beings-necessary-1951-andrew-bone) entitled “ *Are Human Beings Necessary*?” in response to the new field of cybernetics. He pondered the consequences of an automated society long before generative AI as we know it was even imagined. Russell concluded that an automated society might not necessarily require human beings to function, but that probably wasn ’ t a good idea.

We have come to the inflection point where we can automate most elements of knowledge transmission. I ’ m not sure if that is a good idea. But before we take up residence in the Classroom AI Doom Loop, we should have a serious policy discussion about the purpose of education. If a major function of education can be automated, it's probably not human enough.

I can illustrate this point by advising you to walk through the aisles of your local megamart. You will see families, which almost always include a toddler who is sitting in the shopping cart, eyes glued to a tablet, oblivious to the chaotic bounty of capitalism that surrounds them. We have trained a generation of children to be entertained and taught by staring at a screen. Or if you prefer to learn via screen, [watch this passionate lament](https://www.tiktok.com/t/ZT2qf4xmU/) by a teacher named Ema, who shares the same sentiment much more eloquently on TikTok.

The current iteration of AI tutors is really good at teaching content to students, though, as Jeremey Knox [points out](https://unesdoc.unesco.org/ark:/48223/pf0000393197), in a manner that currently breaks no new ground pedagogically. If children prefer to learn that way, let them. For thousands of years teaching has consisted of equal parts transmission of knowledge and human development. Let the machines handle the mundane transmission of low-level knowledge per [Bloom’s Taxonomy.](https://bokcenter.harvard.edu/taxonomies-learning)

But before we take up residence in the Classroom AI Doom Loop, we should have a serious policy discussion about the purpose of education. If a major function of education can be automated, it's probably not human enough.

There is not a school on earth that doesn ’ t have a poster or plaque in the office that says something like the following: “ Our mission is to develop lifelong learners who effectively communicate, critically think, collaborate, and use their creativity to become successful in college, career while improving their community as active citizens.” These competencies are the components of education that humans excel at modeling, explaining, coaching, and teaching.

Let ’ s live up to those promises by letting the humans focus on human development and the array of skills that are described in frameworks as varied as t [he UNESCO Competency Framework](https://en.unesco.org/sites/default/files/competency_framework_e.pdf), [21st Century Skills](https://files.eric.ed.gov/fulltext/ED519462.pdf), [Socio-Emotional Learning](https://casel.org/casel-sel-framework-11-2020/), [Employability Skills](https://cte.ed.gov/initiatives/employability-skills-framework), [Character Education](https://www.scu.edu/character/character-education-framework/), the [Whole Child Approach](https://files.ascd.org/staticfiles/ascd/pdf/siteASCD/publications/wholechild/WC-One-Pager.pdf), and . They are all based on lived experience, and that ’ s something humans currently hold a monopoly on.

The ideas expressed here are those of the authors; they are not necessarily the official position of UNESCO and do not commit the Organization

**David Ross** is a writer and AI consultant, is the former CEO of the Partnership for 21s Century Learning.






[[AI in Education\|AI in Education]]
[[Automation\|Automation]]
[[Knowledge Transmission\|Knowledge Transmission]]
[[Human Development\|Human Development]]
[[01 CONSUME/Web Clippings/Education Policy\|Education Policy]]

