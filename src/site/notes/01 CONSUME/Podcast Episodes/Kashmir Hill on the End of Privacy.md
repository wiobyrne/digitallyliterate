---
{"dg-publish":true,"permalink":"/01-consume/podcast-episodes/kashmir-hill-on-the-end-of-privacy/","title":"Kashmir Hill on the End of Privacy","tags":["podcasts"]}
---

# Kashmir Hill on the End of Privacy

![rw-book-cover](https://wsrv.nl/?url=https%3A%2F%2Fmegaphone.imgix.net%2Fpodcasts%2F5c6a4f4a-e69c-11e8-8066-17a10182e4c8%2Fimage%2FThe_Verge_Decoder_Tileart_3000.jpg%3Fixlib%3Drails-4.3.1%26max-w%3D3000%26max-h%3D3000%26fit%3Dcrop%26auto%3Dformat%2Ccompress&w=300&h=300)

[[02 CURATE/Podcasts/Decoder with Nilay Patel\|Decoder with Nilay Patel]] hosted by [[Nilay Patel\|Nilay Patel]] - [[02 CURATE/Indexes/Podcast Index\|Podcast Index]]

In this intriguing discussion, [[Kashmir Hill\|Kashmir Hill]], a New York Times reporter and author of '[[Your Face Belongs to Us\|Your Face Belongs to Us]],' reveals the startling implications of [[Clearview AI\|Clearview AI]]‚Äôs [[facial recognition\|facial recognition]] technology. She shares insights from her groundbreaking investigation into this secretive startup, which can identify anyone from a simple photo. Topics include the ethical dilemmas of [[surveillance\|surveillance]], the chilling potential for wrongful arrests, and the personal vendettas that tech like this can enable. Hill emphasizes the urgent need for stronger [[02 CURATE/Notes/Privacy\|privacy]] regulations as [[society\|society]] navigates this new digital landscape.


## Highlights
- Episode notes
  1. Clearview AI took risks that big companies like Google and Facebook were not willing to take, giving them a competitive advantage in developing facial recognition technology.
  2. Facial recognition technology poses significant risks to privacy and can disproportionately affect marginalized communities.
  3. Clearview AI pushes responsibility onto police departments to use their technology, but ethical concerns regarding the use of a massive database of individuals need to be addressed.
  4. Big tech companies build surveillance networks for targeted advertising, but there is debate about their effectiveness, and Facebook is not listening to users through their iPhones.
  5. The sources of growth for Clearview AI as a private company are predicated on crawling through websites like Flicker to identify individuals, and filing a DMCA request is an effective way to remove content from the internet. 



## Snips


### [09:52] Clearview AI: The Radical Startup That Reorganized the Internet


[üéß Play snip - 1minÔ∏è (08:31 - 09:54)](https://share.snipd.com/snip/e6ad264a-0cc8-413b-83cc-c4e7ceb414d4)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP3486447209.mp3?updated=1697640136#t=08:31,09:54"> </audio>




### ‚ú® Summary
Clearview AI is a company that stands out because it is willing to do what big companies like Google and Facebook have not: use facial recognition technology openly. Unlike Google and Facebook, Clearview AI started as a startup with a bold vision and nothing to lose, making them a regulatory entrepreneur. They have created a database organized by faces, aiming to reorganize the internet. Their goal is to make their database as extensive as possible before competitors catch up.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>About Clearview AI itself, because the big companies have kind of had this capability for a while. And to their credit, they haven't really done much with it. You know, Google Photos, inside of Google Photos, will do some face matching, but that's not public as far as we know. Facebook can obviously do it, but they keep that inside of Facebook. Clearview is just like, we're doing it. We took a bunch of data and we're doing it. Now the cops can look at your face. Why is this company different? How did it start?</blockquote><br/><blockquote><b>Kashmir Hill</b><br/><br/>I think this was really surprising to people that it's something that's in the book that Google and Facebook both developed this ability internally and decided not to release it. And these are not companies that are traditionally that conservative when it comes to private information. I mean, Google's the company that sent cars all over the world to put our pictures of our homes on the internet. What was different about Clearview AI is that they were a startup with nothing to lose and everything to gain by doing something radical, doing something that other companies weren't Willing to do. And I mean, I put them in the same category of being a regulatory entrepreneur as an Uber or an Airbnb, that this was their differentiator. They said, we're going to make this database and we're going to reorganize the internet by face. And that's our competitive advantage. And we want to make our database as big as we can before anyone else can kind of catch up to us. Were they</blockquote>
</details>



---


### [28:05] The Risks of Facial Recognition Technology and its Impact on Privacy and Marginalized Communities


[üéß Play snip - 1minÔ∏è (27:12 - 28:06)](https://share.snipd.com/snip/622272e5-d8f2-486c-b783-087ca8688bb9)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP3486447209.mp3?updated=1697640136#t=27:12,28:06"> </audio>




### ‚ú® Summary
Cashmere Hill discusses the risks of facial recognition technology in relation to privacy and law enforcement. She points out the trade-offs involved, where law enforcement uses rhetoric to justify its use. The speaker raises concerns about preventing questioning of constitutional rights and the moral implications of challenging privacy. While acknowledging the technology's error rate and inability to audit law enforcement's use of it, the speaker highlights the potential disproportionate impact on marginalized communities based on historical and statistical evidence.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Welcome back. We're talking with Kashmir Hill about the big risks facial recognition poses to privacy. So this runs right into the trade-offs of all technology that is used by law enforcement. It seems like they are a battering ram of rhetoric when it comes to why law enforcement is using it. Like you say we're catching pedophiles and thus no more questions should be asked. Whenever I hear that, the red flags go off for me, right? You're trying to prevent me from asking questions about the Fourth and Fifth Amendment. You're trying to prevent me from asking questions about privacy by making them seem morally wrong to ask. But there's a part of me that says, look, the technology definitely has an error rate. I don't know what the cops are doing. I can't audit their use of it. When they do rely on technology like this, history and statistics suggest that it will have a disproportionate impact on marginalized communities. Has</blockquote>
</details>



---


### [29:06] Clearview AI and the Ethical Implications of Facial Recognition Technology


[üéß Play snip - 1minÔ∏è (28:16 - 29:07)](https://share.snipd.com/snip/8f6486e7-aeca-4c4e-99f7-1b46e1934fbf)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP3486447209.mp3?updated=1697640136#t=28:16,29:07"> </audio>




### ‚ú® Summary
Clearview AI pushes responsibility to police departments, stating they only provide the technology. Arrests should not be made solely based on Clearview matches, but more investigations are needed. Society needs to evaluate the implications. While Clearview has helped solve crimes, the ethical concerns regarding a massive database of individuals need to be addressed. Should everyone be subject to facial recognition technology for any crime, and what are the rules surrounding its use?


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Kashmir Hill</b><br/><br/>Kind of pushes that onus to police departments and saying, you know, we're just providing the technology for them to use. They should never arrest somebody based on a Clearview, you know, match alone and that they need to do more investigating. I think for us as a society, there's just a lot to evaluate here. I've talked to a lot of officers who, yeah, they've solved crimes with Clearview AI as a starting point. Horrific things, you know, abuse of children. But I think we need to ask ourselves, are we comfortable with this database of probably hundreds of millions of people, probably you and me? Should we all be in the lineup every time the police are trying to solve a crime, whether it's shoplifting or murder? You know, if they are going to use facial recognition technology, what are the rules?</blockquote>
</details>



---


### [34:24] Big Tech's Ubiquitous Surveillance Networks and Targeted Advertising


[üéß Play snip - 1minÔ∏è (32:59 - 34:29)](https://share.snipd.com/snip/ea50633e-ab4d-49d2-93d6-97e147e5d134)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP3486447209.mp3?updated=1697640136#t=32:59,34:29"> </audio>




### ‚ú® Summary
Big tech companies build surveillance networks for targeted advertising, but there is debate on its effectiveness. People believe Facebook is listening to them, but it would be illegal and impractical. The digital fingerprint is used to show ads. Nihilism comes into play as people accept invasion for the convenience of their phones.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Kashmir Hill</b><br/><br/>These days.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>Well, put that into practice for me. I've read a lot of your reporting. A lot of your reporting is about how the big tech companies build these ubiquitous surveillance networks, mostly to put advertising in front of us. At the end of it all, they're just trying to sell us some paper towels, right? And like faster than ever before. And there's billions of dollars in between me and the paper towels. But like, that's what it's for, right? It's like very targeted advertising. And there's some debate about whether it's even effective, which I think is very funny. But that's what it's largely for. And I go out, you know, I see my family, I listen to our readers, and they're like, Facebook is listening to us on our iPhones. And they won't believe me that probably not, you know, that's probably not happening, that there's this other very complicated multiple billion dollar mechanism that just makes It seem like Facebook is listening. I mean, it would be very illegal, right?</blockquote><br/><blockquote><b>Kashmir Hill</b><br/><br/>It'd be very illegal if they were.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>It would be illegal. And also, like, it would be harder. It feels like it would be much harder to light up your microphone all the time and listen to you than just assemble the digital fingerprint that they've managed to assemble and show you The ads for a vacation that your friend was talking about. And, you know, you can, like, explain it. But then people just, like, fall back on, well, Facebook is just listening to me on my phone. And I still have a phone and it's fine. And that's the nihilism, right? That's where the nihilism comes into play, where even when people assume that one of the most invasive things that can happen is happening, they're like, well, my phone's so useful. I definitely need to keep letting Facebook listen to me.</blockquote>
</details>



---


### [38:24] Sources of Growth for a Private Company


[üéß Play snip - 1minÔ∏è (37:08 - 38:22)](https://share.snipd.com/snip/6c2a8817-b2e1-41f5-b096-06854f12e692)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP3486447209.mp3?updated=1697640136#t=37:08,38:22"> </audio>




### ‚ú® Summary
A private company's sources of growth are uncertain as they are not a government actor. They target news and player sites by crawling through websites like Flicker, finding photos that individuals may be unaware of. The only effective way to remove content from the internet is to file a DMCA request.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Do we know what the sources are of that growth? Is it still the public internet or are they signing deals? How's that working?</blockquote><br/><blockquote><b>Kashmir Hill</b><br/><br/>You know, unfortunately, they're not a government actor. They're a private company, so I can't send them a public records request and find out what all their sources are. So I mostly see it through when I see an example of a search, whether they run it on me or I see it show up in a police investigation. But yeah, I mean, it seems like pretty wide out there. I mean, news sites, employer sites, they seem to be pretty good at targeting places that are likely to have faces. In one of my last meetings with Juan Tontat, before I was done with the book, they had just crawled Flickr. And he himself was finding all these photos of himself when he was a kid, like a baby coder in Australia. He said, it's a time machine. We invented it. And he did a search on me and it showed photos I didn't know were on Flickr that one of my sister's friends took. It was me at a point in my life when I was depressed, I was heavier, I weighed more. I don't put photos from that time on the internet, but there they were. Clearview had them.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>We have a joke on the verge staff that the only functional regulation on the internet is copyright law. Like, if you want something to come down off the internet, your fastest way to doing it is to file a DMCA request.</blockquote>
</details>


