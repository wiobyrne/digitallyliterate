---
{"dg-publish":true,"permalink":"/01-consume/podcasts/lawrence-lessig-on-ai-and-social-media/","title":"Lawrence Lessig on AI and Social Media","tags":["first-amendment","freedom-of-speech"]}
---

# Lawrence Lessig on AI and Social Media

![rw-book-cover](https://wsrv.nl/?url=https%3A%2F%2Fmegaphone.imgix.net%2Fpodcasts%2F5c6a4f4a-e69c-11e8-8066-17a10182e4c8%2Fimage%2FThe_Verge_Decoder_Tileart_3000.jpg%3Fixlib%3Drails-4.3.1%26max-w%3D3000%26max-h%3D3000%26fit%3Dcrop%26auto%3Dformat%2Ccompress&w=300&h=300)

In this discussion on [[02 DEVELOP/Podcasts/Decoder with Nilay Patel\|Decoder with Nilay Patel]] hosted by [[Nilay Patel\|Nilay Patel]], Harvard Law professor [[Lawrence Lessig\|Lawrence Lessig]], an expert on internet policy, dives into the conundrum of free speech amidst the chaos of AI and social media. He highlights the overwhelming presence of misinformation and the urgent need for regulatory frameworks to safeguard democracy. The conversation uncovers the tensions between First Amendment rights and the regulation of harmful content, as well as the implications of engagement-driven algorithms. Lessig also sheds light on copyright challenges posed by generative AI, advocating for fair artist compensation in the digital age.

[[02 DEVELOP/üóÇÔ∏è MOCs/Podcast Index\|Podcast Index]]

## Highlights
- Episode AI notes
  1. Lawrence Lessig discusses the overwhelming presence of misinformation on the internet and the challenges of regulating speech online due to strong protections under the first amendment.
  2. Strategies like copyright law have emerged as an effective means of regulating internet speech.
  3. Harvard Law School is working to build a better social media platform by filtering out negative aspects and making it more helpful for democracy.
  4. The differences between the Chinese and American versions of TikTok highlight the contrasting prioritization of children's well-being.
  5. The Facebook files reveal interventions favoring conservatives and the increased danger from foreign governments targeting US elections.
  6. TikTok's algorithms and content generation capabilities can mislead people by making them believe they are engaging with specific individuals discussing certain topics.
  7. False information can spread and become ingrained in people's beliefs due to the business model of social media platforms prioritizing engagement.
  8. Speech regulations and algorithmic decisions are not the same, and algorithms can promote false information unlike human editors.
  9. Foreign national Vladimir Putin may use chat GPT to spread false information about elections, posing a challenge in restricting speech while safeguarding American democracy.
  10. Citizen assemblies are a democratic innovation that allows citizens to confront and understand each other's perspectives, leading to supported resolutions.
  11. Open-sourcing deliberation can challenge the current political climate and reshape democratic relations.
  12. Copyright law is shifting, and legal access to underlying material should not be considered a copyright event.
  13. Copyright protection for AI-generated art is important to ensure fair compensation and prevent devaluation of human artists' work.
  14. Blockchain databases and enhanced content identification can help control AI-generated content in campaigns and address copyright issues.
  15. Younger internet users are highly knowledgeable about copyright law, leading to controversies over React videos on platforms like YouTube.
  16. YouTube is making deals with music labels to create private copyright laws to deal with AI-generated music, sparking controversy and raising concerns about potential antitrust issues. 


## Snips


### [03:36] Former President Obama Drops Out of Lab Launch Event


[üéß Play snip - 1minÔ∏è (02:12 - 03:39)](https://share.snipd.com/snip/e005c68c-7f3e-4a05-96aa-905be7d1f6bc)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=02:12,03:39"> </audio>




### ‚ú® Summary
The lab's launch event was a glitzy affair with guest speakers, including former President Barack Obama. Unfortunately, he couldn't attend due to illness. Larry filled in and discussed the overwhelming presence of misinformation on the internet, which harms individuals and democracy. The discussion highlighted the challenge of regulating speech online due to strong protections under the first amendment. However, strategies like copyright law have emerged as an effective means of regulating internet speech.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Launch event for the lab was a glitzy affair featuring a number of guest speakers, including former President Barack Obama, who was set to join Decoder and talk about how social media Can actually benefit democracy and how we might build towards that goal. Unfortunately, President Obama had to drop out of the event due to an illness. We are working with his team on rescheduling that conversation, which we're excited to have for you in the future. Happily, Larry was available to fill in, and he was more than prepared to dive deep on the big issues that the lab was designed to address, and that I've been thinking about quite a bit Lately. As you'll hear us say, there's a lot to unpack here. You'll hear us agree that the internet, at this moment in time, is absolutely flooded with misinformation, disinformation, and other really toxic stuff that's harmful to us as individuals, And frankly, to our future as a functioning democracy. But you'll hear us disagree a fair amount about what to do about it. Here in the United States, the First Amendment puts really strong protections around speech and heavily limits what the government can do to regulate any of it, even outright lies As we saw with both COVID and the 2020 election. But because there's so much stuff on the internet that people do want taken down, a number of strategies to get around the First Amendment have cropped up. For example, there's one law that is really effective at regulating speech on the internet. Copyright law. Filing a DMCA claim on something is one of the fastest ways to get it removed from the internet. And</blockquote>
</details>



---


### [04:36] The Role of Copyright Law in Regulating Speech on the Internet


[üéß Play snip - 1minÔ∏è (03:21 - 04:36)](https://share.snipd.com/snip/e0664781-0b66-48fe-950c-49e2c0f863fd)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=03:21,04:36"> </audio>




### ‚ú® Summary
The internet has led to strategies to regulate speech, such as copyright law. DMCA claims can quickly remove content from the internet, but there are misconceptions about copyright. The controversy over react videos on YouTube represents users trying to establish their own speech regulations. Larry, a writer on internet speech, gives an unexpected answer about these regulations. We also discuss two types of AI shaping our cultural experiences: algorithmic AI and generative AI.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Because there's so much stuff on the internet that people do want taken down, a number of strategies to get around the First Amendment have cropped up. For example, there's one law that is really effective at regulating speech on the internet. Copyright law. Filing a DMCA claim on something is one of the fastest ways to get it removed from the internet. And there's a whole folk understanding of copyright law, which is often wrong, that has sprung up in the creator economy. For example, Larry and I talked about the current and recurring controversies around React videos on YouTube. Not what they are, but what that controversy represents. The users of a platform trying to establish their own culture around what people can and cannot remix and reuse. Their own speech regulations based in copyright law. That is a fascinating cultural development. There is a lot of approaches to create these kinds of speech regulations that get around the First Amendment. And I wanted to know how Larry felt about that as someone who has been writing about speech on the internet for so long. His answers really surprised me. Of course, we also had to talk about AI. You'll hear us pull apart two different kinds of AI that are really shaping our cultural experiences right now. There's algorithmic AI, which runs the recommendation engines on social platforms and tries to keep you engaged. And then there's the new world of generative AI, which everyone agrees is a huge</blockquote>
</details>



---


### [07:11] Building a Better Social Media: Harvard's Innovative Approach to Address Misinformation and Disinformation


[üéß Play snip - 1minÔ∏è (05:48 - 07:09)](https://share.snipd.com/snip/846a24d6-4b66-47f4-be01-4ab25f4470ed)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=05:48,07:09"> </audio>




### ‚ú® Summary
Harvard Law School is bringing together industry professionals and technology experts to build a better social media platform. They aim to filter out the negative aspects and make it more helpful for democracy. The current challenges include AI, misinformation, and a shift in how social media is perceived. The era of Twitter is over, and a new generation has different expectations. After a decade of the same, it's time for a meaningful change.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Think what's important is how it wants to do it.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>So what the lab is going to do is bring people from industry, not, you know, loaned from industry, but people who have kind of left industry, who have decided they want to try to do good In the world, into the context of Harvard Law School, where we'll have policy people engaging with technology people, architecting how we could build a better social media. And of course, social media means media generally. So how we can take what has turned into a really poisonous soup and filter it into something that might actually be helpful for democracy.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>There's a few things happening right now in that soup that are new, one of which is AI, which I want to talk about. Another is two different wars and two different fronts that are defined by myths and disinformation at scale. And a third is what feels to me like a generational reset of how we think about social media at large. We came through the Facebook era. We went through what you might call the Twitter era. The Twitter era is definitively over. It is now a different company with a different name. And it feels like a younger generation is looking at social media differently. They've been raised with different expectations. All of that feels like, well, we've been at this for over a decade. Should we try something new or something meaningful finally going to change? Do you feel that as well?</blockquote>
</details>



---


### [11:36] The difference between Chinese and American versions of TikTok


[üéß Play snip - 2minÔ∏è (10:08 - 11:38)](https://share.snipd.com/snip/d167d34a-c84d-4798-b5f3-e3ce121cd9cc)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=10:08,11:38"> </audio>




### ‚ú® Summary
The differences between the Chinese and American versions of TikTok are stark. While the American version is uncontrolled and feeds negative content to young users, the Chinese version is restricted, limited in usage, and promotes aspirations of becoming an astronaut. This intentional design decision highlights the contrast between prioritizing children's well-being in China and the lack of regulations in the US. It raises important discussions on the tension between speech regulations and the First Amendment.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>First important to be clear about the first part of what you said, which I think is really important. And that is the way other countries are actually doing it. You know, so in China, which obviously is not a political system to be recommended, but we can observe that there's a Chinese version of TikTok and there's an American version of TikTok. And the American version of TikTok is completely uncontrolled. It runs all the time. It feeds the worst possible content to especially young people to drive them to engage. The Chinese version of TikTok is blocked during certain hours. It limits the total amount of time you're allowed to be on it. The substance of what it provides is like aiming to like lead people to want to be astronauts. You know, if you ask our kids what their number one dream job is, it's being a social influencer. If you ask the Chinese kids, it's being an astronaut. That's not an accident. That's not like the free market working. That is an intentional design decision that they're making towards helping their kids and we're making towards giving up.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>I would say if you went and asked a bunch of parents in America, should the government pass some speech regulations that makes our TikTok look more like Chinese TikTok? And then you describe those outcomes. They would say yes. And then you would have to say, well, we can't because of the First Amendment. And that seems like a really important tension that we are facing right now.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>Even like among my own colleagues, we have this conversation about how should the First Amendment be applied in this context. I mean, let's take a very precise example.</blockquote>
</details>



---


### [11:18] Comparison of Chinese and American Versions of TikTok


[üéß Play snip - 1minÔ∏è (10:08 - 11:15)](https://share.snipd.com/snip/6715ab90-286a-4808-84b5-7a56edf7299a)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=10:08,11:15"> </audio>




### ‚ú® Summary
The Chinese version of TikTok is controlled and aims to inspire kids to become astronauts, while the American version is uncontrolled and promotes negative content. This intentional design decision shows a difference in priorities for children between China and the US.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>First important to be clear about the first part of what you said, which I think is really important. And that is the way other countries are actually doing it. You know, so in China, which obviously is not a political system to be recommended, but we can observe that there's a Chinese version of TikTok and there's an American version of TikTok. And the American version of TikTok is completely uncontrolled. It runs all the time. It feeds the worst possible content to especially young people to drive them to engage. The Chinese version of TikTok is blocked during certain hours. It limits the total amount of time you're allowed to be on it. The substance of what it provides is like aiming to like lead people to want to be astronauts. You know, if you ask our kids what their number one dream job is, it's being a social influencer. If you ask the Chinese kids, it's being an astronaut. That's not an accident. That's not like the free market working. That is an intentional design decision that they're making towards helping their kids and we're making towards giving up. I would</blockquote>
</details>



---


### [17:04] Foreign Governments Targeting US Elections: The Dangers of 2024


[üéß Play snip - 2minÔ∏è (15:18 - 17:03)](https://share.snipd.com/snip/5ee43625-cd3b-44d9-9bf6-0b29fc99937c)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=15:18,17:03"> </audio>




### ‚ú® Summary
In 2016 and 2020, the Facebook files revealed interventions favoring conservatives. In 2024, there will be a greater danger from foreign governments targeting the US election, like the Russians and the Chinese. The AI technology used by these governments will work better in America than in Taiwan. Mark Zuckerberg and Facebook were just trying to make money, not destroy democracy. However, now more advanced AI, particularly from platforms like TikTok, will have the power to disrupt institutions.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>Yeah, absolutely. And that's exactly what happened in 2016 and in 2020. Indeed, the Facebook files demonstrated that though, you know, for example, conservatives said that they were being discriminated against by these platforms. In fact, the interventions from the political department of Facebook overwhelmingly were interventions to bend the rules in favor of allowing conservatives to do whatever they Wanted on the platform. So you're right, that dynamic was certainly what happened in that election. 2024 will be that plus order of magnitude greater danger produced by foreign governments that have targeted the United States in this election. Like, you know, there are all sorts of stories of the Russians in 2016 and 2020. The Chinese in 2024 have all, it's already revealed this is what they're doing. The first round will be the Taiwanese elections in January of 24, where they have already begun to figure out how they can flood that space to create disinformation, to tilt the election In the way that they want to tilt it. But that's just a dry run. In fact, the technology they're using will work better in America than it does in Taiwan, because it turns out the AI is better tuned to English than it is to the Taiwanese version of Chinese. And so we will be completely vulnerable to something that has as its purpose screwing up our election. Look, you know, Mark Zuckerberg doesn't hate America. Facebook wasn't trying to destroy American democracy. It was just trying to make money. But now you'll have even more sophisticated AI focused like a laser on blowing up the basic institutions of our democracy.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>And the mechanism of AI or the expression of AI in your mind is specifically TikTok.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>It's the algorithms behind things like TikTok, but it's also, more importantly, the content generation capabilities that LLMs will give them.</blockquote>
</details>



---


### [16:29] The Facebook Files and Political Interventions: Impact on Conservatives in Elections


[üéß Play snip - 1minÔ∏è (15:18 - 16:28)](https://share.snipd.com/snip/0a7f6253-a6f8-4932-b472-7fc8dc51a74d)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=15:18,16:28"> </audio>




### ‚ú® Summary
The Facebook files revealed that conservatives felt discriminated against on the platform. In the upcoming 2024 election, foreign governments like Russia and China pose an even greater danger with their disinformation campaigns. The Chinese have already started targeting the Taiwanese elections as a test run for their tactics. However, their technology is more effective in English, making the US a prime target.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>Yeah, absolutely. And that's exactly what happened in 2016 and in 2020. Indeed, the Facebook files demonstrated that though, you know, for example, conservatives said that they were being discriminated against by these platforms. In fact, the interventions from the political department of Facebook overwhelmingly were interventions to bend the rules in favor of allowing conservatives to do whatever they Wanted on the platform. So you're right, that dynamic was certainly what happened in that election. 2024 will be that plus order of magnitude greater danger produced by foreign governments that have targeted the United States in this election. Like, you know, there are all sorts of stories of the Russians in 2016 and 2020. The Chinese in 2024 have all, it's already revealed this is what they're doing. The first round will be the Taiwanese elections in January of 24, where they have already begun to figure out how they can flood that space to create disinformation, to tilt the election In the way that they want to tilt it. But that's just a dry run. In fact, the technology they're using will work better in America than it does in Taiwan, because it turns out the AI is better tuned to English than it is to the Taiwanese version of Chinese.</blockquote>
</details>



---


### [17:33] The Impact of LLMs and TikTok on Content Generation and Misinformation


[üéß Play snip - 1minÔ∏è (16:51 - 17:33)](https://share.snipd.com/snip/96fe8ac3-f366-425e-914c-f014aaffe72a)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=16:51,17:33"> </audio>




### ‚ú® Summary
TikTok's algorithms and content generation capabilities, known as LLMs, have the power to mislead people by making them believe they are engaging with specific individuals discussing certain topics. This flood of information, resembling pathogens, lacks any defense mechanism or antibodies to combat it.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Of our democracy. And the mechanism of AI or the expression of AI in your mind is specifically TikTok.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>It's the algorithms behind things like TikTok, but it's also, more importantly, the content generation capabilities that LLMs will give them. So, you know, the LLM capability to mislead people into believing that they are engaging with certain people about certain things, that they've seen a certain speech by Obama or a speech By Biden or a speech by Trump. All of these things that we don't have any defense mechanism for right now will just flood into the system. You know, think of it like pathogens. Like they will just spread pathogens throughout the system and we have no antibodies for that. And we, as you're pointing out, because you're obviously legally educated,</blockquote>
</details>



---


### [17:43] The Impact of LLMs on Misleading Content and Defense Mechanisms


[üéß Play snip - 1minÔ∏è (16:51 - 17:48)](https://share.snipd.com/snip/2e13ccce-bdbc-4592-bc0f-65f7ecd0582b)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=16:51,17:48"> </audio>




### ‚ú® Summary
TikTok's algorithms and the content generation capabilities of LLMs can mislead people into believing they are engaging with certain individuals on certain topics, with no defense mechanism in place. It's like spreading pathogens throughout the system without any antibodies. Constitutional barriers and dominant platforms have hindered the government from building these defense mechanisms.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Of our democracy. And the mechanism of AI or the expression of AI in your mind is specifically TikTok.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>It's the algorithms behind things like TikTok, but it's also, more importantly, the content generation capabilities that LLMs will give them. So, you know, the LLM capability to mislead people into believing that they are engaging with certain people about certain things, that they've seen a certain speech by Obama or a speech By Biden or a speech by Trump. All of these things that we don't have any defense mechanism for right now will just flood into the system. You know, think of it like pathogens. Like they will just spread pathogens throughout the system and we have no antibodies for that. And we, as you're pointing out, because you're obviously legally educated, we also have a constitutional barrier to building those antibodies, or at least the government taking Steps to build those antibodies. The most dominant platforms for facilitating the spread of information had basically given up. You</blockquote>
</details>



---


### [19:43] The Embedding of Lies in Media Consumption


[üéß Play snip - 1minÔ∏è (19:00 - 19:43)](https://share.snipd.com/snip/c0d75ba8-bdcc-41d3-8e16-03303bb7d716)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=19:00,19:43"> </audio>




### ‚ú® Summary
The popularity of fake news and its impact is not limited to countries with state-run media. In countries like the US, false information can still spread and become ingrained in people's beliefs. This is due to the business model of social media platforms that prioritize engagement, and it has been found that content promoting hate and division is the most successful at grabbing attention.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>Yeah, right. And it went down a little bit, but it's now come back up. And, you know, if we were like talking about the Soviet Union and you said, well, you know, in the Soviet Union, they believe that America caused the war in whatever. And they still believe that completely false fact. We'd say, yeah, well, that's because you've got state run media. Well, we don't have state run media here. But you can still perpetrate an obvious lie. And that stays. And that's not just stays, it gets embedded into the identity of the people who consume that media. And not accidentally, both because the business model of social media is engagement, and it turns out the politics of hate is the most effective way to get people to</blockquote>
</details>



---


### [24:27] The Impact of TikTok and the Challenges Faced


[üéß Play snip - 1minÔ∏è (23:26 - 24:24)](https://share.snipd.com/snip/ef5b29e5-52fa-46cd-afe6-bea71a4a8f64)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=23:26,24:24"> </audio>




### ‚ú® Summary
TikTok ban is a challenging issue with artists defending their livelihood and First Amendment protection. Solving foreign influence and business model problems is difficult, as the platform aims to keep people engaged, potentially leading to conspiracy theories.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Let's talk about both. I think it's nice that you unpack them that way.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>The TikTok issue is, I think, extremely hard. You know, Montana has basically passed a law to ban TikTok. Immediately TikTok filed a suit challenging it, bringing a whole bunch of artists forward who said that their whole livelihood was TikTok. So therefore, it's the core of First Amendment protection. And I think it's going to be hard under the First Amendment. I mean, I actually volunteer to help Montana defend their law, but I think it's going to be hard. But even if you solve the foreign influence problem, you still haven't solved the business model problem. Because even if you know that China is not intentionally trying to screw with the elections, you still have a platform that's trying to figure out how do you make people spend more time On the platform. And it just is our psychology that the best way to do that is to turn us into conspiracy theorists who are crazy about all sorts of uh i</blockquote>
</details>



---


### [26:41] The Flip of Speech Regulations


[üéß Play snip - 1minÔ∏è (25:17 - 26:41)](https://share.snipd.com/snip/f8c028b2-e9c7-4db4-8adc-038ed5df12cb)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=25:17,26:41"> </audio>




### ‚ú® Summary
Taylor Swift and social media examples don't determine the truth. Feeling good doesn't equate to knowing the truth. Many people believe the big lie and defend it. There is a conflict with previous support for loosened speech regulations. It's not a complete change, but a different problem.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Anger. Yeah.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>But I would just say that, you know, the fact that you can point to Taylor Swift and I can point to everything in social media doesn't mean that I've lost the argument. I mean, you're right. Taylor Swift is a good example. Marvel movies. You can pick any number of things that make people generally feel good. So let's just recognize that's going to be a hard problem. And people feeling good doesn't mean that they know the truth. You know, there are a lot of people who believe the big lie who feel good about what they're doing. Like they're defending the truth, defending America against ‚Äì and they're told that in a very positive way. So I'm not saying that ‚Äì Would you make that illegal?</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>The thing that I'm stuck on here is, again, I came up reading your work, which is very much in favor of loosened speech regulations. And in particular, I think the stuff that you have published that has been most meaningful to me is the idea that the more we tend towards copyright maximism, the more we sort of backdoor Our way into speech regulations. So that Disney is now in control of art because Disney has overwhelming copyright protection. It feels like you're arguing the flip now, that we actually need some more speech regulations. That we should find a way to regulate what is allowed on these platforms or what people are allowed to make with technology.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>That feels like a really big shift for you. I don't think it's a flip, but I wouldn't admit it's a flip, right? But I don't feel like it's a flip. It feels like it's a different problem, right?</blockquote>
</details>



---


### [27:58] The Role of Algorithms in Speech Regulation


[üéß Play snip - 1minÔ∏è (26:34 - 28:02)](https://share.snipd.com/snip/c4e8b35c-92e3-4cc8-92e9-e189994436a3)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=26:34,28:02"> </audio>




### ‚ú® Summary
Speech regulations and algorithmic decisions are not the same - the government should address new problems like algorithms. Algorithms can promote false information, unlike human editors. In 2017, Facebook had a category called 'Jew haters,' generated by AI. We must break the tyranny of analogical reasoning.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>A flip, but I wouldn't admit it's a flip, right? But I don't feel like it's a flip. It feels like it's a different problem, right? So I don't favor the idea of speech regulations in the sense of the government deciding which speech is allowed and which it isn't. I think it's important, though, the government's allowed to address a new kind of problem. Algorithms are a new kind of problem. You know, some people say, when the algorithm decides to feed me stuff that makes me believe that vaccines don't work, that's just like the New York Times editors choosing to put certain Things on the op-ed page or not. It's not. It's not at all like that. Like when the New York Times humans make that judgment, they make a judgment that's reflecting values and understanding of the world and what they think they're trying to produce. When the algorithm like figures out what to feed you so that you engage more because you believe vaccines don't work, that is not those humans. And indeed, the best example of this is in 2017. In the fall of 2017, ProPublica published an article about how Facebook had an ad category called Jew Haters. You could buy Jew Haters as a category and advertise to Jew Haters. And when ProPublica published this, Facebook was like, whoa, whoa, whoa, whoa. We didn't do that. There was no human that wrote that category. And that was true. It was the AI that generated that category. So the point is, we've got to break the tyranny of analogical reasoning here. Yeah, it's like the editor at the New York Times, but it is not the editor at the New York Times.</blockquote>
</details>



---


### [29:15] Restricting the Use of Chat GPT by Foreign Nationals in Telling Lies


[üéß Play snip - 1minÔ∏è (28:21 - 29:18)](https://share.snipd.com/snip/13eddbdf-6e77-4fc2-a6c3-d536949ae432)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=28:21,29:18"> </audio>




### ‚ú® Summary
Foreign national Vladimir Putin may use chat GPT to spread false information about elections, which poses a challenge as restricting speech raises concerns. The DC Circuit, with Brett Kavanaugh's opinion upheld by the US Supreme Court, supports limiting the spending power of legal immigrants in political campaigns to safeguard American democracy. This creates a tension in jurisprudence similar to the Citizens United case, where the question of regulating speech arises.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>In this country uses a chat GPT to tell a lie. Yeah. And that should be somehow restricted.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>Yeah. The challenge there is ‚Äì you're right.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>The foreign national ‚Äì Let's go ahead. We'll just make the foreign national Vladimir Putin. Vladimir Putin shows up probably in Florida and he opens up chat GPT and says, tell some lies about the election. Yeah. Yeah. That is almost certainly protected speech.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>Yeah. Certainly protected speech. Although remember that the D.C. Circuit, Brett Kavanaugh writing the opinion, affirmed without dissent by the United States Supreme Court, of legal immigrants to spend money independently of a political campaign Because we're trying to protect the American democracy to be a democracy that Americans choose. So there's a tension in the jurisprudence. On the one hand, you speak like Citizens United does. It says that the question is just the speech. And does the government have the right to regulate, quote, speech? It doesn't</blockquote>
</details>



---


### [30:45] The Government's Right to Regulate Online Speech


[üéß Play snip - 1minÔ∏è (29:27 - 30:43)](https://share.snipd.com/snip/4dfad8b0-3f94-4a24-8c58-11d3fa458951)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=29:27,30:43"> </audio>




### ‚ú® Summary
The government's right to regulate speech, regardless of who is speaking, is the question at hand. In considering the decision in Citizens United, the importance of recognizing the need to protect democratic processes becomes apparent. The focus should not be on reforming the media to fit an ideal, but rather on safeguarding democracy from the influence of AIs. This includes both generative AIs and recommendation systems, which work together to achieve their objectives.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>It has nothing to do with it. The question is whether the government has a right to regulate the speech. Who cares who's uttering it? It could be a robot uttering the speech, you know, a replicant uttering the speech. It could be you uttering the speech. I don't think that was in Citizens United, replicants. It should have been. I think that's a really important point. But if you adopt that position, then you're right. There's nothing to do about Vladimir Putin. But I don't think we're going to settle on that position. I think we're going to settle on a position that begins to recognize we have a lot to do to protect democratic processes. And that's actually related to the work that we're doing at this new lab. Because, you know, there are a bunch of people out there like, how do we reform the media to make it so it's like our ideal of what the media should be? I think that's hopeless. I mean, God bless them and good luck. I think we instead need to recognize that we need to protect democracy from the radiation of these AIs. Like, you know, think of it as if it's like a ‚Äì like all of a sudden, you know, we can't protect ‚Äì And just to be clear, this is the generative AIs, not the recommendation algorithm AIs. I think they're the same thing right now. I mean, they will be deployed hand in glove in order to achieve the objective of the person deploying.</blockquote>
</details>



---


### [31:46] The Synergy Between Generative AIs and Recommendation Algorithms


[üéß Play snip - 1minÔ∏è (30:28 - 31:48)](https://share.snipd.com/snip/d38c1d0a-ebb6-4b97-bd38-3e62258bc5bf)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=30:28,31:48"> </audio>




### ‚ú® Summary
Generative AI and recommendation algorithms will be deployed hand in glove to achieve the objectives of the person deploying them. However, regulating media to solve the problem is hopeless, as the problem will persist regardless of regulation. The recommendation engine is effective in figuring out what people are open to, so the combination of AI content and recommendation algorithms will shape democracy.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>Know, we can't protect ‚Äì And just to be clear, this is the generative AIs, not the recommendation algorithm AIs.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>I think they're the same thing right now. I mean, they will be deployed hand in glove in order to achieve the objective of the person deploying.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>Walk me through that specifically, because I'm still stuck on the idea that if we're going to write some regulation, it should be, especially in the context of speech, it ought to be Like strict scrutiny from the beginning, right? Very narrowly tailored. And that means you have to define the problem. And so when you say hand in glove, it's, there's going to be a bunch of weird generative AI-created content about our election that gets fed through an AI recommendation algorithm. Yeah, I'll walk you through this, but let's be clear about what I'm trying to say.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>What I'm trying to say is that enterprise of figuring out how to regulate media to solve that problem, I think is hopeless. We're not going to regulate media to solve that problem. That problem is going to be there in some form, some metastasized, dangerous form, regardless of what regulation there is, even if we have creative ways of thinking about how to get Around the First Amendment. But these two things work together because the recommendation engine is just very good at figuring out what people are open to. So you have a fire hose of AI-generated content and the recommendation algorithm is going to- Figure out where to aim it, right? And so my point is like, okay, that's going to happen. We should recognize we can't do democracy in that space.</blockquote>
</details>



---


### [33:11] The Rise of Citizen Assemblies: A Global Democratic Innovation


[üéß Play snip - 1minÔ∏è (31:41 - 33:11)](https://share.snipd.com/snip/0219858c-fddc-4800-9f95-e4c9f5a1fad4)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=31:41,33:11"> </audio>




### ‚ú® Summary
Democracy may not work in certain spaces, so we should consider rebuilding it elsewhere. Citizen assemblies, a growing democratic innovation, are happening around the world. They allow citizens to confront and understand each other's perspectives, leading to supported resolutions. These assemblies have been successful in France, Ireland, Japan, and Europe, but have had limited experimentation in the United States. The important aspect of these assemblies is that they protect the deliberation process and foster understanding among citizens.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>My point is like, okay, that's going to happen. We should recognize we can't do democracy in that space. Yeah. It's not going to work. And then we've got to think about where can we rebuild democracy or what could it look like that was protected from that sort of thing? So one of the things that is happening around the world, completely invisible in American media, but one of the most interesting democratic innovations happening around the world Is the explosion of things called citizen assemblies. France did a huge one around climate change. Ireland has done a whole bunch of them, including two that proposed ending regulations on abortion and endorsing same-sex marriage. The citizen assembly came up with those solutions, overwhelmingly supported them. Then it went out to referendum. The public overwhelmingly supported them. We know that the politicians in Ireland could never have supported those two things, but these citizen assemblies could do it. There are hundreds in Japan. They're all through Europe right now. There have been some tiny experiments in the United States, but not much. But the point about these citizen assemblies is that these are places where citizens confront each other. They're representative, like they're large and representative. They confront each other. They hear the other side. They see that the other side is not a bunch of, you know, reptiles. They're like ordinary humans with the same issues. Like, how do I make sure my kid, you know, has a job after high school? And when they experience that and they deliberate and they come up with some resolution of some issue, whatever it is that's being presented to them, it has been protected. It's</blockquote>
</details>



---


### [34:58] Open-sourcing Deliberation: Democratizing Democracy


[üéß Play snip - 1minÔ∏è (33:44 - 35:01)](https://share.snipd.com/snip/f164f4b3-eb13-4f16-857c-824a05720cf1)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=33:44,35:01"> </audio>




### ‚ú® Summary
We're open sourcing a versatile tool that can be used by churches, schools, communities, and even in games. It promotes healthy deliberation and democracy, challenging our current divisive political climate. We believe others know best how to enable deliberation and that it can reshape our democratic relations. To combat media poisoning, we must build something different. It's like the skies opening up and us being exposed to UV radiation without protection.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>Going to open source it. And we're going to make it available in every single context. So, you know, churches could use it, schools could use it, local communities could use it, a DAO could use it, you know, a game could use it. You could be in the middle of, you know, organizing your friends at a game in a clan, and then you push the deliberation button. It will be an API. It opens into a healthy deliberation context. We're doing this because we believe, first, we don't know how best to enable deliberation. Secondly, we think people out there do. And third, we think that when they do, they'll begin to think about this as another way to do democracy. And it would exercise a muscle of a kind of democratic relation to other people that we don't have right now. Like our democratic relation to other people is to hate the other side. The politics of hate is not just that we're polarized. It's that we have to turn into villains, people who are not the same political view as we are. So what I believe is that we're going to have to find a way to begin to build something different while at the same time we're going to fight the war to make sure the media doesn't poison Us too much. So, again, the radiation metaphor I think is really powerful here. Like, you know, the skies open up and we're not protected from the UVs in the way we were</blockquote>
</details>



---


### [39:42] Professor Larry Lessig's Views on Copyright Lawsuits against Generative AI Companies


[üéß Play snip - 1minÔ∏è (38:30 - 39:43)](https://share.snipd.com/snip/c40f947d-0137-4c88-a17a-499c6169852c)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=38:30,39:43"> </audio>




### ‚ú® Summary
Professor Larry Lessig believes that using creative work to learn something, whether by machines or humans, should not be considered a copyright event. He suggests that regulation might be necessary to address the issue of fair use in AI.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Nilay Patel</b><br/><br/>We're back asking Professor Larry Lessig what he thinks about the wave of copyright lawsuits being filed against generative AI companies. There is one way that the current moment in AI could come to an end, and I would be remiss if I didn't ask you specifically about it, which is all of these LMs are built on vast amounts of training Data. Scraped from the open internet, who knows if that was appropriate or legal or authorized. There are a number of fair use cases pointed at these LM systems now. There's one against open AI. There's, I believe, one coming against Google. If there isn't, there will be. I can make that prediction, even if I don't know. They've got the most money. My colleague, Sarah Jong, says, it feels like this industry is built on a time bomb. This is a house of cards because no one knows the answer whether this copying was fair use or not. You're a copyright law professor. Yeah. Do you think it's fair use or not? So I have two strong views and one is very surprising.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>So the not surprising view I have is that whether you call it fair use or not, using creative work to learn something, whether you're a machine or not, should not be a copyright event. Now, maybe we should regulate in another</blockquote>
</details>



---


### [41:56] The Shifting Landscape of Copyright Law and Access to Underlying Material


[üéß Play snip - 1minÔ∏è (40:36 - 41:54)](https://share.snipd.com/snip/24d61207-ef6f-44a1-ad5d-c0fb2aa3caa0)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=40:36,41:54"> </audio>




### ‚ú® Summary
Copyright law is potentially shifting due to a recent case where Kagan's strong dissent might signal a new direction. Having legal access to underlying material should not be considered a copyright event, as reading a book is not a copyright event either. Training with AI should be free from copyright controls. However, when using AI to create work, there should be copyright protection. The Copyright Office disagrees with this viewpoint.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>A recent case that might make it more of a coin flip than I would have thought. Kagan wrote a very strong dissent in the case. And so maybe that signals that copyright law is shifting in a new way. The question of like legal access to the underlying material is always there. So I'm saying if you have access to the underlying material‚Äî And that's where your license scheme would come in. Yeah. And I'm not even sure it's a licensing point. My point is, if it's out there in the world and somebody has legal access to it and they use it to learn, that's not a copyright event. You know, reading a book is not a copyright event. Even though when you do it online, it technically copies, the whole point is it shouldn't be a copyright event because the equivalent, reading, is the sort of thing that was free. It was protected as free. Copyright was a narrow range of controls that we had to impose to create incentives for authors. And I don't think any of those controls are relevant in the context of the training. So I'm a very strong training is free. The view I have, which is surprising to people, is that, or people who know anything, you know, the 10 people in the world who know anything about my views on copyright. No, no, no, I have to make sure I'm one of those people. Is that I absolutely think that when you use AI to create work, there ought to be a copyright that comes out of that.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>And the copyright office has just sort of said no.</blockquote>
</details>



---


### [45:15] The Importance of Copyright for Artists and AI-generated Art


[üéß Play snip - 2minÔ∏è (43:18 - 45:21)](https://share.snipd.com/snip/8eed32f8-ec39-4751-8e3f-8dcd60109d58)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=43:18,45:21"> </audio>




### ‚ú® Summary
Navigating the world of AI-generated art poses challenges, including copyright issues. Without proper copyright protection, artists who rely on AI may struggle to make a living. Just as American authors fought for copyright to level the playing field with their English counterparts, AI artists need copyright to prevent unfair advantage for businesses using their work without compensation. The abundance of AI-generated content can devalue the work of human artists. Ensuring appropriate compensation and copyright licenses is essential to maintain a thriving artistic market.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>Here's how it was made and when it was made and what fed into it. Like whatever the provenance has to be to make it useful. I'm not sure of that exactly. But if you began to do that, you begin to build infrastructure of registries that would make it easier for us to begin to navigate in this context. The other reason to push for this is that, you know, artists in the next 10 years are going to increasingly move to AI generation for their art. Okay. If you don't get copyright from that, then basically these people have almost no way to make any living. You'll remember this, I hope, from copyright law. At the birth of America, foreign authors got no American copyright. And all the Americans thought, this is great. We're protecting the Americans against the foreigners. But of course, what that meant is that all the English books were much cheaper than the American books. So the American authors were at a disadvantage because the English authors weren't getting copyright. And the American authors began to push, give everybody copyright so that there's no unleveled playing field. Well, that's the same with this generative AI. If when I sit down and I make a creative work, I get a copyright and you push a button on MidJourney and there's no copyright there, the people consuming that work, like businesses trying To build advertising, are going to stop dealing with the artists. They're going to just deal with MidJourney and they're going to get all this stuff for free that they can use in a commercial way that the artist before would have been compensated for.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>Don't the basic laws of supply and demand kind of get in the way well before the sort of copyright licensing cost? If I'm using MidJourney, I can make 10,000 images in the time it takes an artist to make their first cup of coffee. Right. And this is what I hear from artists and musicians, right? Our markets are about to get flooded with C plus work because most of it's C plus work.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>Yeah, yeah, yeah.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>And like most people don't care enough. But if you have enough supply of C plus work, the price of that will fall to zero. Yeah. And no one will ever pay us for A plus work. And like whether or not, you know, paying me for A plus work comes with an appropriate copyright license or not seems pretty secondary to that basic economic problem.</blockquote>
</details>



---


### [44:40] The Importance of Copyright for AI-Generated Art


[üéß Play snip - 1minÔ∏è (43:18 - 44:44)](https://share.snipd.com/snip/0d6e9d2a-5763-4a3a-ada9-52978ab2b00d)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=43:18,44:44"> </audio>




### ‚ú® Summary
Building infrastructure of registries to navigate in the context of AI-generated art is crucial to protect the livelihoods of artists. Without copyright protection for their works, artists will struggle to make a living, similar to the disadvantage American authors faced when foreign authors had no American copyright. Ensuring a level playing field is essential to prevent businesses from bypassing artists and obtaining free generative AI content for commercial use.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>Here's how it was made and when it was made and what fed into it. Like whatever the provenance has to be to make it useful. I'm not sure of that exactly. But if you began to do that, you begin to build infrastructure of registries that would make it easier for us to begin to navigate in this context. The other reason to push for this is that, you know, artists in the next 10 years are going to increasingly move to AI generation for their art. Okay. If you don't get copyright from that, then basically these people have almost no way to make any living. You'll remember this, I hope, from copyright law. At the birth of America, foreign authors got no American copyright. And all the Americans thought, this is great. We're protecting the Americans against the foreigners. But of course, what that meant is that all the English books were much cheaper than the American books. So the American authors were at a disadvantage because the English authors weren't getting copyright. And the American authors began to push, give everybody copyright so that there's no unleveled playing field. Well, that's the same with this generative AI. If when I sit down and I make a creative work, I get a copyright and you push a button on MidJourney and there's no copyright there, the people consuming that work, like businesses trying To build advertising, are going to stop dealing with the artists. They're going to just deal with MidJourney and they're going to get all this stuff for free that they can use in a commercial way that the artist before would have been compensated for.</blockquote>
</details>



---


### [48:05] Controlling AI in American Campaigns and the Providence Issue


[üéß Play snip - 1minÔ∏è (46:40 - 48:04)](https://share.snipd.com/snip/bbb0fc18-b171-498b-ad7b-fdddabac5265)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=46:40,48:04"> </audio>




### ‚ú® Summary
"It could be copyright." The speaker discusses the potential for controlling AI-generated content in political campaigns. They propose a solution of making all campaign treasurers swear no money was spent on AI-generated content. However, this approach doesn't address foreign influence. The speaker suggests using blockchain databases to enhance content identification and ownership, which could be recognized by the Copyright Office.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>It could be copyright. This actually relates to another part of a really great question you asked before that I think it's important to be clear about. So when you were asking about AI in the context of elections, and how are you ever going to control that stuff? Because there are all sorts of, you know, right now, proprietary AI, like open AI, has said you can't use this content for political speech. But we have all sorts of open source models out there that can use the content for political speech. And so one question is, can you do anything about that? And the answer is, absolutely, you could control American campaigns. And people are not creative enough about how to control it. But if, for example, you made every treasurer of every campaign swear on the penalty of perjury that no money was spent for any AI-generated content in that campaign, you could shut It down right away. But that still would leave you vulnerable to the foreign influence. Now, that's not to say that there shouldn't be something we do about it. We should do that. But the point is, it will never be complete. And I think it's the same point with the provenance issue. There are so many fantastic databases out there that are being developed, blockchain databases, that would allow us to do much more in identifying like provenidence and ownership Of content. And I think that if they are set up so that the copyright office could recognize them, that would be the best of both worlds.</blockquote>
</details>



---


### [50:05] The Role of Copyright Law in the Creator Sphere on YouTube


[üéß Play snip - 2minÔ∏è (48:22 - 50:05)](https://share.snipd.com/snip/b98fa680-cf5d-4e7a-8dfc-a942394d1492)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=48:22,50:05"> </audio>




### ‚ú® Summary
Younger people on the internet are very aware of copyright law and there is a controversy over React videos on YouTube. Young creators believe this is a copyright violation and want something to be done about it. There is a concern that folk private copyright law is being substituted in for speech regulations, which could lead to something bad happening.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>I think the blockchain people are desperate for a use case that looks like this. Anything other than what they got now. I want to end kind of more in the weeds on something.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>I started by saying it feels like a reset moment on the internet. Like the platforms are shifting, user behavior shifting. A thing that has jumped out to me, maybe more than anything, is that younger people on the internet are so deeply aware of copyright law in a way that my generation wasn't beyond getting Sued for using Napster. That was basically our interaction with copyright law. Right now on YouTube, there is a controversy over so-called react videos, where one creator makes a video, a bigger creator reacts to that video, adds nothing other than some faces Potentially, and then they get all the views, right? And this is fine or not fine, but actually within the creator sphere on YouTube, the notion that this is a copyright violation and something should be done and this is wrong and they're Going to reach to copyright law is very strong, right? There's actually a copyright maximalism amongst younger creators that is shocking to me. Do you see that there's like a new kind of folk private copyright law where because speech regulations are definitely against sort of the American idea, we're going to substitute in Our folk wisdom about what copyright can or should be. We're going to say fair use like a magical incantation to claim moral superiority and have a fight. That seems all very like wrong to me. Like something bad is about to happen here. Yeah. Because we're ‚Äì again, we're once again training people to talk about regulating speech without actually talking about regulating speech. Yeah.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>I think it's actually a reaction to a very bad</blockquote>
</details>



---


### [49:45] The New Kind of Folk Private Copyright Law


[üéß Play snip - 1minÔ∏è (48:22 - 49:50)](https://share.snipd.com/snip/5e5ac72c-e277-4a2e-be38-07143713e08b)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=48:22,49:50"> </audio>




### ‚ú® Summary
Younger people on the internet are deeply aware of copyright law, leading to controversies on platforms like YouTube over React videos. There is a strong belief among younger creators that this is a copyright violation and should be addressed. It seems that a new kind of private copyright law is emerging, where individuals rely on their own interpretations of fair use as a form of moral superiority.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>I think the blockchain people are desperate for a use case that looks like this. Anything other than what they got now. I want to end kind of more in the weeds on something.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>I started by saying it feels like a reset moment on the internet. Like the platforms are shifting, user behavior shifting. A thing that has jumped out to me, maybe more than anything, is that younger people on the internet are so deeply aware of copyright law in a way that my generation wasn't beyond getting Sued for using Napster. That was basically our interaction with copyright law. Right now on YouTube, there is a controversy over so-called react videos, where one creator makes a video, a bigger creator reacts to that video, adds nothing other than some faces Potentially, and then they get all the views, right? And this is fine or not fine, but actually within the creator sphere on YouTube, the notion that this is a copyright violation and something should be done and this is wrong and they're Going to reach to copyright law is very strong, right? There's actually a copyright maximalism amongst younger creators that is shocking to me. Do you see that there's like a new kind of folk private copyright law where because speech regulations are definitely against sort of the American idea, we're going to substitute in Our folk wisdom about what copyright can or should be. We're going to say fair use like a magical incantation to claim moral superiority and have a fight. That seems all</blockquote>
</details>



---


### [54:40] YouTube's AI Copyright Law and the Need for Legislation


[üéß Play snip - 1minÔ∏è (53:21 - 54:43)](https://share.snipd.com/snip/f11eff3c-1389-43ff-9559-c680e61d28b4)
<audio controls> <source src="https://www.podtrac.com/pts/redirect.mp3/pdst.fm/e/chrt.fm/track/524GE/traffic.megaphone.fm/VMP7845495358.mp3?updated=1698159174#t=53:21,54:43"> </audio>




### ‚ú® Summary
YouTube is making deals with music labels to create private copyright laws on their platform to deal with AI-generated music that sounds like popular artists. This has sparked controversy as it is not based on any existing federal or state laws. While it could be seen as a market solution, there are concerns about potential antitrust issues. Some artists are worried about their style being copied and used by AI, but there may be unique ways to address this issue.


---




#### üìö Transcript
<details>
<summary>Click to expand</summary>
<blockquote><b>Lawrence Lessig</b><br/><br/>But instead, there's been conventions set by industries that were long before the Internet that creates these expectations. So this is happening right now.</blockquote><br/><blockquote><b>Nilay Patel</b><br/><br/>YouTube is entering into deals, particularly with universal music, where they're going to invent some private copyright law on the platform to deal with AI. So there was an AI artist on YouTube that sounded like Drake. It's a big scandal. Universal got very mad about it. YouTube has basically said, we're going to invent some stuff for you. So if there's AI that sounds like Drake, we'll let you take it down. That's not in any federal law that I can find or any decision that I can find yet. It hasn't been litigated. It's not really in any state law outside of likeness. So you basically have a private copyright law to one platform for the benefits of the music label. You could argue that that is an appropriate sort of market solution to this problem, but it feels like we should probably actually have a law.</blockquote><br/><blockquote><b>Lawrence Lessig</b><br/><br/>Where do you think that lands? It could be a market solution, assuming we're not having an antitrust issue involved. And I'm not sure I would assume that right now. With YouTube specifically? Yeah, with YouTube and some of these labels, right? So, you know, I have a lot of sympathy for the artists who are anxious about the fact that their style is taken and used in a particular way. And AI is obviously making this easy, trivial. And that's why I said at the beginning, I think there might be sui generis ways to compensate for that sort of</blockquote>
</details>
