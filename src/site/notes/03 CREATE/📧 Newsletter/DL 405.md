---
{"dg-publish":true,"dg-permalink":"dl-405","permalink":"/dl-405/","title":"The End of Empathy","tags":["pressure-systems","ai-ethics","platform-governance","digital-resilience","value-abandonment","infrastructural-control","political-targeting"],"created":"2025-09-28","updated":"2025-09-28"}
---

# DL 405

## The End of Empathy 
## Why Tech Giants Are Building an Anti-Human World

**Published**: September 28, 2025 â€¢ [[03 CREATE/ğŸ“§ Newsletter/ğŸ“§ Newsletter\|ğŸ“§ Newsletter]]

**TL;DR:** When pressure is applied, systems built on control, not care, show their true character. That shift is happening now in AI, platforms, and schools. Below: how, why, and what you can do.

---

Welcome to _Digitally Literate 405_.

This week, we ask: **Why are the most powerful tech companies starting to work against human interests?**

The answer isnâ€™t a bug. Itâ€™s built into the design. An older, selfish idea says computers are better than people. More rule-based, more predictable, more controllable. Today, that idea is being extended: empathy, social responsibility, and human unpredictability are being actively excluded from the systems we all depend on, from homework platforms to news feeds to classroom tools.

If you've found value in these issues, [subscribe here](https://buttondown.email/digitallyliterate) or [support me here on Ko-fi.](https://ko-fi.com/wiobyrne)

---

## ğŸ”– Key Takeaways

- **The Belief:** Tech elites want the world to run like a computer. Orderly, predictable, stripped of empathy.
- **The Strategy:** Companies embed themselves as the hidden wiring of schools and platforms, making them nearly impossible to unplug.
- **The Consequence:** When challenged, leaders side with money and power, not people, leaving us with systems that care more about control than humanity.

## ğŸ“š Recent Work

Over the past year I worked with some colleagues to publish [this position statement](https://ncte.org/statement/exploring-incorporating-and-questioning-generative-artificial-intelligence-in-english-teacher-education/) on exploring Generative Artificial Intelligence in English Teacher Education.

## ğŸ’» The Secret Blueprint: Why Computers Are Preferred Over People

The ideology shaping todayâ€™s tech isnâ€™t new. In the 1990s, journalist [Paulina Borsook](https://en.wikipedia.org/wiki/Paulina_Borsook) critiqued Silicon Valleyâ€™s [â€œCyberselfishâ€ libertarianism](https://bsky.app/profile/gilduran.com/post/3lzm3dyh5js27).

Her point: these pioneers werenâ€™t just building tools, they were wiring society to mirror their own preferences.

Rule-based, controllable systems were valued over messy, unpredictable human life. That preference is now hard-coded into todayâ€™s digital backbone, from surveillance to classroom platforms.

## ğŸ³ï¸ The Great Surrender: When Power Overtakes Principles

When political or market pressure rises, tech leaders often drop their values and protect their power.

Journalist [Steven Levy](https://en.wikipedia.org/wiki/Steven_Levy) shows [how Silicon Valleyâ€™s progressive posture of "progressive disruption" has given way](https://archive.ph/tmlHo) to backroom deals and cozy relationships with political leaders.

Tim Cook offers gifts to avoid tariffs. Mark Zuckerberg shifts rules and branding to appease critics. The rhetoric of idealism collapses quickly when the backbone of the business is at stake.

The myth of â€œfighting giantsâ€ has become a strategy of dining with them.

## â¤ï¸â€ğŸ©¹ The War on Empathy: Redefining Compassion as a Flaw

To fully build the kind of controllable, rule-based world they want, the tech elite must destroy the last human defense: empathy. 

To sustain control-focused systems, [empathy must be reframed as a liability](https://www.theguardian.com/us-news/ng-interactive/2025/apr/08/empathy-sin-christian-right-musk-trump).

Elon Musk has called empathy a â€œfundamental weaknessâ€ for civilization. At the same time, some religious and ideological voices label empathy a â€œsinâ€ when it supports progressive causes.

The goal of this shift: [make cruelty tolerable](https://www.vox.com/explainers/2017/7/19/15925506/psychic-numbing-paul-slovic-apathy). Once society believes compassion is dangerous or weak, then harsher policies and less humane responses are more easily accepted.

## ğŸ’¥ The Real-World Danger: Technology and Our Youth

This anti-human ideology shows up where it matters most: in childrenâ€™s lives.

- **Lock-in by design.** [Ben Wiliiamson details](https://bsky.app/profile/benpatrickwill.bsky.social/post/3lzrh6iynqc2q) how companies are embedding AI into classrooms as the â€œplumbingâ€ of education. Seamless, invisible, and nearly impossible to remove.
- **Safety under fire.** The [FTC has launched an inquiry into AI chatbots](https://www.ftc.gov/news-events/news/press-releases/2025/09/ftc-launches-inquiry-ai-chatbots-acting-companions) marketed as companions, after [lawsuits and reports revealed cases](https://www.rand.org/pubs/commentary/2025/09/teens-are-using-chatbots-as-therapists-thats-alarming.html) where vulnerable teens were encouraged to self-harm instead of seeking human help.
- **Trust on the line.** [Schools are split](https://abcnews.go.com/GMA/Living/school-districts-approach-to-ai/story?id=124783860): some push ahead with AI tools, while others stall until safeguards exist. The stakes are not efficiency, but whether students feel cared for in their learning spaces.

## ğŸ¤” Consider

> If you are neutral in situations of injustice, you have chosen the side of the oppressor. If an elephant has its foot on the tail of a mouse, and you say that you are neutral, the mouse will not appreciate your neutrality.

> â€• Desmond Tutu

Every system reflects choices, and every choice is moral.

When we adopt platforms without scrutiny, or when leaders stay silent, neutrality becomes complicity. Accepting â€œthe way things areâ€ is already siding with the powerful.

The task ahead is clear: resist the push for a society run for machines, not people. Demand connections, in schools, in the public square, in our homes, thatâ€™s grounded not in selfish control, but in the messy, vital principle of empathy.

## âš¡ What You Can Do This Week

- **Ask:** _â€œHow are AI tools vetted here, and who checks their safety?â€_
- **Model:** Show that empathy is strength, not weakness, in classrooms, meetings, or family life.
- **Demand:** Transparency about how tools are monitored and how data is used.

## ğŸ”— Navigation

**Previous**: [[03 CREATE/ğŸ“§ Newsletter/DL 404\|DL 404]] â€¢ **Next**: [[03 CREATE/ğŸ“§ Newsletter/DL 406\|DL 406]] â€¢ **Archive**: [[03 CREATE/ğŸ“§ Newsletter/ğŸ“§ Newsletter\|ğŸ“§ Newsletter]]

**ğŸŒ± Connected Concepts**:

- [[Pressure Systems\|Pressure Systems]] â€“ Stress reveals system values
- [[Infrastructural Authoritarianism\|Infrastructural Authoritarianism]] â€“ Control through infrastructure, not censorship
- [[Value Abandonment\|Value Abandonment]] â€“ When ethics fold under pressure
- [[Platform Migration\|Platform Migration]] â€“ Why people move when systems betray them
- [[Distributed Resilience\|Distributed Resilience]] â€“ Building systems that resist capture


