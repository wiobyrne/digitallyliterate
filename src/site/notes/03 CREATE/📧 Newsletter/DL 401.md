---
{"dg-publish":true,"dg-permalink":"dl-401","permalink":"/dl-401/","title":"Useful Friction","tags":["ai-paradox","surveillance-capitalism","deliberate-practice","technological-determinism","cognitive-offloading","media-ecology"]}
---

# DL 401

## Useful Friction

**Published**: August 30, 2025 â€¢ [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

Welcome to _Digitally Literate_ 401. After nearly 400 issues of watching technology promise frictionless solutions, this issue explores why the smoothest path isn't always the smartest one. Sometimes the most valuable work happens in the spaces between automation and agency, where useful friction lives.

**Want to get this in your inbox?** [Subscribe to _Digitally Literate_ here](https://buttondown.email/digitallyliterate).

---
## ðŸ”– Key Takeaways

- **The AI Paradox**: Advanced AI mimics reasoning but lacks robust intelligence, leading to failed business pilots and cognitive dependency
- **Convenient Illusions**: We choose surveillance-based shortcuts over difficult truths about human-AI collaboration
- **Useful Friction**: Deliberate practice in writing and critical thinking becomes more valuable as automation spreads
- **Ecological Change**: Technology doesn't just add capabilities, it transforms entire systems of thinking and learning

## ðŸ“š Recent Work

Here's some of my recent posts:
- [Reclaiming Our Tools: Why We Canâ€™t Opt Out of the AI Future](https://wiobyrne.com/reclaiming-our-tools/) - AI isn't a future we can opt out of. It's a reality we must actively shape. My recent post challenges us to move beyond passive skepticism and towards intentional engagement.
- [Seven Critical Decisions to Make When Trying New AI Tools](https://wiobyrne.com/decisions-to-make-when-trying-new-ai-tools/) - Perfect tools donâ€™t exist, but thoughtful choices do. Hereâ€™s how we move beyond shiny demos and start aligning AI use with our real goals and values.
- [Whatâ€™s Actually Inside an AI Model? (Itâ€™s Not What You Think)](https://wiobyrne.com/inside-an-ai-model/) - When we talk about AI models, what is actually in these files? Let's take a look. 

**Supporting Digital Literacy Analysis After 400+ Issues**

After nearly 400 newsletter issues analyzing how we learn, work, and navigate information online, I'm launching a way for readers to directly support this work and get deeper access to these insights.

I've set up Ko-fi memberships at [https://ko-fi.com/wiobyrne](https://ko-fi.com/wiobyrne) for those who want more:

**Digital Literacy Supporter ($5/month):** Early access to newsletter deep-dives, quarterly Q&A sessions, and complete searchable archive of all 400+ issues.

**Newsletter Strategy Insider ($25/month):** Everything above plus monthly group coaching calls, my newsletter templates and frameworks, and direct email access for feedback on your newsletter strategy.

This support helps me spend more time on in-depth analysis rather than just maintaining the free newsletter. If you've found value in these issues, consider joining the community of educators and professionals who are serious about understanding our digital world

## ðŸ«§ Popping the AI Hype Bubble

Most AI conversations fall into three camps: Golden Age, End of Humanity, or Long Messy Transition. But they're all missing the real story: **The AI Paradox.** AI excels at complex tasks while failing at basic common sense.

Apple researchers' "[The Illusion of Thinking](https://machinelearning.apple.com/research/illusion-of-thinking)" exposes this paradox. Today's "reasoning" isn't budding intelligence. It's sophisticated pattern matching that mimics human reasoning but lacks the robust, symbolic logic that underpins true intelligence.

This fragility shows up in boardrooms. [MIT's NANDA Lab reports](https://mlq.ai/media/quarterly_decks/v0.1_State_of_AI_in_Business_2025_Report.pdf) that 95% of AI pilots are failing despite high adoption rates. We're deploying a narrow tool while expecting sweeping transformation it can't deliver.

The paradox's most troubling effect may be on us. [Research by Kosmyna et al.](https://arxiv.org/abs/2506.08872) shows AI writing assistants decrease brain connectivity and homogenize language. Changes that persist even after we stop using these tools.

## ðŸŽ­ Convenient Illusions Over Difficult Truths

The AI Paradox reveals something deeper than technical limitations. It exposes our willingness to accept shortcuts over understanding. We know these systems are fragile mimics, yet we deploy them anyway. We know they're [built for surveillance and profit](https://archive.ph/o/ElVAA/https://www.ft.com/content/799b4fcf-2cf7-41d2-81b4-10d9ecdd83f6), yet we hand over more cognitive work to them.

Not because AI isn't powerful, but because the people selling it don't care what it does, [only what it can be sold as](https://arxiv.org/html/2505.11449v1). What they're building isn't intelligence. It's a mirror, a mimic, [a control system designed to monitor, monetize, and manipulate](https://www.linkedin.com/pulse/everyones-worried-ai-get-too-smart-im-more-itll-rob-sebastian-y4udc/). 

This pattern extends beyond AI. The internet, initially envisioned as a tool for connection, [has instead fostered isolation and neuroticism](https://www.persuasion.community/p/how-we-got-the-internet-all-wrong) among young people. We chose algorithmic feeds over intentional relationships, convenience over genuine connection.

## ðŸ‹ï¸ The Antidote: Useful Friction

The path forward requires embracing what [Paul Jun calls deliberate practice](https://pauljun.substack.com/p/anti-slop-and-anti-brainrot). Resisting shortcuts and engaging in activities that build cognitive strength. As the world automates, conditioning fundamental capabilities like writing and critical thinking becomes more valuable, not less.

## ðŸ¤” Consider

> Technological change is neither additive nor subtractive. It is ecological. I mean â€œecologicalâ€ in the same sense as the word is used by environmental scientists. One significant change generates total change. 
> 
> If you remove the caterpillars from a given habitat, you are not left with the same environment minus caterpillars: you have a new environment, and you have reconstituted the conditions of survival; the same is true if you add caterpillars to an environment that has had none. 
> 
> This is how the ecology of media works as well. A new technology does not add or subtract something. It changes everything.

> â€” Neil Postman

In an age of algorithmic shortcuts and AI assistance, the most radical act might be choosing the harder path. Not because difficulty is virtuous, but because some kinds of friction, the mental effort of writing, the cognitive work of reasoning, the social challenge of genuine connection, are what make us human.

The question isn't whether we'll use these tools, but whether we'll let them use us.

## ðŸ”— Navigation

**Previous**: [[03 CREATE/ðŸ“§ Newsletter/DL 400\|DL 400]] â€¢ **Next**: [[03 CREATE/ðŸ“§ Newsletter/DL 402\|DL 402]] â€¢ **Archive**: [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

**ðŸŒ± Connected Concepts**:
- [[AI Paradox\|AI Paradox]] - The gap between AI's narrow capabilities and broad promises
- [[03 CREATE/ðŸŒ² Evergreens/Surveillance Capitalism\|Surveillance Capitalism]] - How attention economy shapes technology design
- [[Deliberate Practice\|Deliberate Practice]] - Building cognitive strength through intentional effort
- [[Technological Determinism\|Technological Determinism]] - Why tools aren't neutral forces but shaped by human choices
- [[Cognitive Offloading\|Cognitive Offloading]] - What we lose when we outsource thinking to machines
- [[01 CONSUME/ðŸ“š Books/Digital Minimalism\|Digital Minimalism]] - Intentional technology use aligned with values
- [[Pattern Recognition vs Reasoning\|Pattern Recognition vs Reasoning]] - Understanding AI's actual capabilities and limitations
- [[Media Ecology\|Media Ecology]] - How new technologies reshape entire information environments

_Also available at [digitallyliterate.net](https://digitallyliterate.net/) with linked connections._