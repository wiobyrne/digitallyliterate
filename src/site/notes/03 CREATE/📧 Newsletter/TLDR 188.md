---
{"dg-publish":true,"dg-permalink":"tldr-188","permalink":"/tldr-188/","title":"Orchids and Dandelions","tags":["digital-literacy","education-technology","online-safety-guides","national-online-safety","peergrade","peer-evaluation","formative-assessment","momo-challenge","viral-hoax","urban-legend","moral-panic","uk-safer-internet","fake-news","vpn-privacy","will-oremus","karl-bode","virtual-private-networks","privacy-theater","vpn-risks","ethical-operators","elsevier-cancellation","university-california","open-access","academic-publishing","subscription-costs","scholarly-communication","publishing-monopoly","youtube-fact-checking","arimeta-diop","search-context","information-panels","recommendation-algorithm","radicalization-pipeline","ai-humanities","karen-hao","tech-humanities-divide","false-dichotomy","henry-kissinger","guiding-philosophy","enlightenment-reversal","orchid-children","dandelion-children","thomas-boyce","sensitive-kids","biological-reactivity","stress-response","childhood-resilience","differential-susceptibility","work-life-balance","thomas-frank","overwhelm","time-management","neil-barringham","grass-is-greener","attention-cultivation"],"created":"2019-03-09","updated":"2025-12-13"}
---

# TLDR 188

## Orchids and Dandelions

**Published**: 2019-03-09 â€¢ [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

Welcome to Issue 188. Orchids and dandelions.

Hi all, welcome to TL;DR. My name is [Ian O'Byrne](https://wiobyrne.com/start/). I research, teach, & write about technology in our lives. I try to synthesize what happened this week in tech...so you can be the expert as well.

I posted a couple of other things this week:

- [Online safety guide for parents & care-givers](https://screentime.me/online-safety-guides-for-parents-care-givers/) - This portal from the National Online Safety organization shares their most up to date guides for social media apps and platforms.
- [Encouraging peer evaluation & feedback of student work using Peergrade](https://www.youtube.com/watch?v=4QVkGgD_Sm4&feature=youtu.be) - A quick video lecture focusing on how I structure assessments including formative and summative assessments in Peergrade.

---

## ðŸ”– Key Takeaways

- **Momo Challenge Hoax**: Viral urban legend about supposed suicide game demonstrates how moral panic spreads faster than evidence, with UK Safer Internet Centre calling it "fake news" and YouTube finding no evidence.
- **VPN Privacy Theater**: Most VPN providers may increase privacy risks rather than reduce them, with ethical operators nearly impossible to identify revealing another form of security theater.
- **Open Access Victory**: University of California canceling $11 million annual Elsevier subscriptions represents major advancement for open access movement against publishing monopolies demanding escalating costs.
- **YouTube Fact-Checking Limitations**: Platform adding information panels to controversial searches while recommendation algorithm continues creating radicalization pipelines reveals surface-level intervention avoiding systemic fixes.
- **Orchid and Dandelion Framework**: Most children are resilient dandelions coping well with stress while minority are sensitive orchids with heightened biological reactivity requiring different support approaches.

---

## ðŸ“º Watch

### [The Momo Challenge Hoax](https://knowyourmeme.com/memes/momo-challenge)

Dear readers of this newsletter...I apologize that I did not pick up on the [Momo challenge](https://knowyourmeme.com/memes/momo-challenge) up until this point. It was not until some friends of mine in edtech indicated that fearful parents were inundating schools with calls from fearful parents asking what they should do about this supposed suicide game.

Before you keep exploring, please note that this is a [viral urban legend](https://www.vox.com/2019/3/3/18248783/momo-challenge-hoax-explained) that has been persistent online for a little over a year.

The [UK Safer Internet Centre](https://www.saferinternet.org.uk/) called the claims "fake news". YouTube said it had seen no evidence of videos showing or promoting the Momo challenge on its platform.

The Momo Challenge demonstrates how contemporary moral panics spread through social media amplification. A creepy sculpture (actually artwork by Japanese special effects company) becomes associated with unverified claims of dangerous content targeting children. Worried parents share warnings, media reports on parental concerns, schools respond to inquiries, creating feedback loop where reporting on panic generates more panic. No credible evidence emerged of actual Momo-related harm, but widespread fear was real. The mechanism: disturbing imagery plus child safety concerns plus social media virality plus traditional media coverage equals mass hysteria. The pattern repeats: Slenderman, Blue Whale, every generation's version of "stranger danger" adapted to digital contexts. The challenge isn't content moderation but media literacyâ€”helping parents distinguish between legitimate threats and viral legends.

---

## ðŸ“š Read

### VPNs and Privacy Theater

I've talked about virtual private networks (VPNs) a lot in the past in this newsletter. VPNs extend a private network by allowing you to send and receive data across a shared network as if you were directly connected to the private network. What this means is that you would connect to a third party, and then conduct your web navigation from there.

This piece from [Will Oremus](https://twitter.com/WillOremus) in Slate shares his exploration and research of some of the companies that exist in the VPN market. He basically suggests that most of these companies are a complete waste of money...and perhaps may be more a privacy risk than just searching openly online.

Read this [post in TechDirt](https://www.techdirt.com/articles/20190228/10082141693/vpns-are-no-privacy-panacea-finding-ethical-operator-is-comical-shitshow.shtml) from [Karl Bode](https://twitter.com/KarlBode) for more on this important topic.

VPN privacy promises rest on trusting third party more than your ISP. The marketing claims: VPNs encrypt traffic, hide browsing from ISP, protect on public WiFi, enable geo-spoofing. The reality: you're shifting trust from ISP (regulated, accountable, visible) to VPN provider (often anonymous, jurisdiction-shopping, incentivized to monetize your data). Most VPN companies operate opaquelyâ€”who owns them? Where are servers located? Do they log traffic despite "no logging" claims? Have they been audited? The investigation reveals sketchy practices: shared infrastructure across competing "brands," ownership by data brokers, connections to malware distribution, marketing through sponsored content disguised as journalism. The fundamental problem: VPN privacy depends entirely on provider trustworthiness, which is nearly impossible to verify. For most users, VPNs provide security theaterâ€”feeling of protection without meaningful privacy gain, possibly creating new vulnerabilities.

### [Big Win For Open Access, As University Of California Cancels All Elsevier Subscriptions, Worth $11 Million A Year](https://www.techdirt.com/articles/20190304/09220141728/big-win-open-access-as-university-california-cancels-all-elsevier-subscriptions-worth-11-million-dollars-year.shtml)

The move to open access resources, whereby anyone can read academic papers for free, is on a long, hard journey. However, the victories are starting to build up, and here's another one that could have important wider ramifications for open access, especially in the US. The [University of California system indicated this week](https://www.universityofcalifornia.edu/press-room/uc-terminates-subscriptions-worlds-largest-scientific-publisher-push-open-access-publicly) that they are moving to an open access model. They did this in grand fashion by canceling all of their subscriptions to Elsevier.

The problems faced by the University of California (UC) are the usual ones. The publishing giant [Elsevier](https://www.techdirt.com/blog/?company=elsevier) was willing to move to an open access model â€“ but only if the University of California paid even more on top of what were already "rapidly escalating costs". To its credit, the institution instead decided to walk, depriving Elsevier of around [$11 million a year](http://faculty.econ.ucsb.edu/~tedb/Journals/BigDeals/UCalifornia/ElsevierSD2014-2018.pdf) (pdf).

UC's Elsevier cancellation represents major escalation in open access battles. The absurd system: publicly-funded researchers conduct studies, write papers, peer review others' work (unpaid), then universities pay publishers massive fees to access research they created. Elsevier's profit margins (37%) exceed Apple's, extracted from publicly-funded scholarship. Publishers claim they add value through editing, formatting, distributionâ€”but digital publishing costs approach zero while subscription prices climb 5-7% annually. UC's leverage: 10-campus system, major research output, collective bargaining power. The risk: faculty and students temporarily lose access to paywalled journals. The bet: alternative access methods (interlibrary loan, preprint servers, author copies) plus pressure on Elsevier will prove sustainable. The stakes: if UC succeeds, other institutions follow, potentially breaking publishing oligopoly strangling scholarly communication. Open access isn't just about free papers but restructuring knowledge production away from profit extraction toward public benefit.

### [YouTube: Okay What If We Suggest Racist Videos But Add Context?](https://theoutline.com/post/7146/youtube-moves-to-combat-misinformation-by-fact-checking-users-searches?zd=3&zi=xtv6kxov)

[Arimeta Diop](https://twitter.com/arimeta_d) in The Outline on an attempt by YouTube to curb the proliferation of false information on their platform. The online video giant has started rolling out a new feature that will fact-check user's searches.

[YouTube's algorithm](https://www.buzzfeednews.com/article/carolineodonovan/down-youtubes-recommendation-rabbithole) can take a user from a benign news report from a reputable source to content from anti-immigrant hate groups in just a few clicks through their "Up Next" recommendations. With the new feature, when a user searches a topic that has been at the center of controversy or "prone to misinformation," an "information panel" debunking and offering accurate information from fact checkers will then appear, [Buzzfeed reports](https://www.buzzfeednews.com/article/pranavdixit/youtube-debunk-information-panels-india).

YouTube's fact-checking panels treat symptom while ignoring disease. The actual problem: recommendation algorithm optimizes for engagement (watch time, clicks, session duration) which systemically promotes inflammatory, conspiratorial, extreme content because outrage drives engagement. The documented pipeline: someone watches mainstream news, algorithm recommends increasingly extreme content, within hours they're watching white nationalist propaganda or conspiracy theories. YouTube knows thisâ€”their own research showed radicalization pipelineâ€”but fixing recommendation algorithm would reduce engagement metrics and ad revenue. So instead: information panels! Small text boxes with fact-checks that most users ignore, addressing search results while recommendation engine continues radicalizing. It's classic platform evasion: implement visible but ineffective intervention to deflect criticism while preserving problematic core functionality. Real solution would be redesigning recommendation algorithm to prioritize accuracy and diversity over engagement, but that requires sacrificing profit for responsibility.

### [There's No Such Thing as a "Tech Person" in the Age of AI](https://www.technologyreview.com/s/613063/ai-ethics-mit-college-of-computing-tech-humanities/)

[Karen Hao](https://twitter.com/_karenhao) in Technology Review on the need to stop perpetuating the false dichotomy between technology and the humanities.

> In hindsight, this separation hasn't served us so well. As Henry Kissinger [wrote](https://www.theatlantic.com/magazine/archive/2018/06/henry-kissinger-ai-could-mean-the-end-of-human-history/559124/) in the June 2018 issue of the Atlantic: "The Enlightenment started with essentially philosophical insights spread by a new technology. Our period is moving in the opposite direction. It has generated a potentially dominating technology in search of a guiding philosophy."

That so-called dominating technology is artificial intelligence. Its sudden rise has already permeated every aspect of our lives, transforming our social, political, and economic systems. We no longer live in a society that reflects our old, manufactured separations. To catch up, we need to restructure the way we learn and work.

Hao identifies the Enlightenment reversal: philosophy driving technology versus technology seeking philosophy. AI systems now make decisions about bail, hiring, credit, content moderation, medical diagnosisâ€”embedding values, perpetuating biases, reshaping societyâ€”without coherent ethical framework. The "tech person" versus "humanities person" divide creates engineers who build powerful systems without understanding social implications and humanists who critique systems without understanding technical constraints. Neither alone is equipped for AI age. The integration challenge: teaching computer scientists about ethics, bias, fairness, social context while teaching humanists about algorithms, data structures, machine learning mechanics. MIT's College of Computing attempts this through mandatory ethics requirements and interdisciplinary collaboration. The deeper issue: education system structured around artificial disciplinary boundaries when actual problems (algorithmic bias, misinformation, privacy, automation) require integrated knowledge. Building ethical AI requires people who are simultaneously technical and humanisticâ€”not "tech people" or "humanities people" but humans equipped to think across domains.

### [Is Your Child an Orchid or a Dandelion? Unlocking the Science of Sensitive Kids](https://www.kqed.org/mindshift/53207/is-your-child-an-orchid-or-a-dandelion-unlocking-the-science-of-sensitive-kids)

I've recently been researching a bit more about technology use in early childhood. As part of this, I've been intrigued by the framework developed by Thomas Boyce and colleagues at the University of California, San Francisco. The group studies the human response to stress and examines this in the lives of children.

They suggest that most kids tend to be like dandelions, fairly resilient and able to cope with stress and adversity in their lives. But a minority of kids, those he calls "orchid children," are more sensitive and biologically reactive to their circumstances, which makes it harder for them to deal with stressful situations.

The orchid-dandelion framework describes differential susceptibility to environmental influences. Dandelion children (roughly 80%) are resilientâ€”they cope reasonably well across varied circumstances, thriving adequately even in challenging environments. Orchid children (roughly 20%) have heightened biological reactivityâ€”elevated stress hormones, stronger physiological responses, greater sensitivity to both negative and positive experiences. In harsh environments, orchid children struggle more than dandelions, experiencing higher rates of illness, behavioral problems, emotional difficulties. But crucially: in supportive environments, orchid children don't just do equally wellâ€”they flourish beyond dandelions, showing exceptional creativity, empathy, academic achievement. The implication: orchid children aren't deficient but differently calibrated, requiring more careful environmental cultivation. For parenting and education: one-size-fits-all approaches miss that some children need more support, stability, and nurturance to thrive, while benefiting more dramatically when provided. For technology debates: orchid children likely more susceptible to both harms and benefits of digital environments, requiring more individualized rather than universal screentime rules.

---

## ðŸ”¨ Do

### Work-Life Balance Strategies

If you feel constantly overwhelmed - like you've always got too much to do and not enough time to do it in - then you're in the same boat Frank has been in for several months. In this video he details the plan that he has been putting into action in order to strike a better work-life balance.

Chronic overwhelm signals mismatch between commitments and capacity. The typical responsesâ€”work harder, sleep less, multitask moreâ€”deepen the problem by ignoring that time is fundamentally limited. Better approaches: ruthless prioritization (saying no to good opportunities for sake of great ones), time blocking (protecting focused work periods), energy management (recognizing different tasks require different mental states), boundary setting (distinguishing urgent from important). The cultural challenge: hustle culture treats overwhelm as badge of honor and rest as weakness. Sustainable productivity requires acknowledging human limitations and structuring work accordingly rather than demanding infinite capacity.

---

## ðŸ¤” Consider

> "The grass is greener where you water it." â€” Neil Barringham

Barringham's metaphor challenges comparative thinking underlying many issues this week. VPN users seeking greener privacy pastures often trade known surveillance for unknown risks. Open access advocates water scholarly communication rather than envying publishing profits. YouTube's fact-checking panels ignore that they should be watering recommendation algorithm instead. Orchid children need more frequent watering than dandelions but bloom more beautifully when properly tended. The insight applies to technology debates broadly: instead of assuming grass is greener with different platforms, devices, or rules, cultivate intentional practices with tools you have.

---

## ðŸ”— Navigation

**Previous**: [[03 CREATE/ðŸ“§ Newsletter/TLDR 187\|TLDR 187]] â€¢ **Next**: [[03 CREATE/ðŸ“§ Newsletter/TLDR 189\|TLDR 189]] â€¢ **Archive**: [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

**ðŸŒ± Connected Concepts**:

- [[Momo Challenge Hoax\|Momo Challenge Hoax]] â€” Viral urban legend demonstrating how moral panics spread through social media amplification faster than evidence with media reporting on concerns generating more panic in [[Digital Folklore\|Digital Folklore]].
- [[Open Access Movement\|Open Access Movement]] â€” University of California canceling $11 million Elsevier subscriptions represents major victory against publishing monopolies strangling scholarly communication through profit extraction in [[Academic Publishing\|Academic Publishing]].
- [[AI Humanities Integration\|AI Humanities Integration]] â€” [[Karen Hao\|Karen Hao]] arguing false tech-humanities dichotomy leaves us with technology seeking guiding philosophy requiring restructured education in [[Interdisciplinary Education\|Interdisciplinary Education]].
- [[Orchid Dandelion Framework\|Orchid Dandelion Framework]] â€” [[Thomas Boyce\|Thomas Boyce]] distinguishing resilient dandelion children from sensitive orchid children with heightened biological reactivity requiring different environmental support in [[Developmental Psychology\|Developmental Psychology]].
- [[Platform Responsibility\|Platform Responsibility]] â€” YouTube adding fact-checking panels while recommendation algorithm continues radicalization reveals surface intervention avoiding systemic fixes prioritizing engagement over accuracy in [[Algorithmic Accountability\|Algorithmic Accountability]].

---

*Part of the [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]] archive documenting digital literacy and technology.*
