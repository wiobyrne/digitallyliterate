---
{"dg-publish":true,"dg-permalink":"dl-413","permalink":"/dl-413/","title":"The Glass City Paradox","tags":["ai-literacy","education-policy","information-integrity","surveillance-capitalism","critical-pedagogy","digital-sovereignty","infrastructure"]}
---

# DL 413

**Published**: November 23, 2025 â€¢ [[03 CREATE/ğŸ“§ Newsletter/ğŸ“§ Newsletter\|ğŸ“§ Newsletter]]

**The Glass City Paradox**

**When Technology Shines, but the Foundation Cracks**

Weâ€™ve built a **City of Glass**: dazzling with technological power, but terrifyingly brittle underneath. In this issue, I explore how our digital world amplifies us, and exposes us, too. We talk about AIâ€™s double-edged nature, how fragile the internet really is, and why trust in our institutions feels more fragile than ever.

If you've found value in these issues, [subscribe here](https://buttondown.email/digitallyliterate) or [support me here on Ko-fi.](https://ko-fi.com/wiobyrne)

## ğŸ”– Key Takeaways

- **AIâ€™s Paradox**: AI can expand human capacity, but it also risks deskilling us and fueling large-scale misinformation when guardrails fail.
- **Fragile Foundations**: The Cloudflare outage and FCC cybersecurity rollback show how dependent we are on brittle, aging infrastructure run by a handful of providers.
- **Eroding Trust**: From Metaâ€™s youth harms to manipulated public-health information, institutions meant to protect us are increasingly shaping, or distorting, what we see as true.
- **Shifting Power**: Schools, states, and communities are beginning to push back with audits, new AI governance models, and tools that prioritize user agency and data sovereignty.

## ğŸ“š Recent Work

This week I published the following:
- [From Scrap Hardware to Stable Proxmox: Building the Core of My Homelab](https://wiobyrne.com/building-the-core-of-my-homelab/) - The latest in my homelab series. In this post I discuss using Proxmox for my services.
- [The Illusion of Simplicity](https://wiobyrne.com/the-illusion-of-simplicity/) - A followup to my earlier post about prompt engineering and moving to conversations with your AI tools. 

## ğŸš€ğŸ“‰ AI: Elevator or Crutch?

AI is transforming how we think, learn, and make decisions. But the big question remains. Is AI lifting us up, or quietly weakening our core skills? This tension is at the heart of this weekâ€™s story.
### Cognitive Deskilling: When Convenience Costs Us
More people are leaning on AI and smart tools for everyday thinking, providing summaries, reports, explanations, even opinions. This shift toward _â€œThinking as a Serviceâ€ (TaaS)_ is incredibly convenient, but it comes with a hidden cost.

Patterns of AI dependence may contribute to [**cognitive deskilling**](https://www.andyhillier.systems/ThinkingAsAService.html), a gradual erosion of our ability to research, analyze, and evaluate on our own.

Historically, deskilling has been [a strategy used in capitalist systems](https://www.theatlantic.com/ideas/archive/2025/10/ai-deskilling-automation-technology/684669/) to separate _conception_ from _execution_: a small group holds the high-level knowledge while everyone else simply carries out tasks. AI risks accelerating this divide by shifting more intellectual labor to machines.
### AI as an Augmenter, Not a Job Killer
Despite fears of mass job loss, current research paints a different picture. Studies show that **AI hasnâ€™t reduced working hours or earnings** in many fields; instead, itâ€™s acting as a _performance booster_ for humans.

A recent report from the University of Chicago finds [**no measurable reduction** in hours worked or pay](https://bfi.uchicago.edu/wp-content/uploads/2025/04/BFI_WP_2025-56-1.pdf), suggesting AI is enhancing, not replacing, professional work.

Researchers describe this emerging dynamic as _Connected Intelligence_: a collaborative partnership where humans and AI agents work side-by-side, each doing what they do best.  
More here: [https://www.sciencedirect.com/science/article/pii/S2773032824000154](https://www.sciencedirect.com/science/article/pii/S2773032824000154)

But thereâ€™s a catch: this augmented future only works with fast, reliable, low-latency internet. Without it, the collaboration breaks down.
### The Information Integrity Crisis
AI doesnâ€™t just assist us. It also floods the information ecosystem with content, and not all of it trustworthy.

- **Disinformation gets easier:** Googleâ€™s Gemini and Nano Banana Pro models can now [generate strikingly realistic images](https://www.theverge.com/report/826003/googles-nano-banana-pro-generates-excellent-conspiracy-fuel) of highly sensitive historical events (JFK, 9/11) with little resistance. That makes it easier for bad actors to seed false narratives.
- **Truth gets blurrier:** Even the strongest language models still struggle with reliable facts. A recent _Nature_ article shows that state-of-the-art LLMs still [miss nearly **30% of basic general-knowledge questions**](https://www.nature.com/articles/s42256-025-01113-8).

This combination, easy disinformation + inconsistent accuracy, creates a powerful challenge for public understanding and trust.

## ğŸŒğŸ“‰ The Cracks in Our Digital Infrastructure
The second big story this month is about how shaky our digital foundation really is. From fragile internet systems to political fights over who gets to regulate (or deregulate) the tech we depend on every day.
### Internet Outages Reveal System Fragility
This monthâ€™s widespread outage across major services (X, ChatGPT, Amazon, Spotify, and more) highlighted just how vulnerable our internet infrastructure can be.

The trigger? A single configuration file at Cloudflare that [grew bigger than the system could handle](https://blog.cloudflare.com/18-november-2025-outage/), causing a domino effect that disrupted apps around the world.

For users, it was a reminder that so much of the internet runs through just a few companies. As coverage in ZDNet noted, [when Cloudflare goes down, a huge portion of the web goes with it](https://www.zdnet.com/article/major-cloudflare-outage-took-down-chatgpt-x-and-spotify-tuesday-heres-what-happened/).
### Federal Power Grab Over AI Regulation
AI regulation is becoming a fierce political battleground. The Trump administration is reportedly considering an executive order that would give the federal government exclusive authority over AI laws, sidelining states that want stronger protections.

[According to The Verge](https://www.theverge.com/ai-artificial-intelligence/824608/trump-executive-order-ai-state-laws), the proposal would also create an _â€œAI Litigation Task Forceâ€_ to challenge state laws that industry groups find burdensome. [Coverage in _Wired_ frames the move](https://www.wired.com/story/trump-prepares-executive-order-challenging-state-ai-laws/](https://www.wired.com/story/trump-prepares-executive-order-challenging-state-ai-laws/) as an effort to combat what the administration calls â€œwokeâ€ or restrictive AI rules at the state level. Potentially even tying federal broadband or tech grants to states aligning with federal AI policy. 

No matter where one stands politically, this is a major shift. It centralizes power over AI regulation in Washington and weakens local control.
### Cybersecurity Rollbacks at the FCC
In another surprising move affecting digital safety, the Federal Communications Commission voted 2â€“1 to scrap rules requiring phone and internet companies to meet minimum cybersecurity standards.

[The decision rolls back protections](https://techcrunch.com/2025/11/21/despite-chinese-hacks-trumps-fcc-votes-to-scrap-cybersecurity-rules-for-phone-and-internet-companies/](https://techcrunch.com/2025/11/21/despite-chinese-hacks-trumps-fcc-votes-to-scrap-cybersecurity-rules-for-phone-and-internet-companies/) put in place during the Biden administration, despite ongoing concerns about foreign hacking and critical-infrastructure vulnerabilities. 

Critics warn this could make the U.S. more vulnerable to breaches, while supporters argue it reduces regulatory burden. Either way, itâ€™s a major shift in how we approach national cyber defense.

## âš–ï¸ğŸ”’ Trust, Control & Power in the Digital Age
This monthâ€™s biggest story sits right at the intersection of trust, technology, and who actually has control over the systems we rely on. Across health, social media, and education, weâ€™re seeing what happens when powerful digital platforms fail to act responsibly, and how those choices ripple out into the lives of everyday people.
### Social Media, Youth Safety & the Meta Revelations
Newly unsealed court filings allege that Meta (Facebook/Instagram) knew its platforms were harmful to young people, and did far too little about it.

According to the disclosures, [Meta was aware that its apps could be addictive and worsen mental health issues for teens](https://time.com/7336204/meta-lawsuit-files-child-safety/). Yet executives allegedly **pushed aside safety recommendations** if they threatened growth.

Some of the most troubling details include:
- A **â€œ17 strikesâ€** tolerance before removing accounts involved in _sex trafficking_
- Safety features being shelved because they might reduce engagement
- Millions of preventable â€œinappropriate interactions with childrenâ€

These filings reinforce a hard truth: when engagement becomes the top priority, safety often loses.
### Public Health & the Erosion of Trust
Another worrying development this month. The integrity of official public-health information was further compromised.

The [CDCâ€™s website was altered to suggest a false link between vaccines and autism](https://www.pbs.org/newshour/health/cdc-vaccine-safety-webpage-changed-to-contradict-scientific-conclusion-that-vaccines-dont-cause-autism).

This contradicts decades of rigorous scientific research, and it wasnâ€™t an accident. When political pressure reshapes scientific communication, it undermines the publicâ€™s ability to trust critical health guidance. Research shows that [even small cracks in trust can have major consequences](https://pmc.ncbi.nlm.nih.gov/articles/PMC9421549/) during real emergencies.
### Surveillance in Schools: The Proctorio Case
Education isnâ€™t immune from these issues either. A long-running legal battle between librarian Ian Linkletter and the remote-proctoring company Proctorio finally settled, but the implications remain significant.

The case centered on Linkletter sharing [publicly available Proctorio training videos](https://arstechnica.com/tech-policy/2025/11/proctorio-settles-curious-lawsuit-with-librarian-who-shared-public-youtube-videos/) to raise concerns about:
- Invasive surveillance of students
- Algorithmic bias and error rates
- A chilling effect on public conversation about EdTech
- Lack of transparency in tools that make high-stakes decisions

Educators and researchers are responding by pushing for practices such as Algorithmic Impact Assessments. This is essentially, a health-and-safety inspection for AI tools before theyâ€™re allowed into classrooms. Initiatives like the [Data & Society Algorithmic Impact Methods Lab](https://datasociety.net/research/algorithmic-impact-methods-lab/) are helping schools understand how to evaluate these systems responsibly.

## ğŸ¤” Consider

> We build our computer systems the way we build our citiesâ€”over time, without a plan, on top of ruins.
> â€” Ellen Ullman

Our societyâ€™s relationship with technology is defined by a paradox. We live surrounded by systems of immense power. AI models that amplify our abilities, networks that link billions, platforms that shape our social and civic lives. Yet these systems are more fragile, more opaque, and more easily abused than we care to admit.

The City of Glass offers clarity and brilliance, but also exposure. Its cracks show where trust is thinning, where infrastructure is brittle, and where our cognitive foundations are shifting beneath us.

But this isnâ€™t a story of collapse, itâ€™s a call to _craftsmanship_:
- to build tools that strengthen, not replace, human judgment
- to design infrastructures that serve communities, not corporations
- to create digital ecosystems where truth, safety, and sovereignty are assumptions, not add-ons

If we build with care, transparency, and agency, the City of Glass can become something better:  
a place where technology reflects our best values, not our blind spots.

## âš¡ What You Can Do This Week

- **Ask What You Depend On**: List the three digital services you rely on most (cloud storage, calendar, chat, etc.). Explore whether there are open-source or self-hosted alternatives you could try, even part-time.
- **Be a Thoughtful Consumer of AI**: Use AI as a partner, not a replacement, and keep exercising your own mental muscles.When using summaries or tools powered by AI, pause and ask: _What skills is this replacing?_ _What might I be losing by outsourcing this thinking?_ 
- **Demand Digital Ethics**: If your school, workplace, or community is adopting AI tech, ask for transparency. How are decisions made? Whoâ€™s accountable? Are impact assessments in place?
- **Support Digital Sovereignty**: Consider contributing to or using platforms like Nextcloud. Spread the word: sovereignty is not just a â€œtechieâ€ issue. Itâ€™s about democracy, trust, and our ability to shape the future.

## ğŸ”— Navigation

**Previous**: [[03 CREATE/ğŸ“§ Newsletter/DL 412\|DL 412]] â€¢ **Next**: [[DL 414\|DL 414]] â€¢ **Archive**: [[03 CREATE/ğŸ“§ Newsletter/ğŸ“§ Newsletter\|ğŸ“§ Newsletter]]

**ğŸŒ± Connected Concepts**:

- **[[World Models\|World Models]]** â€” Why AI systems grounded in physical and causal reality matter more than next-token prediction.
- **[[AI Literacy\|AI Literacy]]** â€” Core competencies for evaluating, questioning, and contextualizing AI outputs.
- **[[Engagement vs Learning\|Engagement vs Learning]]** â€” How design incentives in EdTech shape outcomes for students and institutions.
- **[[02 DEVELOP/ğŸŒ¿ Plants/Surveillance Capitalism\|Surveillance Capitalism]]** â€” The economic logic behind the failures of Meta, Proctorio, and engagement-driven platforms.
- **[[Privacy by Design\|Privacy by Design]]** â€” Principles for building resilient systems that minimize harm and maximize autonomy.
- **[[Digital Sovereignty\|Digital Sovereignty]]** â€” Why owning your data, stack, and infrastructure becomes essential in a brittle digital world.
- **[[Infrastructure as Literacy\|Infrastructure as Literacy]]** â€” Understanding outages, protocols, and governance as part of digital citizenship.