---
{"dg-publish":true,"dg-permalink":"dl-271","permalink":"/dl-271/","title":"The Coming War","tags":["ai-ethics","algorithms","timnit-gebru","proctoring","teacher-burnout","poverty-trap"]}
---


# DL 271
## The Coming War

**Published**: December 5, 2020 â€¢ [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

Welcome to *Digitally Literate*, issue #271. Your go-to source for insightful content on education, technology, and the digital landscape.

## ðŸ”– Key Takeaways
- **AI Ethics Crisis**: Google fires Timnit Gebru after she questions large language models and voices frustration over diversity efforts
- **Algorithmic Poverty Traps**: Credit scoring algorithms trap poor people in cycles of denial for housing, jobs, and basic services
- **Proctoring Surveillance**: Online exam monitoring invades privacy and undermines the integrity institutions demand students uphold
- **Teacher Burnout**: Pandemic teaching conditions are unsustainable and threaten to lose an entire generation of educators

---

Thank you for being here. You are valued.

This week I worked on the following:

- *[Trust, But Verify](https://wiobyrne.com/trust-but-verify/)* - Users of the Internet become pawns in a flow of information that circulates endlessly in the ether causing a contagion that is nearly insurmountable.
- *[Shades of Gray](https://wiobyrne.com/shades-of-gray/)* - Absolute truth becomes even more subjective as there are very few things that are clearly right or wrong.

If you haven't already, please [subscribe](https://digitallyliterate.net/subscribe/) if you would like this newsletter to show up in your inbox. Feel free to reach out and say hey at [hello@digitallyliterate.net](mailto:hello@digitallyliterate.net).

## ðŸ“º Watch

### [1981 Nightline interview with Steve Jobs](https://www.youtube.com/watch?v=3H-Y-D3-j-M)

Ted Koppel, Bettina Gregory, and Ken Kashiwahara present news stories from 1981 on the relevancy of computers in every day life and how they will affect our future. Included are interviews with Apple Computer Chairman Steve Jobs and writer David Burnham.

## ðŸ“š Read

### [Google Researcher Says She Was Fired Over Paper Highlighting Bias in A.I.](https://www.nytimes.com/2020/12/03/technology/google-researcher-timnit-gebru.html)

Timnit Gebru, a prominent a co-leader of the Ethical Artificial Intelligence team at Google sent [an email to her colleagues](https://www.platformer.news/p/the-withering-email-that-got-an-ethical) voicing exasperation over the company's response to efforts to increase minority hiring.

Gebru had been working on a research paper that she hoped to publish, but ran into resistance from her superiors at Google. And so she sent a letter expressing her frustration to the internal listserv Google Brain Women and Allies.

[The paper](https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/), titled "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" lays out the risks of large language modelsâ€”AIs trained on staggering amounts of text data.

A few days later, Gebru was fired â€” Google reportedly found the email "inconsistent with the expectations of a Google manager." It details the struggles Gebru experienced as a Black leader working on ethics research within the company, and presents a bleak view of the path forward for underrepresented minorities at the company.

### [The coming war on the hidden algorithms that trap people in poverty](https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/)

A growing group of lawyers are uncovering, navigating, and fighting the automated systems that deny the poor housing, jobs, and basic services.

*Credit scores have been used for decades to assess consumer creditworthiness, but their scope is far greater now that they are powered by algorithms: not only do they consider vastly more data, in both volume and type, but they increasingly affect whether you can buy a car, rent an apartment, or get a full-time job. Their comprehensive influence means that if your score is ruined, it can be nearly impossible to recover. Worse, the algorithms are owned by private companies that don't divulge how they come to their decisions. Victims can be sent in a downward spiral that sometimes ends in homelessness or a return to their abuser.*

### [Online exam monitoring can invade privacy and erode trust at universities](https://theconversation.com/online-exam-monitoring-can-invade-privacy-and-erode-trust-at-universities-149335)

[Bonnie Stewart](https://bonstewart.com/) on the testing and proctoring methods that invade privacy and erode trust end up undermining the very integrity that institutions demand students uphold.

As institutions of higher ed turn to online proctoring in the name of academic integrity the risks of exchanging the four walls of the classroom for surveillance platforms may be higher than many institutions bargained for.

As Stewart points out at the end of the piece, higher ed doesn't need proctoring. Timed tests value what students remember.

> Is memorization really a valid educational reason for risking privacy, well-being, and tight university budgets in a world where students will spend most of their lives with Google in their pockets?

### [Examining Screen Time, Screen Use Experiences, and Well-Being in Adults](https://www.scirp.org/Journal/PaperInformation.aspx?PaperID=81683)

This study examined the relationship between screentime and well-being in adults, including positive relationships, meaning, and loneliness. The study is possibly the first to investigate how much pleasure and meaning people feel during screen use and their mediating effects.

Screentime was not found to be significantly correlated with well-being; and screen use experiences did not mediate any of the screen time and well-being relationships.

However, screen use meaning was positively associated with overall well-being and positive relationships. This finding prompts a review of the importance of screen time for well-being, suggesting that this may be a limited approach. Other factors related to screen quality may be equal if not more important for well-being.

### [Teaching in the Pandemic: 'This Is Not Sustainable'](https://www.nytimes.com/2020/11/30/us/teachers-remote-learning-burnout.html)

Teacher burnout will erode instructional quality, stymie working parents and hinder the reopening of the economy.

"If we keep this up, you're going to lose an entire generation of not only students but also teachers," said [Shea Martin](https://sheathescholar.medium.com/), an education scholar and facilitator who works with public schools on issues of equity and justice.

## ðŸ”¨ Do

### [Enhance Student Engagement with Virtual Social Learning Spaces](https://catlintucker.com/2020/11/virtual-social-learning-spaces/)

Caitlin Tucker with ideas and strategies for utilizing those shared spaces to create student-centered learning experiences.

- Zoom or Google Meet Breakout Rooms
- Google Docs, Slide Decks, Drawings, Sheets
- [Jamboard](https://jamboard.google.com/) and [Padlet](https://padlet.com/)
- [Wakelet](https://wakelet.com/)
- [Flipgrid](https://info.flipgrid.com/)

## ðŸ¤” Consider

### If you get tired, learn to rest, not to quit.
*Banksy*

---

## ðŸ”— Navigation

**Previous**: [[03 CREATE/ðŸ“§ Newsletter/DL 270\|DL 270]] â€¢ **Next**: [[03 CREATE/ðŸ“§ Newsletter/DL 272\|DL 272]] â€¢ **Archive**: [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

**Connected concepts**:
- [[AI Ethics and Corporate Power\|AI Ethics and Corporate Power]] - Timnit Gebru's firing from Google's AI ethics team represents a watershed moment showing how tech companies silence internal criticism. Her research on large language model bias threatened Google's business interests, revealing fundamental tensions between profit motives and ethical AI development. This connects to broader questions about whether corporations can self-regulate AI when doing so conflicts with their financial incentives.
- [[Algorithmic Poverty Traps\|Algorithmic Poverty Traps]] - Credit scoring algorithms demonstrate how automated systems perpetuate and deepen inequality. Unlike traditional credit scores, these opaque algorithms consider vast amounts of data to determine access to housing, employment, and services. Once trapped in a low score, recovery becomes nearly impossible, showing how technology can encode and amplify existing power structures rather than challenge them.
- [[Surveillance Proctoring Crisis\|Surveillance Proctoring Crisis]] - Online exam monitoring tools represent the surveillance creep into education, trading privacy for false assurances of academic integrity. The question "Is memorization really worth risking privacy?" connects to larger debates about assessment reform, trust in education, and whether institutions should deploy surveillance tech that undermines the very values they claim to uphold.

---

*Part of the [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]] archive documenting digital literacy and technology.*
