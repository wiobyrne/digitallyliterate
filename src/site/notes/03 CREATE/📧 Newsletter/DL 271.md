---
{"dg-publish":true,"dg-permalink":"dl-271","permalink":"/dl-271/","title":"The Coming War","tags":["timnit-gebru","algorithmic-poverty","online-proctoring","screen-time-research","teacher-burnout","1981-computers"]}
---

# DL 271

## The Coming War

**Published**: December 5, 2020 â€¢ [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

Welcome to *Digitally Literate*, issue 271. Your go-to source for insightful content on education, technology, and the digital landscape.

## ðŸ”– Key Takeaways
- **Google Fires AI Ethics Leader**: Timnit Gebru fired for email criticizing diversity effortsâ€”presents bleak view for underrepresented minorities at company
- **Algorithms Create Poverty Traps**: Credit scores powered by algorithms affect cars, apartments, jobsâ€”if score is ruined, recovery is nearly impossible
- **Proctoring Erodes Trust**: Testing methods that invade privacy undermine the very integrity institutions demand students uphold
- **Screen Time Isn't the Problem**: Study finds screen time not significantly correlated with well-beingâ€”quality matters more than quantity
- **Teacher Burnout Is Unsustainable**: If we keep this up, we'll lose an entire generation of not only students but also teachers

---

Hi all, welcome back. Take a look around.

This week I worked on the following:

- [Trust, But Verify](https://wiobyrne.com/trust-but-verify/) - Users of the Internet become pawns in a flow of information that circulates endlessly causing a contagion that is nearly insurmountable.
- [Shades of Gray](https://wiobyrne.com/shades-of-gray/) - Absolute truth becomes even more subjective as there are very few things that are clearly right or wrong.

## ðŸ“º Watch

### [Computers in 1981](https://www.youtube.com/watch?v=5WCTn4FljUQ)

Ted Koppel, Bettina Gregory, and Ken Kashiwahara present news stories from 1981 on the relevancy of computers in everyday life and how they will affect our future. Included are interviews with Apple Computer Chairman Steve Jobs and writer David Burnham.

## ðŸ“š Read

### [Google Fires AI Ethics Leader Timnit Gebru](https://www.platformer.news/p/the-withering-email-that-got-an-ethical)

Timnit Gebru, a prominent co-leader of the Ethical Artificial Intelligence team at Google, sent an email to her colleagues voicing exasperation over the company's response to efforts to increase minority hiring.

Gebru had been working on a research paper that she hoped to publish, but ran into resistance from superiors. [The paper](https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/), titled "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" lays out the risks of large language models.

A few days later, Gebru was firedâ€”Google reportedly found the email "inconsistent with the expectations of a Google manager." It details the struggles Gebru experienced as a Black leader working on ethics research within the company, and presents a bleak view of the path forward for underrepresented minorities.

### [The Coming War on Hidden Algorithms That Trap People in Poverty](https://www.technologyreview.com/2020/12/04/1013068/algorithms-create-a-poverty-trap-lawyers-fight-back/)

A growing group of lawyers are uncovering, navigating, and fighting the automated systems that deny the poor housing, jobs, and basic services.

Credit scores powered by algorithms consider vastly more data and increasingly affect whether you can buy a car, rent an apartment, or get a full-time job. Their comprehensive influence means that if your score is ruined, it can be nearly impossible to recover. Worse, the algorithms are owned by private companies that don't divulge how they come to their decisions.

### [Online Exam Monitoring Can Invade Privacy and Erode Trust](https://theconversation.com/online-exam-monitoring-can-invade-privacy-and-erode-trust-at-universities-149335)

[Bonnie Stewart](https://bonstewart.com/) on the testing and proctoring methods that invade privacy and erode trust end up undermining the very integrity that institutions demand students uphold.

As Stewart points out, higher ed doesn't need proctoring. Timed tests value what students remember.

Is memorization really a valid educational reason for risking privacy, well-being, and tight university budgets in a world where students will spend most of their lives with Google in their pockets?

### [Screen Time and Well-Being in Adults](https://www.scirp.org/Journal/PaperInformation.aspx?PaperID=81683)

This study examined the relationship between screen time and well-being in adults.

Screen time was not found to be significantly correlated with well-being. However, screen use meaning was positively associated with overall well-being and positive relationships.

This finding prompts a review of the importance of screen time for well-being, suggesting that this may be a limited approach. Other factors related to screen quality may be equal if not more important.

### [Teaching in the Pandemic: 'This Is Not Sustainable'](https://www.nytimes.com/2020/11/30/us/teachers-remote-learning-burnout.html)

Teacher burnout will erode instructional quality, stymie working parents and hinder the reopening of the economy.

"If we keep this up, you're going to lose an entire generation of not only students but also teachers," said [Shea Martin](https://sheathescholar.medium.com/), an education scholar who works with public schools on issues of equity and justice.

## ðŸ”¨ Do

### [Online Collaborative Tools for Student-Centered Learning](https://catlintucker.com/2020/12/shared-spaces/)

Caitlin Tucker with ideas and strategies for utilizing shared spaces:

- Zoom or Google Meet Breakout Rooms
- Google Docs, Slide Decks, Drawings, Sheets
- [Jamboard](https://jamboard.google.com/) and [Padlet](https://padlet.com/)
- [Wakelet](https://wakelet.com/)
- [Flipgrid](https://info.flipgrid.com/)

## ðŸ¤” Consider

### The greatest crimes in the world are not committed by people breaking the rules but by people following the rules.

*Banksy*

Banksy's insight frames an issue about systemsâ€”Google following rules to fire an ethics researcher, algorithms following rules to trap people in poverty, proctoring software following rules to surveil students. The coming war isn't against individuals but against the rules themselves.

---

## ðŸ”— Navigation

**Previous**: [[03 CREATE/ðŸ“§ Newsletter/DL 270\|DL 270]] â€¢ **Next**: [[03 CREATE/ðŸ“§ Newsletter/DL 272\|DL 272]] â€¢ **Archive**: [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

**ðŸŒ± Connected Concepts**:

- **[[03 CREATE/ðŸŒ² Evergreens/Media Literacy\|Media Literacy]]** â€” Timnit Gebru firing, large language model dangers
- **[[Privacy Rights\|Privacy Rights]]** â€” Algorithmic poverty traps, credit score opacity, proctoring surveillance
- **[[Pedagogy\|Pedagogy]]** â€” Teacher burnout, collaborative tools, proctoring critique
- **[[Digital Wellbeing\|Digital Wellbeing]]** â€” Screen time research, quality over quantity
- **[[Philosophy\|Philosophy]]** â€” Banksy on rules, systems over individuals
