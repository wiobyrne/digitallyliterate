---
{"dg-publish":true,"dg-permalink":"dl-208","permalink":"/dl-208/","title":"Data Rights are Human Rights","tags":["digital-literacy","education-technology","data-rights","human-rights-data","voter-privacy-act","dianne-feinstein","cambridge-analytica-response","david-carroll-rights","right-to-know","right-to-own","right-to-review","right-to-remove","right-to-refuse","capital-one-hack","data-breach","pearson-breach","equifax-aftermath","matt-blaze","radioactive-data","jonathan-zimmerman","civil-discourse","controversial-issues","teaching-disagreement","college-news-engagement","multimodal-consumption","social-life-news","peer-credibility","gltr-tool","ai-detecting-ai","fake-text-detection","harvard-mit-ibm","disinformation-steps","brookings-recommendations","algorithm-awareness","news-cycle-stress","self-care-news","daniel-keys-moran","data-information","data-society"]}
---

# DL 208

## Data Rights are Human Rights

**Published**: 2019-08-03 â€¢ [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

Welcome to issue 208. Data rights are human rights.

Hi all, my name is [Ian O'Byrne](https://wiobyrne.com/start/) and welcome to Digitally Literate. In this newsletter I distill the news of the week in technology into an easy-to-read resource. Thank you for reading.

---

## ðŸ”– Key Takeaways

- **Legislative Response Emerges**: Senator Feinstein's Voter Privacy Act is the first legislation directly responding to Cambridge Analytica's harvesting of 87 million voters' data.
- **Five Missing Rights**: David Carroll outlines data rights Americans lackâ€”right to know, own, review, remove, and refuseâ€”that Europeans gained through GDPR.
- **Breach Inevitability**: Capital One and Pearson hacks demonstrate that after Equifax consequences failed to materialize, data breaches became inevitable cost of business.
- **AI Detecting AI**: Harvard and MIT's GLTR tool identifies AI-generated text by spotting statistical patterns too predictable for human writing.
- **Civil Discourse Skills**: Jonathan Zimmerman argues we must teach disagreement productively, distinguishing emotional conviction from argument quality.

---

## ðŸ“º Watch

### [Jonathan Zimmerman on Civil Discourse](https://bigthink.com/sponsored-institute-for-humane-studies/rules-for-civil-engagement-how-to-talk-with-someone-unlike-yourself)

Some practical ways to disagree and get along with someone at the same time from Jonathan Zimmerman. Zimmerman is Professor of History of Education at the Graduate School of Education at the University of Pennsylvania. His latest book is [The Case for Contention: Teaching Controversial Issues in American Schools](https://www.amazon.com/Case-Contention-Controversial-Philosophy-Education/dp/022645634X).

Key principles:
- Statements like, "You're a blankety-blank" close discussions rather than open them. Instead, say, "You know, that's interesting. That's not the way I see it. Tell me more about why you think that."
- Being more open about your intentions can help, too. Tell the person that you see the issue from a different angle, and ask them what they think of your view.
- A key rule for civil discourse, especially in this political climate, is to recognize the difference between emotion and argument. The depth of conviction with which something is said is not a substitute for argument quality or truth.

Zimmerman's framework addresses the discourse crisis underlying many issues this newsletter covers. Disinformation spreads partly because we've lost capacity for productive disagreementâ€”conversations become performance rather than inquiry. The emotion/argument distinction is crucial: passionate delivery can substitute for evidence, and calling out lack of evidence gets read as personal attack. Teaching controversial issues well requires modeling these skills: showing students that disagreement can be curious rather than hostile, that changing minds is possible without losing face, that conviction doesn't equal correctness. These are citizenship skills as fundamental as reading.

---

## ðŸ“š Read

### [Voter Privacy Act: First Cambridge Analytica Response](https://www.feinstein.senate.gov/public/_cache/files/4/4/44e9fcb2-66cf-43e0-ad73-f0502997010a/A0E53C2716084310E677BCA6621967B5.voter-privacy-act.pdf)

A US lawmaker, Senator Dianne Feinstein introduced a bill this week, the Voter Privacy Act, that would regulate how political parties use voters' data in federal elections. This legislation is the first to directly respond to Cambridge Analytica, which used Facebook to [harvest the data of 87 million voters](https://www.nytimes.com/2018/03/17/us/politics/cambridge-analytica-trump-campaign.html), often without permission, in hopes of influencing their behavior.

Thankfully, many are starting to have a discussion about basic data rights. Data rights are fundamentally human rights.

[David Carroll provides a great review](https://twitter.com/profcarroll/status/1157420352131276802) of the five basic rights that do not exist yet in the US:

- Right to Know
- Right to Own
- Right to Review
- Right to Remove
- Right to Refuse

Carroll's five rights frameworkâ€”know, own, review, remove, refuseâ€”provides clear criteria for evaluating data legislation. Europeans gained these through GDPR; Americans still lack them. "Right to know" means companies must tell you what data they have. "Right to own" means that data belongs to you, not them. "Right to review" means you can see and correct errors. "Right to remove" means you can demand deletion. "Right to refuse" means you can decline collection in the first place. The Voter Privacy Act addresses political data specifically, but the framework applies broadly. Until these rights exist comprehensively, data extraction continues as default.

### [Capital One Hacked, Over 100 Million Affected](https://techcrunch.com/2019/07/29/capital-one-hacked-over-100-million-customers-affected/)

Capital One disclosed that they were hacked. The breach was first discovered on July 19th.

In a somewhat related story, education software maker Pearson indicated [a data breach affected thousands of accounts](https://techcrunch.com/2019/07/31/education-software-maker-pearson-says-data-breach-affected-thousands-of-accounts-in-the-u-s/) in the US. The [Wall Street Journal reports](https://www.wsj.com/articles/pearson-hack-exposed-details-on-thousands-of-u-s-students-11564619001) that the data breach happened in November 2018 and Pearson was notified by the FBI in March. The perpetrator is still unknown.

Another day, another data breach. After we didn't do anything about Equifax, these events will now be [inevitable](https://techcrunch.com/2019/07/29/capital-one-breach-was-inevitable/).

Matt Blaze indicates that perhaps we should handle data in the same way that we handle radioactive waste. "Best practice for protecting it is not to collect it in the first place, with potentially unlimited liability for those who mishandle it."

Blaze's radioactive waste analogy reframes data collection. Radioactive materials require extraordinary precautions because harm persists indefinitely; collected data similarly creates permanent vulnerability. The "inevitable" framing matters: Equifax exposed 147 million people with minimal consequences, teaching companies that breaches are survivable costs rather than existential threats. Capital One and Pearson follow logicallyâ€”why invest in security when failure carries no real penalty? The Pearson breach affecting students is particularly concerning: educational data collected about children creates lifelong vulnerability for people who never consented. The solution Blaze suggestsâ€”don't collect itâ€”challenges business models built on data accumulation.

### [How College Students Engage with News](https://journals.uic.edu/ojs/index.php/fm/article/view/10166/8057)

This research reports results from a mixed-methods study about how college students engage with news when questions of credibility and "fake news" abound in the U.S. Findings are based on 5,844 online survey responses, one open-ended survey question (N=1,252), and 37 follow-up telephone interviews with students enrolled at 11 U.S. colleges and universities.

Results shed light on the information seeking behaviors of young adults. Of interest to me is the social life of news, most respondents got news during the past week through discussions with peers (93 percent) whether face-to-face or online via text, e-mail, or using direct messaging on social media. The majority of respondents had news consumption habits that were multimodal (text, images, video, audio, etc.). Participants gave extra credibility to the source of the infoâ€¦if it was shared by a professor in this case.

The 93% peer discussion finding reveals how news actually circulates among young adultsâ€”not through direct consumption of news sources but through social mediation. Friends share, discuss, contextualize, and recommend. This has implications: news literacy education focused on evaluating sources misses how students actually encounter information. The professor credibility effect is interesting but potentially concerningâ€”authority figures can share misinformation too. Multimodal consumption reflects platform reality: news arrives as text, images, video, audio, often combined. Literacy education must address all modes, not just reading comprehension.

### [AI Tool to Spot AI-Generated Text](https://www.technologyreview.com/f/614021/a-new-tool-uses-ai-to-spot-text-written-by-ai/)

We're quickly approachingâ€¦if we haven't already arrivedâ€¦in a place where the machines are just talking to one another.

AI algorithms can generate text convincing enough to fool the average humanâ€”potentially providing a way to mass-produce fake news, bogus reviews, and phony social accounts. Thankfully, AI can now be used to identify fake text, too.

Researchers from [Harvard University](https://nlp.seas.harvard.edu/) and the [MIT-IBM Watson AI Lab](https://mitibmwatsonailab.mit.edu/) have developed a [new tool](https://arxiv.org/abs/1906.04043) for spotting text that has been generated using AI. Called the Giant Language Model Test Room (GLTR), it exploits the fact that AI text generators rely on statistical patterns in text, as opposed to the actual meaning of words and sentences. In other words, the tool can tell if the words you're reading seem too predictable to have been written by a human hand.

Interested? [Try it here](http://gltr.io/dist/index.html).

GLTR represents arms race logic: AI generates convincing text, so AI must detect AI text. The "too predictable" detection method exploits how language models workâ€”they predict likely next words, producing text that's statistically typical. Humans write less predictably, choosing unexpected words, making idiosyncratic errors, expressing genuinely novel ideas. As generation improves, detection must improve correspondingly. The tool's availability matters for educators, journalists, and anyone evaluating text authenticity. But the deeper concern: when AI-generated text becomes indistinguishable from human writing, what happens to trust in written communication itself?

### [Four Steps to Stop Disinformation](https://www.brookings.edu/blog/techtank/2019/07/23/four-steps-to-stop-the-spread-of-disinformation-online/)

While preserving democratic and economic institutions in the digital era will require more action from governments and platforms, we the people also need to recognize our responsibilities in these new spaces.

Here are four simple ways to do your part in fighting back:

- Know your algorithm
- Retrain your newsfeed
- Scrutinize your news sources
- Consider not sharing

The Brookings recommendations place responsibility on individuals, which is both necessary and insufficient. "Know your algorithm" means understanding that platforms show you content optimized for engagement, not accuracy. "Retrain your newsfeed" involves deliberately seeking diverse sources rather than accepting algorithmic curation. "Scrutinize your sources" requires evaluation skills many lack. "Consider not sharing" addresses amplificationâ€”the pause before retweet that could prevent spread. These individual actions matter but can't substitute for platform design changes and regulatory frameworks. The burden shouldn't fall entirely on users to resist systems designed to manipulate them.

---

## ðŸ”¨ Do

### [Managing the News Cycle Stress](https://www.fastcompany.com/90384055/how-to-stay-grounded-and-productive-in-the-news-cycle)

The emotionally draining news cycle doesn't show any signs of slowing down. A clinical psychologist shares her thoughts on staying groundedâ€”and productive.

This post shares insight about dealing with the "news." I think this provides good advice for dealing with social media in general.

- Recognize the psychological effects of negative news exposure
- Consider the importance of self-care & channeling your frustrations
- Set boundaries when your job requires you to engage with the news
- Get yourself in the right headspace
- Know when to ask for help

The news cycle stress management advice recognizes what information overload does to mental health. Constant exposure to negative newsâ€”especially when we can't act on itâ€”creates helplessness and anxiety. The boundaries point matters most: those whose work requires news engagement (journalists, researchers, educators) face occupational hazard requiring intentional mitigation. Self-care isn't indulgence but sustainability. Channeling frustration into actionâ€”contacting representatives, supporting causes, creating contentâ€”transforms passive consumption into agency. Knowing when to ask for help acknowledges that news-induced distress can become clinical, requiring professional support.

---

## ðŸ¤” Consider

> "You can have data without information, but you cannot have information without data." â€” Daniel Keys Moran

Moran's distinction between data and information connects to this issue's themes. Cambridge Analytica had dataâ€”millions of data points about millions of people. They transformed it into informationâ€”psychological profiles predicting and influencing behavior. Data rights matter because data becomes information in hands of those who process it. The five rights Carroll articulatesâ€”know, own, review, remove, refuseâ€”address data before transformation, giving individuals power over raw material that becomes power over them.

---

## ðŸ”— Navigation

**Previous**: [[03 CREATE/ðŸ“§ Newsletter/DL 207\|DL 207]] â€¢ **Next**: [[03 CREATE/ðŸ“§ Newsletter/DL 209\|DL 209]] â€¢ **Archive**: [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

**ðŸŒ± Connected Concepts**:

- [[Data Rights\|Data Rights]] â€” David Carroll's five rights framework (know, own, review, remove, refuse) that Americans lack and Voter Privacy Act beginning to address in [[Privacy Policy\|Privacy Policy]].
- [[Data Breaches\|Data Breaches]] â€” Capital One and Pearson hacks demonstrating post-Equifax inevitability with Matt Blaze's radioactive waste collection analogy in [[Cybersecurity\|Cybersecurity]].
- [[Civil Discourse\|Civil Discourse]] â€” Jonathan Zimmerman on teaching disagreement productively distinguishing emotional conviction from argument quality in [[Democratic Education\|Democratic Education]].
- [[AI Detection\|AI Detection]] â€” Harvard and MIT's GLTR tool spotting AI-generated text by identifying statistical patterns too predictable for human writing in [[Information Literacy\|Information Literacy]].
- [[News Literacy\|News Literacy]] â€” Research showing 93% of college students get news through peer discussion requiring social mediation focus in literacy education in [[03 CREATE/ðŸŒ² Evergreens/Media Literacy\|Media Literacy]].

---

*Part of the [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]] archive documenting digital literacy and technology.*
