---
{"dg-publish":true,"dg-permalink":"dl-191","permalink":"/dl-191/","title":"On Suffering & Surveillance","tags":["digital-literacy","education-technology","augmented-reality","virtual-reality","ar-vs-vr","immersive-technology","stoicism","silicon-valley-philosophy","tech-elite","self-mastery","intentional-suffering","nellie-bowles","power-structure","digital-privilege","chris-gilliard","privacy-abstraction","surveillance-pedagogy","kate-klonick","eavesdropping-exercise","vulnerable-populations","privacy-harms","internet-of-things","smart-home-devices","iot-safety","james-mullarkey","data-sovereignty","personal-data-rights","prison-labor","ai-training-data","vainu","finland-prisons","data-tagging","exploitation-vs-empowerment","phone-bans","classroom-technology","jamie-brooker","kahoot","digital-citizenship","technology-education","procrastination","emotion-regulation","future-self-stranger","temporal-discounting","self-control-myth","annalee-newitz","cosplay-defense","surveillance-evasion","identity-masking","technopanic-podcast","human-contact-luxury","screentime-class","slack-collaboration"]}
---

# DL 191

## On Suffering & Surveillance

**Published**: 2019-03-30 â€¢ [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

Welcome to Digitally Literate 191. On suffering & surveillance.

Hi all, my name is [Ian O'Byrne](https://wiobyrne.com/start/) and welcome to Digitally Literate. In this newsletter, I try to synthesize what happened this week so you can be digitally literate as well.

I posted a couple of other things this week:

- [The Technopanic Podcast](https://screentime.me/technopanic-podcast/) - My podcast with Kristen Turner continues. Subscribe on [iTunes](https://itunes.apple.com/us/podcast/technopanic-podcast-living-learning-in-age-screentime/id1453320328), [Spotify](https://open.spotify.com/show/2xnLc2qVa7Q2lkYN2F0W9i), [PocketCasts](https://pca.st/OCfk), or the podcast catcher of your choice.
- [Human contact is now a luxury good?](https://screentime.me/human-contact-is-now-a-luxury-good/) - A response to a recent piece from Nellie Bowles in the NY Times suggests that screentime can now be considered a luxury.
- [Using Slack as a hub for facilitating collaboration online and in person](https://www.youtube.com/watch?v=H4k9oDd7A8U&feature=youtu.be) - A brief overview of Slack, and what I'm looking for as I test out new alternatives for online collaborative spaces.

---

## ðŸ”– Key Takeaways

- **Stoicism as Status Quo**: Silicon Valley's embrace of intentional suffering reflects belief that current power structures are correctly setâ€”self-mastery replaces systemic critique.
- **Privacy Has Real Victims**: Chris Gilliard argues against treating privacy as abstract exercise, emphasizing surveillance pedagogy's concrete harms to vulnerable populations.
- **IoT Data Sovereignty**: Smart devices fail basic rights tests when individuals don't control what data is collected, its purpose, or how it's shared.
- **Prison Labor Evolves**: Finnish inmates training AI algorithms represents either valuable skill-building or new form of exploitation dressed as reform.
- **Procrastination Is Emotional**: We avoid tasks because our brains perceive future selves as strangersâ€”the solution requires emotional management, not productivity apps.

---

## ðŸ“º Watch

### [AR vs VR: What's the Difference?](https://www.youtube.com/watch?v=example)

This week my classes started playing with AR and VR using some high tech, and low tech tools and toys. This video discusses the fact that the two technologies are confusingly similar, but utterly different.

Augmented reality overlays digital information onto physical worldâ€”you see your actual environment enhanced with virtual elements through phone screen or glasses. Virtual reality replaces your environment entirelyâ€”headset blocks physical world and substitutes computer-generated space. AR augments reality; VR creates alternative reality. The distinction matters pedagogically: AR keeps students grounded in physical context while adding information layers, VR transports them to otherwise inaccessible places and perspectives. AR works with cheap devices (any smartphone); VR requires dedicated hardware. AR suits contextual learning (identifying plants in the field); VR enables impossible experiences (walking through historical events, exploring molecular structures). Both technologies raise presence questionsâ€”what happens when digital and physical blur?

---

## ðŸ“š Read

### [Silicon Valley's Stoicism Obsession](https://www.nytimes.com)

[Nellie Bowles](https://twitter.com/NellieBowles) in The NY Times on the possible reasons why the dominant thought leaders from Google to Apple are focused on inner virtues, self-mastery, and courage. This focus on Stoicism may be an indication that the "world and its current power structure are correctly set" and they need to just fit right in.

> Start-ups big and small believe their mission is to make the transactions of life frictionless and pleasing. But the executives building those things are convinced that a pleasing, on-demand life will make them soft. So they attempt to bring the pain.

The contradiction is telling: billionaires building platforms to eliminate friction in others' lives embrace personal friction as virtue. Cold showers, fasting, extreme exerciseâ€”suffering as status symbol. Stoicism historically emerged among those without power to change circumstances; tech's adoption inverts this, deployed by those with maximum power to avoid changing circumstances. If the problem is internal (weakness, distraction, insufficient discipline), the solution is personal transformation. If the problem is external (inequality, exploitation, concentration of power), the solution is systemic change. Stoicism conveniently locates all problems internally. The philosophy that once comforted the powerless now justifies the powerful.

### [Privacy's Not an Abstraction](https://www.fastcompany.com/90323529/privacy-is-not-an-abstraction)

Great piece by [Chris Gilliard](https://twitter.com/hypervisible) responding to an op-ed in the New York Times about a privacy lesson. Kate Klonick, an assistant professor at St. John's University Law School, described an assignment where she asked students to eavesdrop on and surveil unsuspecting people in public to see what information they could gather using only Google search on their phones.

Gilliard [summarizes](https://twitter.com/hypervisible/status/1110184623915651073) his thinking: Don't surveil people. Don't turn students into spies. Don't divorce privacy from its effects on vulnerable populations.

Gilliard's critique cuts to fundamental problem with "privacy as abstraction" pedagogy. Treating surveillance as intellectual exerciseâ€”interesting puzzle about information availabilityâ€”ignores differential impact. Some populations face surveillance as existential threat: undocumented immigrants, domestic violence survivors, political dissidents, marginalized communities targeted by law enforcement. Teaching students to surveil strangers normalizes surveillance as neutral activity rather than power exercise with real victims. The pedagogy also assumes students occupy positions of relative safetyâ€”they're the watchers, never the watched. Truly understanding privacy requires recognizing it as protection for the vulnerable against the powerful, not thought experiment for the privileged.

### [Is This Smart Device Safe in My Home?](https://www.jamesmullarkey.com/2019/03/is-this-smart-device-safe-in-my-home-three-simple-checks/)

[James Mullarkey](https://twitter.com/jamesmullarkey) on the test we need to give to "Internet of Things" devices to make sure they ensure our basic rights and personal safety.

How do your devices stand up to these three conditions regarding your data:

- The individual alone decides what experience is rendered as data
- The purpose of the data is to enrich the life of the individual
- The individual is the sole arbiter of how the data is shared or put to use

Mullarkey's three-part test exposes how thoroughly current IoT devices fail basic data ethics. Smart speakers that listen always, thermostats that report your schedule, televisions that watch you watching themâ€”none pass even the first test. The individual doesn't decide what's collected; the company does. Data purpose isn't user enrichment but corporate value extraction. Sharing decisions are buried in terms of service no one reads. The framework isn't radicalâ€”it simply asserts individual sovereignty over personal data. That such basic standards seem utopian reveals how far surveillance capitalism has normalized invasion as convenience.

### [Inmates in Finland Are Training AI](https://www.theverge.com/2019/3/28/18285572/prison-labor-finland-artificial-intelligence-data-tagging-vainu)

[Angela Chen](https://twitter.com/chengela) on a startup, [Vainu](https://product.vainu.io/usa/), that uses "prison labor" to classify data to train artificial intelligence algorithms. The startup is using inmates at two prisons in Finland to do a new type of labor.

Some suggest that this is a partnership and a kind of prison reform that teaches valuable skills. Others suggest it plays into the exploitative economics of prisoners being required to work for very low wages.

Is this empowerment or exploitation?

The question resists simple answers. Traditional prison laborâ€”license plates, furnitureâ€”offers no transferable skills. Data tagging provides experience in growing field, potentially useful post-release. But: prisoners can't meaningfully consent given power differential. Low wages extract value from captive workforce. "Job training" rhetoric often masks exploitation. Finland's prison system is more humane than most, but questions persist about whether prisoners can truly choose. The deeper issue: AI systems require massive labeled datasets, and that labeling is tedious human work. Who does invisible labor enabling machine learning? Often the most vulnerableâ€”gig workers, developing world contractors, prisoners. The AI supply chain obscures human cost.

### [Why Banning Phones from Schools Is a Backward Step](https://thenextweb.com/podium/2019/03/23/why-banning-phones-from-schools-is-a-backward-step-for-education/)

[Jamie Brooker](https://twitter.com/jamiebrooker), entrepreneur and co-founder of [Kahoot!](https://kahoot.com/b/) on the regular discussions we have about banning devices from our classrooms.

Brooker suggests that instead we should treat this as an opportunity to help young people today become productive members of society.

> By becoming knowledgeable about the wider role technology plays politically, socially, and environmentally, and with a greater appreciation for the positives of what technology could enable if designed empathetically, the next generations will be better placed to create the tools that provide a more sustainable future.

The ban debate often misses the point. Phones aren't the problemâ€”unexamined phone use is. Banning devices in school doesn't teach students to manage devices outside school; it just delays reckoning. Brooker argues for education about technology rather than protection from it. Students need to understand how platforms manipulate attention, how algorithms shape perception, how design choices serve corporate interests. This knowledge enables critical engagement rather than passive consumption. The goal isn't digital abstinence but digital citizenshipâ€”informed users who can navigate technology intentionally rather than reactively.

---

## ðŸ”¨ Do

### Understanding Procrastination

If procrastination isn't about laziness, then what is it about?

A few of the key insights:

> â€¦on a neural level, we perceive our "future selves" more like strangers than as parts of ourselves. When we procrastinate, parts of our brains actually think that the tasks we're putting off â€” and the accompanying negative feelings that await us on the other side â€” are somebody else's problem.

> We must realize that, at its core, procrastination is about emotions, not productivity. The solution doesn't involve downloading a time management app or learning new strategies for self-control. It has to do with managing our emotions in a new way.

Neuroscience reframes procrastination as temporal empathy failure. We discount future suffering because future self feels like strangerâ€”the neural patterns for thinking about yourself in five years resemble patterns for thinking about other people. Present comfort beats future self's problems. Understanding this shifts intervention strategy: not willpower or scheduling but emotional regulation. The task feels overwhelming? Address the overwhelm. The task triggers anxiety? Address the anxiety. Productivity systems fail because they treat symptoms (missed deadlines) rather than cause (emotional avoidance). Managing procrastination means befriending your future self.

---

## ðŸ¤” Consider

> "With technology tracking us everywhere we go, 'cosplay' might become our best defense against surveillance." â€” Annalee Newitz

Newitz's provocation suggests identity play as resistance strategy. If surveillance depends on consistent identityâ€”linking behaviors across time and space to single profileâ€”then inconsistency defeats it. Cosplay traditionally means costume play, adopting fictional identities. Digital cosplay might mean: varying personas across platforms, introducing noise into data profiles, strategic inconsistency confounding algorithms. Silicon Valley stoics perfect consistent selves; perhaps the oppressed should perfect inconsistent selves. Privacy through obscurity, identity through multiplicity.

---

## ðŸ”— Navigation

**Previous**: [[03 CREATE/ðŸ“§ Newsletter/DL 190\|DL 190]] â€¢ **Next**: [[03 CREATE/ðŸ“§ Newsletter/DL 192\|DL 192]] â€¢ **Archive**: [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]]

**ðŸŒ± Connected Concepts**:

- [[Privacy Ethics\|Privacy Ethics]] â€” [[Chris Gilliard\|Chris Gilliard]] arguing against surveillance pedagogy divorced from concrete harms to vulnerable populations in [[Digital Rights\|Digital Rights]].
- [[Surveillance Culture\|Surveillance Culture]] â€” Smart devices failing basic data sovereignty tests where individuals control collection, purpose, and sharing in [[IoT Ethics\|IoT Ethics]].
- [[Technology Education\|Technology Education]] â€” Teaching students critical engagement with platforms rather than banning devices delays necessary digital citizenship reckoning in [[02 DEVELOP/ðŸŒ¿ Plants/Media Literacy\|Media Literacy]].
- [[Digital Labor\|Digital Labor]] â€” Finnish prisoners training AI raising exploitation questions about who performs invisible work enabling machine learning in [[AI Ethics\|AI Ethics]].
- [[Attention Economy\|Attention Economy]] â€” Procrastination reframed as emotional problem where future selves feel like strangers requiring empathy rather than productivity apps in [[Behavioral Psychology\|Behavioral Psychology]].

---

*Part of the [[03 CREATE/ðŸ“§ Newsletter/ðŸ“§ Newsletter\|ðŸ“§ Newsletter]] archive documenting digital literacy and technology.*
