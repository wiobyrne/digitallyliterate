---
{"dg-publish":true,"dg-permalink":"epistemic-stance","permalink":"/epistemic-stance/","title":"Epistemic Stance","tags":["epistemic-stance","knowledge-construction","authority","critical-thinking","AI-literacy","trust","validation"]}
---

# Epistemic Stance

## Definition

**Epistemic stance** refers to how students position themselves in relation to knowledge construction when working with AI. It encompasses their beliefs about:

- **Who** has authority to create and validate knowledge (human, AI, or collaboration)
- **What** counts as legitimate knowledge
- **How** knowledge should be constructed and verified
- **Where** responsibility lies for truth claims

Epistemic stance reveals whether students see themselves as knowledge *consumers* (passive) or knowledge *constructors* (active).

---

## Theoretical Foundation

This concept draws from:

1. **Epistemology** - Theories of knowledge and knowing (Hofer & Pintrich, 1997)
2. **Epistemic cognition** - How people understand the nature and justification of knowledge (Greene et al., 2016)
3. **New Literacies** - Knowledge construction in digital environments (Leu et al., 2013)
4. **Critical AI literacy** - Questioning AI as authoritative knowledge source (Long & Magerko, 2020)

---

## Dimensions of Epistemic Stance in AI-Literacy

### 1. Authority and Trust
**Who is positioned as the knower?**

| Stance | Description | Evidence |
|--------|-------------|----------|
| **AI-Authoritative** | AI positioned as expert/oracle | "The AI said..." (uncritical acceptance) |
| **Self-Authoritative** | Student as primary knowledge constructor | "I used AI to help me think..." |
| **Co-Constructed** | Knowledge emerges from collaboration | "AI suggested X, but I revised to Y because..." |

### 2. Knowledge Validation
**How is knowledge verified?**

| Stance | Description | Evidence |
|--------|-------------|----------|
| **Outsourced Validation** | AI output accepted without verification | No fact-checking, source verification |
| **Human Validation** | Student cross-checks against sources | "I verified the AI's claim against..." |
| **Collaborative Validation** | Iterative checking with AI and sources | Using AI to check AI, plus human judgment |

### 3. Responsibility for Truth
**Who is accountable for accuracy?**

| Stance | Description | Evidence |
|--------|-------------|----------|
| **AI-Responsible** | AI blamed for errors | "The AI got it wrong" |
| **Self-Responsible** | Student owns final product | "I should have caught that error" |
| **Shared-Responsible** | Acknowledges joint accountability | "I didn't verify the AI's output carefully enough" |

---

## Epistemic Stance Continuum

```
Passive Consumption ‚Üê‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Äï‚Üí Active Construction
(AI as Authority)                               (Human as Authority)
        |                    |                    |
   Low Agency          Co-Construction      High Agency
   Low Critical         Collaborative        High Critical
    Thinking             Thinking             Thinking
```

---

## Evidence of Epistemic Stance in Framework Components

### In [[02 DEVELOP/üåø Plants/Co-Constructing AI Boundaries Framework Component - Outputs\|Co-Constructing AI Boundaries Framework Component - Outputs]]
- Critical evaluation of AI responses
- Recognition of hallucinations, bias
- Questioning AI's "knowledge"

### In [[Co-Constructing AI Boundaries Framework Component - Integration\|Co-Constructing AI Boundaries Framework Component - Integration]]
- Modification signals self as knowledge authority
- Rejection demonstrates critical epistemic stance
- Verbatim copy suggests AI-authoritative stance

### In [[Co-Constructing AI Boundaries Framework Component - Reflection\|Co-Constructing AI Boundaries Framework Component - Reflection]]
- Explicit statements about knowledge authority
- Metacognitive awareness of who is "thinking"
- Articulation of responsibility for truth claims

---

## Relationship to Other Concepts

- [[03 CREATE/üå≤ Evergreens/Agency\|Agency]] - Epistemic stance informs how students exercise agency
- [[03 CREATE/üå≤ Evergreens/Boundary-work\|Boundary-work]] - Boundaries reflect epistemic beliefs about authority

---

## Key Questions for Analyzing Epistemic Stance

1. Does the student position themselves as knowledge creator or knowledge consumer?
2. Do they treat AI outputs as truth claims requiring verification or as authoritative?
3. Do they claim ownership of ideas generated through AI collaboration?
4. How do they talk about responsibility for accuracy and quality?
5. Do they demonstrate awareness of AI limitations and biases?

---

## Examples from Data

### High Epistemic Agency
```
"I asked the AI to summarize the readings, but I noticed it
missed the critical perspective from hooks (1994), so I
prompted it to reconsider. Even then, I rewrote the analysis
in my own voice because the AI's framing was too neutral."
```
(Student positions self as authority, validates AI, transforms output)

### Low Epistemic Agency
```
"Here's what the AI said about the topic."
[Pastes AI output verbatim]
```
(AI positioned as authority, no validation, no transformation)

---

## Pedagogical Implications

To foster critical epistemic stance:
1. Explicit discussion of knowledge authority with AI
2. Practice identifying AI errors and biases
3. Structured reflection on "who is thinking"
4. Emphasis on human responsibility for final claims
5. Modeling of verification and transformation practices

---

## Related Notes

- [[02 DEVELOP/üåø Plants/Analytic Framework for AI Human Meaning-Making Practices\|Analytic Framework for AI Human Meaning-Making Practices]]
- [[02 DEVELOP/üåø Plants/How learners should engage Large Language Models framework\|How learners should engage Large Language Models framework]]
- [[02 DEVELOP/üåø Plants/Tracing the AI-Human Conversation Framework\|Tracing the AI-Human Conversation Framework]]

---

## Tags

#concept #epistemic-stance #knowledge-construction #AI-literacy #critical-thinking
