---
{"dg-publish":true,"dg-permalink":"orchestrated-collaboration-vs-algorithmic-passivity","permalink":"/orchestrated-collaboration-vs-algorithmic-passivity/","title":"Orchestrated Collaboration vs Algorithmic Passivity","tags":["AI-literacy","boundary-work","pre-service-teachers","agency","human-AI-collaboration","epistemic-authority"]}
---

# Orchestrated Collaboration vs Algorithmic Passivity

## Core Framework

This research framework examines how pre-service teachers negotiate agency with generative AI during literacy education tasks. Two contrasting interaction profiles emerge from process-level analysis:

### The Orchestrator Profile

The **Orchestrator** engages in active boundary work characterized by:

- **Iterative correction loops**: Extended back-and-forth dialogue with AI, arguing with the model and refining outputs
- **Epistemic stance assertion**: Rejecting responses not because they are incorrect, but because they lack nuance, voice, or contextual sensitivity
- **Constraint evolution**: Increasingly specific redirection of AI behavior over time
- **Extended response latencies**: Longer pauses between AI output and student intervention, signaling deliberation and critical reading
- **High edit distance**: Substantial divergence between raw AI output and final artifact

Crucially, Orchestrators often experience heightened "cheating tension" because their deep engagement makes AI contributions more visible. The more they refine the AI's output to match their "historical body" (personal teaching philosophy), the more they feel they are "using" the AI to simulate their own brain.

### The Outsourcer Profile

The **Outsourcer** demonstrates algorithmic passivity through:

- **Linear delegation**: Minimal iterative engagement, accepting early outputs
- **Generic deference**: Increasingly vague prompts that surrender epistemic authority
- **Low edit distance**: Final artifacts closely mirror raw AI output
- **Short latencies**: Quick acceptance without substantive evaluation
- **Termination at "Acceptable"**: Evaluative process concludes once outputs appear serviceable

---

## Theoretical Foundation: Wertsch's Mediational Means

This framework draws on **Wertsch's (1991) mediational means** concept, viewing AI as a cognitive tool that shapes and is shaped by human activity. Key insights include:

1. **Irreducible tension**: There is always tension between the agent and the cultural tools they employ; the tool transforms the activity even as the agent uses it
2. **Agency as interactional accomplishment**: Agency is not a property of the individual but emerges through the interaction between human and tool
3. **Historical body**: Students bring prior educational experiences (years of prohibition-oriented schooling) that shape how they negotiate AI use

---

## The Four-Step Agency Check

Agency in AI-mediated literacy clusters around a recurring evaluative sequence:

| Level | Question | Threshold |
|-------|----------|-----------|
| **Credible** | Is the information accurate and source-grounded? | Basic verification |
| **Relevant** | Does it address the specific task or inquiry? | Contextual fit |
| **Acceptable** | Is it cohesive and serviceable as a draft? | Low-agency termination point |
| **Nuanced** | Does it reflect particular epistemic stance, contextual sensitivity, and human voice? | High-agency practice |

Low-agency interactions terminate at "Acceptable." High-agency practice requires engagement at the level of "Nuance."

---

## Key Findings

1. **Process over product**: Differences between Orchestrators and Outsourcers are visible only through process-level analysis of interaction traces; final artifacts often appear deceptively similar
2. **Ethical discomfort correlates with sophistication**: Students who engage most deeply with boundary work experience the most "cheating tension"
3. **HITL as literacy practice**: Human-in-the-Loop is not a technical safeguard but an interactional literacy practice
4. **AI as amplifier or authority**: AI functions as a cognitive amplifier only when humans actively regulate the loop; absent such regulation, AI becomes structural authority

---

## Implications for Teacher Education

- Design "loops worth living in": Learning environments that make evaluation, refusal, and reflection visible and expected
- Normalize productive friction: Support students in embracing cognitive friction as professional development
- Reframe AI literacy as boundary work: Not about prompt strategies but cultivating professional judgment
- Position refusal as practice: Teach students that deciding when NOT to use AI is as important as knowing how to use it

---

## Related Concepts

- [[03 CREATE/ðŸŒ² Evergreens/Boundary-work\|Boundary-work]]
- [[03 CREATE/ðŸŒ² Evergreens/Agency\|Agency]]
- [[03 CREATE/ðŸŒ² Evergreens/Epistemic Stance\|Epistemic Stance]]
- [[03 CREATE/ðŸŒ² Evergreens/Nexus Analysis for AI Literacy Research\|Nexus Analysis for AI Literacy Research]]
- [[SPOC Model for AI Interaction Analysis\|SPOC Model for AI Interaction Analysis]]
